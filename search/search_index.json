{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ensembl-genes","text":"<p>Ensembl genes utilities and tools \u2014 project documentation</p> <p>This repository provides tools and utilities used by Ensembl for genome annotation and related workflows. The documentation is produced with MkDocs.</p> <p>Contents</p> <ol> <li>Install</li> <li>Usage</li> </ol>"},{"location":"#license","title":"License","text":"<p>Software in this repository is distributed under the Apache-2.0 License.</p> <p>Source: https://github.com/Ensembl/ensembl-genes</p>"},{"location":"code_of_conduct/","title":"Code of Conduct","text":"<p>The Ensembl project is built on a foundation of collaboration, mutual respect and equality with a diverse and global community. We do not condone discrimination or abusive behaviour of any form. We encourage participation and engagement for everyone, in a professional manner, and wish all members of our community to adhere to the same principles.</p>"},{"location":"install/","title":"How to install this repository","text":"<p>This project requires Python 3.11+ (see <code>pyproject.toml</code>).</p>"},{"location":"install/#basic-installation","title":"Basic installation","text":"<p>To install the package from GitHub using pip:</p> <pre><code>pip install git+https://github.com/Ensembl/ensembl-genes.git\n</code></pre>"},{"location":"install/#development-installation","title":"Development installation","text":"<p>Create and activate a virtual environment, then install in editable mode:</p> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\ngit clone https://github.com/Ensembl/ensembl-genes.git\npip install -e ensembl-genes/.[cicd,docs]\n</code></pre> <p>Documentation is generated with MkDocs. For usage information see the <code>mkdocs.yml</code> and the <code>mkdocs/</code> directory.</p>"},{"location":"usage/","title":"Usage","text":"<p>Examples and usage notes for the utilities in this repository will be added here.</p> <p>TBD: add short examples for the commonly used scripts (e.g., <code>star2introns</code>, <code>Repeatmask_Red</code>).</p>"},{"location":"ensembl/genes/automation/pre_release_ftp/","title":"<code>ensembl.genes.automation.pre_release_ftp</code>","text":""},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp","title":"<code>ensembl.genes.automation.pre_release_ftp</code>","text":"<p>Pre-release FTP processing script for Ensembl genebuild pipeline.</p> <p>This script gathers GTF, GFF3, and reheadered toplevel FASTA files from a pre-release directory structure and organizes them into an FTP-ready directory structure with standardized naming and MD5 checksums.</p>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.calculate_md5","title":"<code>calculate_md5(filepath)</code>","text":"<p>Calculate MD5 checksum of a file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the file to checksum</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Hexadecimal MD5 hash</p> <p>Raises:</p> Type Description <code>IOError</code> <p>If file cannot be read</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def calculate_md5(filepath: str) -&gt; str:\n    \"\"\"\n    Calculate MD5 checksum of a file.\n\n    Args:\n        filepath: Path to the file to checksum\n\n    Returns:\n        str: Hexadecimal MD5 hash\n\n    Raises:\n        IOError: If file cannot be read\n    \"\"\"\n    hash_md5 = hashlib.md5()\n    with open(filepath, \"rb\") as file:\n        for chunk in iter(lambda: file.read(4096), b\"\"):\n            hash_md5.update(chunk)\n    return hash_md5.hexdigest()\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.create_ftp_directory_structure","title":"<code>create_ftp_directory_structure(output_path, species_name, gca_string, annotation_files, fasta_file, two_bit_file, logger)</code>","text":"<p>Create FTP directory structure and copy files with standardized naming.</p> <p>Creates directory structure: {output_path}/ftp_release/{Species_Name}/{GCA_ID}/ and copies files with standardized names.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>str</code> <p>Base output directory</p> required <code>species_name</code> <code>str</code> <p>Species name for directory creation</p> required <code>gca_string</code> <code>str</code> <p>Full GCA identifier (e.g., 'GCA_030222105.1')</p> required <code>annotation_files</code> <code>Dict[str, Optional[str]]</code> <p>Dictionary of annotation file paths</p> required <code>fasta_file</code> <code>str</code> <p>Path to reheadered FASTA file</p> required <code>two_bit_file</code> <code>Optional[str]</code> <p>Path to 2bit file</p> required <code>logger</code> <code>Logger</code> <p>Logger instance for status messages</p> required <p>Returns:</p> Type Description <code>Tuple[str, List[str]]</code> <p>Tuple[str, List[str]]: FTP directory path and list of copied file paths</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If directory creation or file copying fails</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def create_ftp_directory_structure(  # pylint: disable=too-many-locals, too-many-arguments\n    output_path: str,\n    species_name: str,\n    gca_string: str,\n    annotation_files: Dict[str, Optional[str]],\n    fasta_file: str,\n    two_bit_file: Optional[str],\n    logger: logging.Logger,\n) -&gt; Tuple[str, List[str]]:\n    \"\"\"\n    Create FTP directory structure and copy files with standardized naming.\n\n    Creates directory structure: {output_path}/ftp_release/{Species_Name}/{GCA_ID}/\n    and copies files with standardized names.\n\n    Args:\n        output_path: Base output directory\n        species_name: Species name for directory creation\n        gca_string: Full GCA identifier (e.g., 'GCA_030222105.1')\n        annotation_files: Dictionary of annotation file paths\n        fasta_file: Path to reheadered FASTA file\n        two_bit_file: Path to 2bit file\n        logger: Logger instance for status messages\n\n    Returns:\n        Tuple[str, List[str]]: FTP directory path and list of copied file paths\n\n    Raises:\n        OSError: If directory creation or file copying fails\n    \"\"\"\n    # Parse GCA information\n    gca_number, version = parse_gca_id(gca_string)\n\n    # Create FTP directory structure: species_name/GCA_ID/\n    species_title = format_species_name(species_name)\n\n    ftp_base = os.path.join(output_path, \"ftp_release\")\n    ftp_species_dir = os.path.join(ftp_base, species_title)\n    ftp_final_dir = os.path.join(ftp_species_dir, gca_string)\n\n    # Create directories\n    os.makedirs(ftp_final_dir, exist_ok=True)\n    logger.info(f\"Created FTP directory: {ftp_final_dir}\")\n\n    copied_files: List[str] = []\n\n    # Copy and rename annotation files\n    for file_type, source_file in annotation_files.items():\n        if source_file and os.path.exists(source_file):\n            new_filename = generate_new_filename(\n                source_file, species_name, gca_number, version, file_type\n            )\n            dest_file = os.path.join(ftp_final_dir, new_filename)\n\n            logger.info(\n                f\"Copying {file_type}: {os.path.basename(source_file)} -&gt; {new_filename}\"\n            )\n            shutil.copy2(source_file, dest_file)\n            copied_files.append(dest_file)\n        else:\n            logger.warning(f\"No {file_type} file found to copy\")\n\n    # Copy and rename FASTA file\n    if fasta_file and os.path.exists(fasta_file):\n        new_fasta_name = generate_new_filename(\n            fasta_file, species_name, gca_number, version, \"dna.softmasked.fa\"\n        )\n        dest_fasta = os.path.join(ftp_final_dir, new_fasta_name)\n\n        logger.info(\n            f\"Copying FASTA: {os.path.basename(fasta_file)} -&gt; {new_fasta_name}\"\n        )\n        shutil.copy2(fasta_file, dest_fasta)\n        copied_files.append(dest_fasta)\n    else:\n        logger.warning(\"No reheadered FASTA file found to copy\")\n\n    # Copy 2bit file if it exists\n    if two_bit_file and os.path.exists(two_bit_file):\n        new_2bit_name = generate_new_filename(\n            two_bit_file, species_name, gca_number, version, \"dna.toplevel.2bit\"\n        )\n        dest_2bit = os.path.join(ftp_final_dir, new_2bit_name)\n\n        logger.info(\n            f\"Copying 2bit file: {os.path.basename(two_bit_file)} -&gt; {new_2bit_name}\"\n        )\n        shutil.copy2(two_bit_file, dest_2bit)\n        copied_files.append(dest_2bit)\n    else:\n        logger.warning(\"No 2bit file found to copy\")\n    return ftp_final_dir, copied_files\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.extract_species_from_filename","title":"<code>extract_species_from_filename(filename)</code>","text":"<p>Extract species name from Ensembl filename format.</p> <p>Parses filenames like: - Bos_taurus_gca002263795v4.ARS-UCD2.0.114.primary_assembly.1.gff3.gz - macaca_mulatta_gca030222105v1.gtf.gz</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Full filename or path to parse</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Species name (e.g., 'Bos_taurus', 'macaca_mulatta')</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def extract_species_from_filename(filename: str) -&gt; str:\n    \"\"\"\n    Extract species name from Ensembl filename format.\n\n    Parses filenames like:\n    - Bos_taurus_gca002263795v4.ARS-UCD2.0.114.primary_assembly.1.gff3.gz\n    - macaca_mulatta_gca030222105v1.gtf.gz\n\n    Args:\n        filename: Full filename or path to parse\n\n    Returns:\n        str: Species name (e.g., 'Bos_taurus', 'macaca_mulatta')\n    \"\"\"\n    basename = os.path.basename(filename)\n    # Split on first occurrence of version pattern (gca followed by numbers)\n    match = re.match(r\"([a-zA-Z_]+)_gca\\d+\", basename, re.IGNORECASE)\n    if match:\n        return match.group(1)\n\n    # Fallback: take everything before the first dot\n    return basename.split(\".\")[0]\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.find_2bit","title":"<code>find_2bit(output_path)</code>","text":"<p>Find the 2bit file in the output directory.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>str</code> <p>Path to the base output directory</p> required <p>Returns:     Optional[str]: Path to the 2bit file or None if not found</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def find_2bit(output_path: str) -&gt; Optional[str]:\n    \"\"\"\n    Find the 2bit file in the output directory.\n\n    Args:\n        output_path: Path to the base output directory\n    Returns:\n        Optional[str]: Path to the 2bit file or None if not found\n    \"\"\"\n    two_bit_pattern = os.path.join(output_path, \"*_softmasked_toplevel.2bit\")\n    two_bit_matches = glob.glob(two_bit_pattern)\n    if two_bit_matches:\n        return two_bit_matches[0]  # Return first match\n    return None\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.find_annotation_files","title":"<code>find_annotation_files(output_path)</code>","text":"<p>Find GFF3 and GTF annotation files in the clade (vertabrates/ etc) directory structure. Prioritizes main annotation files over specialized variants like abinitio.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>str</code> <p>Path to the base output directory</p> required <p>Returns:</p> Type Description <code>Dict[str, Optional[str]]</code> <p>Dict[str, Optional[str]]: Dictionary with 'gff3' and 'gtf' keys mapping                     to file paths or None if not found</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def find_annotation_files(output_path: str) -&gt; Dict[str, Optional[str]]:\n    \"\"\"\n    Find GFF3 and GTF annotation files in the clade (vertabrates/ etc) directory structure.\n    Prioritizes main annotation files over specialized variants like abinitio.\n\n    Args:\n        output_path: Path to the base output directory\n\n    Returns:\n        Dict[str, Optional[str]]: Dictionary with 'gff3' and 'gtf' keys mapping\n                                to file paths or None if not found\n    \"\"\"\n    annotation_files: Dict[str, Optional[str]] = {\"gff3\": None, \"gtf\": None}\n\n    # Look for GFF3 files\n    gff3_pattern = os.path.join(output_path, \"*\", \"gff3\", \"**\", \"*.gff3.gz\")\n    gff3_matches = glob.glob(gff3_pattern, recursive=True)\n    if gff3_matches:\n        # Prioritize main GFF3 files over specialized variants\n        main_gff3 = _select_main_annotation_file(gff3_matches, \"gff3\")\n        annotation_files[\"gff3\"] = main_gff3\n\n    # Look for GTF files\n    gtf_pattern = os.path.join(output_path, \"*\", \"gtf\", \"**\", \"*.gtf.gz\")\n    gtf_matches = glob.glob(gtf_pattern, recursive=True)\n    if gtf_matches:\n        # Prioritize main GTF files over specialized variants\n        main_gtf = _select_main_annotation_file(gtf_matches, \"gtf\")\n        annotation_files[\"gtf\"] = main_gtf\n\n    return annotation_files\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.find_reheadered_fasta","title":"<code>find_reheadered_fasta(output_path)</code>","text":"<p>Find the reheadered toplevel FASTA file and its corresponding FAI index file.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>str</code> <p>Directory path to search for FASTA files</p> required <p>Returns:</p> Type Description <code>str</code> <p>tuple[str, str]: Full paths to (FASTA file, FAI file)</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If reheadered FASTA file or its FAI index is not found</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def find_reheadered_fasta(output_path: str) -&gt; str:\n    \"\"\"\n    Find the reheadered toplevel FASTA file and its corresponding FAI index file.\n\n    Args:\n        output_path: Directory path to search for FASTA files\n\n    Returns:\n        tuple[str, str]: Full paths to (FASTA file, FAI file)\n\n    Raises:\n        FileNotFoundError: If reheadered FASTA file or its FAI index is not found\n    \"\"\"\n    # Find FASTA file\n    fasta_pattern = os.path.join(output_path, \"*_softmasked_toplevel.fa.gz\")\n    fasta_matches = glob.glob(fasta_pattern)\n    if not fasta_matches:\n        raise FileNotFoundError(\n            f\"No reheadered toplevel FASTA file found in {output_path}\"\n        )\n\n    return fasta_matches[0]\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.format_species_name","title":"<code>format_species_name(species_name)</code>","text":"<p>Reformat species name into typical binomial nomenclature format.</p> <p>Converts species names to the standard scientific naming convention where the genus is capitalized, subsequent parts are lowercase, and all parts are separated by underscores. Replaces spaces, hyphens, and periods with underscores.</p> <p>Parameters:</p> Name Type Description Default <code>species_name</code> <code>str</code> <p>Species name to format (e.g., 'homo sapiens', 'canis_lupus')</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Formatted species name (e.g., 'Homo_sapiens', 'Canis_lupus')</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def format_species_name(species_name: str) -&gt; str:\n    \"\"\"\n    Reformat species name into typical binomial nomenclature format.\n\n    Converts species names to the standard scientific naming convention where\n    the genus is capitalized, subsequent parts are lowercase, and all parts\n    are separated by underscores. Replaces spaces, hyphens, and periods with\n    underscores.\n\n    Args:\n        species_name: Species name to format (e.g., 'homo sapiens', 'canis_lupus')\n\n    Returns:\n        str: Formatted species name (e.g., 'Homo_sapiens', 'Canis_lupus')\n    \"\"\"\n    parts = species_name.replace(\"_\", \" \").split()\n    if len(parts) &gt;= 2:\n        species_title = parts[0].capitalize() + \"_\" + parts[1].lower()\n        # Add any additional parts if they exist\n        if len(parts) &gt; 2:\n            species_title += \"_\" + \"_\".join(part.lower() for part in parts[2:])\n    else:\n        species_title = species_name.capitalize()\n    return species_title.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\".\", \"_\")\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.generate_md5_checksums","title":"<code>generate_md5_checksums(directory, files, logger)</code>","text":"<p>Generate MD5 checksums for files and write to CHECKSUMS file.</p> <p>Creates a CHECKSUMS file in the specified directory with MD5 hashes for all provided files in the format: {hash}  {filename}</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Directory where CHECKSUMS file will be created</p> required <code>files</code> <code>List[str]</code> <p>List of file paths to checksum</p> required <code>logger</code> <code>Logger</code> <p>Logger instance for status messages</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the created CHECKSUMS file</p> <p>Raises:</p> Type Description <code>IOError</code> <p>If CHECKSUMS file cannot be written</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def generate_md5_checksums(\n    directory: str, files: List[str], logger: logging.Logger\n) -&gt; str:\n    \"\"\"\n    Generate MD5 checksums for files and write to CHECKSUMS file.\n\n    Creates a CHECKSUMS file in the specified directory with MD5 hashes\n    for all provided files in the format: {hash}  {filename}\n\n    Args:\n        directory: Directory where CHECKSUMS file will be created\n        files: List of file paths to checksum\n        logger: Logger instance for status messages\n\n    Returns:\n        str: Path to the created CHECKSUMS file\n\n    Raises:\n        IOError: If CHECKSUMS file cannot be written\n    \"\"\"\n    md5_file = os.path.join(directory, \"CHECKSUMS\")\n\n    logger.info(f\"Generating MD5 checksums in: {md5_file}\")\n\n    with open(md5_file, \"w\") as file:  # pylint: disable=unspecified-encoding\n        for filepath in sorted(files):\n            if os.path.exists(filepath):\n                filename = os.path.basename(filepath)\n                md5_hash = calculate_md5(filepath)\n                file.write(f\"{md5_hash}  {filename}\\n\")\n                logger.info(f\"  {filename}: {md5_hash}\")\n\n    return md5_file\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.generate_new_filename","title":"<code>generate_new_filename(original_file, species_name, gca_number, version, file_type)</code>","text":"<p>Generate standardized filename for FTP release.</p> <p>Creates filenames in the format: species_gca{number}v{version}.{type}.gz</p> <p>Parameters:</p> Name Type Description Default <code>original_file</code> <code>str</code> <p>Original file path (used for reference)</p> required <code>species_name</code> <code>str</code> <p>Species name (e.g., 'Macaca_mulatta')</p> required <code>gca_number</code> <code>str</code> <p>GCA accession number (e.g., '030222105')</p> required <code>version</code> <code>str</code> <p>Version number (e.g., '1')</p> required <code>file_type</code> <code>str</code> <p>File type (e.g., 'gff3', 'gtf', 'dna.toplevel.fa')</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Standardized filename</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def generate_new_filename(\n    original_file: str, species_name: str, gca_number: str, version: str, file_type: str\n) -&gt; str:\n    \"\"\"\n    Generate standardized filename for FTP release.\n\n    Creates filenames in the format: species_gca{number}v{version}.{type}.gz\n\n    Args:\n        original_file: Original file path (used for reference)\n        species_name: Species name (e.g., 'Macaca_mulatta')\n        gca_number: GCA accession number (e.g., '030222105')\n        version: Version number (e.g., '1')\n        file_type: File type (e.g., 'gff3', 'gtf', 'dna.toplevel.fa')\n\n    Returns:\n        str: Standardized filename\n    \"\"\"\n    species_lower = species_name.lower()\n    new_name = f\"{species_lower}_gca{gca_number}v{version}.{file_type}\"\n\n    if is_compressed_file(original_file) and not new_name.endswith(\".gz\"):\n        new_name += \".gz\"\n    return new_name\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.is_compressed_file","title":"<code>is_compressed_file(filepath)</code>","text":"<p>Check if a file is actually compressed by examining its magic bytes.</p> <p>Checks for gzip magic bytes (0x1f, 0x8b) at the beginning of the file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the file to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if file is actually gzip compressed</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def is_compressed_file(filepath: str) -&gt; bool:\n    \"\"\"\n    Check if a file is actually compressed by examining its magic bytes.\n\n    Checks for gzip magic bytes (0x1f, 0x8b) at the beginning of the file.\n\n    Args:\n        filepath: Path to the file to check\n\n    Returns:\n        bool: True if file is actually gzip compressed\n    \"\"\"\n    try:\n        with open(filepath, \"rb\") as file:\n            magic_bytes = file.read(2)\n            # Check for gzip magic bytes (0x1f, 0x8b)\n            return (\n                len(magic_bytes) == 2\n                and magic_bytes[0] == 0x1F\n                and magic_bytes[1] == 0x8B\n            )\n    except (IOError, OSError):\n        # If we can't read the file, assume it's not compressed\n        return False\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.main","title":"<code>main()</code>","text":"<p>Main function to process pre-release FTP data.</p> <p>Parses command line arguments, validates inputs, and orchestrates the file gathering and FTP structure creation process.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>On validation errors or processing failures</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"\n    Main function to process pre-release FTP data.\n\n    Parses command line arguments, validates inputs, and orchestrates the\n    file gathering and FTP structure creation process.\n\n    Raises:\n        SystemExit: On validation errors or processing failures\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Gather GTF, GFF3, and FASTA files into FTP directory structure\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nExamples:\n    %(prog)s -p /path/to/GCA_030222105.1/ -g GCA_030222105.1 -s Macaca_mulatta\n    %(prog)s -p /path/to/data/ -g GCA_002263795.4\n        \"\"\",\n    )\n    parser.add_argument(\n        \"-p\",\n        \"--path\",\n        required=True,\n        help=\"Output path containing the genome data directory structure\",\n    )\n    parser.add_argument(\n        \"-g\",\n        \"--gca\",\n        required=True,\n        help=\"GCA identifier in format GCA_NNNNNNNN.N (e.g., GCA_030222105.1)\",\n    )\n    parser.add_argument(\n        \"-s\",\n        \"--species\",\n        help=\"Species name (e.g., Macaca_mulatta). If not provided, will extract from filenames\",\n    )\n\n    args = parser.parse_args()\n    logger = setup_logging()\n\n    output_path: str = args.path\n    gca_string: str = args.gca\n    species_name: Optional[str] = args.species\n\n    # Validate input path\n    if not os.path.exists(output_path):\n        logger.error(f\"Output path does not exist: {output_path}\")\n        sys.exit(1)\n\n    if not os.path.isdir(output_path):\n        logger.error(f\"Output path is not a directory: {output_path}\")\n        sys.exit(1)\n\n    logger.info(f\"Processing pre-release FTP data in: {output_path}\")\n    logger.info(f\"GCA identifier: {gca_string}\")\n\n    try:\n        # Find reheadered FASTA file\n        try:\n            fasta_file = find_reheadered_fasta(output_path)\n            logger.info(f\"Found reheadered FASTA file: {os.path.basename(fasta_file)}\")\n\n        except FileNotFoundError as err:\n            logger.error(str(err))\n            sys.exit(1)\n\n        annotation_files = find_annotation_files(output_path)\n        logger.info(f\"Found annotation files: {annotation_files}\")\n\n        # Find 2bit file if it exists\n        two_bit_file = find_2bit(output_path)\n        if two_bit_file:\n            logger.info(f\"Found 2bit file: {os.path.basename(two_bit_file)}\")\n        else:\n            logger.warning(\"No 2bit file found in the output directory\")\n\n        # Extract species name if not provided\n        if not species_name:\n            # Try to extract from GFF3 file first, then GTF\n            for file_type, filepath in annotation_files.items():\n                if filepath:\n                    species_name = extract_species_from_filename(filepath)\n                    logger.info(\n                        f\"Extracted species name from {file_type} file: {species_name}\"\n                    )\n                    break\n\n            if not species_name:\n                logger.error(\n                    \"Could not determine species name. Please provide with -s option\"\n                )\n                sys.exit(1)\n\n        # Create FTP directory structure and copy files\n        ftp_dir, copied_files = create_ftp_directory_structure(\n            output_path,\n            species_name,\n            gca_string,\n            annotation_files,\n            fasta_file,\n            two_bit_file,\n            logger,\n        )\n\n        # Generate MD5 checksums\n        if copied_files:\n            checksum_file = generate_md5_checksums(ftp_dir, copied_files, logger)\n            logger.info(f\"MD5 checksums written to: {checksum_file}\")\n\n        logger.info(f\"FTP structure created successfully in: {ftp_dir}\")\n        logger.info(\"Pre-release FTP processing completed successfully\")\n\n    except Exception as err:  # pylint: disable=broad-exception-caught\n        logger.error(f\"Error during processing: {str(err)}\")\n        sys.exit(1)\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.parse_gca_id","title":"<code>parse_gca_id(gca_string)</code>","text":"<p>Parse GCA ID to extract accession number and version information.</p> <p>Parameters:</p> Name Type Description Default <code>gca_string</code> <code>str</code> <p>GCA identifier in format GCA_030222105.1</p> required <p>Returns:</p> Type Description <code>Tuple[str, str]</code> <p>Tuple[str, str]: GCA number and version (e.g., ('030222105', '1'))</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If GCA format is invalid</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def parse_gca_id(gca_string: str) -&gt; Tuple[str, str]:\n    \"\"\"\n    Parse GCA ID to extract accession number and version information.\n\n    Args:\n        gca_string: GCA identifier in format GCA_030222105.1\n\n    Returns:\n        Tuple[str, str]: GCA number and version (e.g., ('030222105', '1'))\n\n    Raises:\n        ValueError: If GCA format is invalid\n    \"\"\"\n    # Extract GCA number and version from format like GCA_030222105.1\n    match = re.match(r\"GCA_(\\d+)\\.(\\d+)\", gca_string)\n    if not match:\n        raise ValueError(\n            f\"Invalid GCA format: {gca_string}. Expected format: GCA_NNNNNNNN.N\"\n        )\n\n    gca_number = match.group(1)\n    version = match.group(2)\n\n    return gca_number, version\n</code></pre>"},{"location":"ensembl/genes/automation/pre_release_ftp/#ensembl.genes.automation.pre_release_ftp.setup_logging","title":"<code>setup_logging()</code>","text":"<p>Set up logging configuration with timestamps and appropriate formatting.</p> <p>Returns:</p> Type Description <code>Logger</code> <p>logging.Logger: Configured logger instance</p> Source code in <code>src/python/ensembl/genes/automation/pre_release_ftp.py</code> <pre><code>def setup_logging() -&gt; logging.Logger:\n    \"\"\"\n    Set up logging configuration with timestamps and appropriate formatting.\n\n    Returns:\n        logging.Logger: Configured logger instance\n    \"\"\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n        datefmt=\"%Y-%m-%d %H:%M:%S\",\n    )\n    return logging.getLogger(__name__)\n</code></pre>"},{"location":"ensembl/genes/content/main_static_content/","title":"<code>ensembl.genes.content.main_static_content</code>","text":""},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content","title":"<code>ensembl.genes.content.main_static_content</code>","text":"<p>Module to create static content files for main release. This module fetches assembly information from a MySQL database and the ENA API, and generates HTML files containing assembly and annotation content.</p>"},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.CORE_QUERY","title":"<code>CORE_QUERY = \"SELECT meta_key, meta_value FROM meta WHERE meta_key IN ('assembly.accession', 'species.url');\"</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.assembly_info","title":"<code>assembly_info = get_assembly_info(core_dict['assembly.accession'])</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.core_dict","title":"<code>core_dict = {(meta_pair[0]): (meta_pair[1]) for meta_pair in core_meta}</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.core_meta","title":"<code>core_meta = mysql_fetch_data(CORE_QUERY, host=(server_info['server']['db_host']), user=(server_info['server']['db_user']), port=(server_info['server']['db_port']), database=db)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.db","title":"<code>db = args.db_name</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.output_dir","title":"<code>output_dir = Path(args.output_dir)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.parser","title":"<code>parser = argparse.ArgumentParser(description='Prepare static content files for main release')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.server_info","title":"<code>server_info = {'server': {'db_host': args.host, 'db_port': args.port, 'db_user': 'ensro'}}</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.url_name","title":"<code>url_name = core_dict['species.url']</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.get_assembly_info","title":"<code>get_assembly_info(accession)</code>","text":"<p>Retrieve assembly information from the ENA API for a given accession.</p> <p>Parameters:</p> Name Type Description Default <code>accession</code> <code>str</code> <p>The assembly accession number to fetch information for.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, str]</code> <p>A dictionary containing assembly attributes such as name, level,        submitter, and counts.</p> Source code in <code>src/python/ensembl/genes/content/main_static_content.py</code> <pre><code>def get_assembly_info(accession: str) -&gt; Dict[str, str]:\n    \"\"\"\n    Retrieve assembly information from the ENA API for a given accession.\n\n    Args:\n        accession (str): The assembly accession number to fetch information for.\n\n    Returns:\n        dict: A dictionary containing assembly attributes such as name, level,\\\n        submitter, and counts.\n    \"\"\"\n    assembly_url = f\"https://www.ebi.ac.uk/ena/browser/api/xml/{accession}\"\n    assembly_xml = requests.get(assembly_url, timeout=10)\n    assembly_dict = xmltodict.parse(assembly_xml.text)\n    assembly_attribs = assembly_dict[\"ASSEMBLY_SET\"][\"ASSEMBLY\"][\"ASSEMBLY_ATTRIBUTES\"][\n        \"ASSEMBLY_ATTRIBUTE\"\n    ]\n\n    return_dict = {}\n\n    # Retrieve specific attributes with error handling\n    return_dict[\"assembly.name\"] = assembly_dict[\"ASSEMBLY_SET\"][\"ASSEMBLY\"].get(\n        \"NAME\", \"\"\n    )\n    return_dict[\"assembly.level\"] = assembly_dict[\"ASSEMBLY_SET\"][\"ASSEMBLY\"].get(\n        \"ASSEMBLY_LEVEL\", \"\"\n    )\n    return_dict[\"assembly.submitter\"] = assembly_dict[\"ASSEMBLY_SET\"][\"ASSEMBLY\"][\n        \"IDENTIFIERS\"\n    ][\"SUBMITTER_ID\"].get(\"@namespace\", \"\")\n\n    # Fetch specific attributes based on tags\n    for attrib_set in assembly_attribs:\n        if attrib_set[\"TAG\"] == \"count-contig\":\n            return_dict[\"contig.count\"] = attrib_set[\"VALUE\"]\n        elif attrib_set[\"TAG\"] == \"scaffold-count\":\n            return_dict[\"scaffold.count\"] = attrib_set[\"VALUE\"]\n        elif attrib_set[\"TAG\"] == \"ENA-LAST-UPDATED\":\n            return_dict[\"assembly.date\"] = attrib_set[\"VALUE\"]\n        elif attrib_set[\"TAG\"] == \"n50\":\n            return_dict[\"scaffold.n50\"] = attrib_set[\"VALUE\"]\n        elif attrib_set[\"TAG\"] == \"contig-n50\":\n            return_dict[\"contig.n50\"] = attrib_set[\"VALUE\"]\n\n    return return_dict\n</code></pre>"},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.mysql_fetch_data","title":"<code>mysql_fetch_data(query, database, host, port, user)</code>","text":"<p>Fetch data from a MySQL database based on a provided query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SQL query to execute.</p> required <code>database</code> <code>str</code> <p>Database name to connect to.</p> required <code>host</code> <code>str</code> <p>Host address of the MySQL server.</p> required <code>port</code> <code>int</code> <p>Port number of the MySQL server.</p> required <code>user</code> <code>str</code> <p>Username for the MySQL server.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>Optional[Tuple]</code> <p>A tuple containing the fetched data.</p> Source code in <code>src/python/ensembl/genes/content/main_static_content.py</code> <pre><code>def mysql_fetch_data(\n    query: str, database: str, host: str, port: int, user: str\n) -&gt; Optional[Tuple]:\n    \"\"\"\n    Fetch data from a MySQL database based on a provided query.\n\n    Args:\n        query (str): SQL query to execute.\n        database (str): Database name to connect to.\n        host (str): Host address of the MySQL server.\n        port (int): Port number of the MySQL server.\n        user (str): Username for the MySQL server.\n\n    Returns:\n        tuple: A tuple containing the fetched data.\n    \"\"\"\n    try:\n        conn = pymysql.connect(\n            host=host, user=user, port=port, database=database.strip()\n        )\n        cursor = conn.cursor()\n        cursor.execute(query)\n        info = cursor.fetchall()\n    except pymysql.Error as err:\n        print(f\"Database error: {err}\")\n        info = None\n    finally:\n        cursor.close()\n        conn.close()\n    return info\n</code></pre>"},{"location":"ensembl/genes/content/main_static_content/#ensembl.genes.content.main_static_content.write_content","title":"<code>write_content(info, out_dir, url_path)</code>","text":"<p>Write assembly and annotation content to HTML files.</p> <p>Parameters:</p> Name Type Description Default <code>info</code> <code>dict</code> <p>Assembly information to be written.</p> required <code>output_dir</code> <code>Path</code> <p>Directory path for output files.</p> required <code>url_path</code> <code>str</code> <p>Name used to title the output files.</p> required Source code in <code>src/python/ensembl/genes/content/main_static_content.py</code> <pre><code>def write_content(info: Dict[str, str], out_dir: Path, url_path: str) -&gt; None:\n    \"\"\"\n    Write assembly and annotation content to HTML files.\n\n    Args:\n        info (dict): Assembly information to be written.\n        output_dir (Path): Directory path for output files.\n        url_path (str): Name used to title the output files.\n    \"\"\"\n    with open(  # pylint: disable=unspecified-encoding\n        out_dir / f\"{url_path}_assembly.html\", \"w\"\n    ) as assembly_out:  # pylint: disable=unspecified-encoding\n        print(\n            f\"&lt;p&gt;The {info['assembly.name']} assembly was submitted by \"\n            f\"{info['assembly.submitter']} and last updated on \"\n            f\"{info['assembly.date']}. The assembly is on the \"\n            f\"{info['assembly.level']} \"\n            f\"level, consisting of {info['contig.count']} contigs assembled into \"\n            f\"{info['scaffold.count']} scaffolds. \"\n            f\"The N50 size is the length such that 50% of the assembled genome lies in \"\n            f\"blocks of the N50 size or longer. \"\n            f\"The N50 length for the contigs is {info['contig.n50']} while the \"\n            f\"scaffold N50 is {info['scaffold.n50']}.&lt;/p&gt;\",\n            file=assembly_out,\n        )\n\n    with open(  # pylint: disable=unspecified-encoding\n        out_dir / f\"{url_path}_annotation.html\", \"w\"\n    ) as annotation_out:  # pylint: disable=unspecified-encoding\n        print(\n            \"&lt;p&gt;Genome annotation was generated using the \"\n            '&lt;a href=\"https://beta.ensembl.org/help/articles/vertebrate-genome-annotation\"&gt;Ensembl vertebrate annotation pipeline&lt;/a&gt;. '  # pylint: disable=line-too-long\n            \"&lt;/p&gt;&lt;p&gt;In accordance with the \"\n            '&lt;a href=\"https://en.wikipedia.org/wiki/Fort_Lauderdale_Agreement\"&gt;Fort Lauderdale Agreement&lt;/a&gt;, please check the publication '  # pylint: disable=line-too-long\n            \"status of the genome/assembly before publishing any genome-wide analyses using these data.&lt;/p&gt;\",  # pylint: disable=line-too-long\n            file=annotation_out,\n        )\n</code></pre>"},{"location":"ensembl/genes/content/main_static_murine_content/","title":"<code>ensembl.genes.content.main_static_murine_content</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content","title":"<code>ensembl.genes.content.main_static_murine_content</code>","text":"<p>Prepare static content files for main release. This script fetches assembly information from a MySQL database and the ENA API, and generates HTML files containing assembly and annotation content.</p>"},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.CORE_QUERY","title":"<code>CORE_QUERY = \"SELECT meta_key, meta_value FROM meta WHERE meta_key IN ('assembly.accession', 'species.url', 'species.strain');\"</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.assembly_info","title":"<code>assembly_info = get_assembly_info(core_dict['assembly.accession'])</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.core_dict","title":"<code>core_dict = {(meta_pair[0]): (meta_pair[1]) for meta_pair in core_meta}</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.core_meta","title":"<code>core_meta = mysql_fetch_data(CORE_QUERY, host=(server_info['server']['db_host']), user=(server_info['server']['db_user']), port=(server_info['server']['db_port']), database=db)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.db","title":"<code>db = args.db_name</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.output_dir","title":"<code>output_dir = Path(args.output_dir)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.parser","title":"<code>parser = argparse.ArgumentParser(description='Prepare static content files for main release')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.server_info","title":"<code>server_info = {'server': {'db_host': args.host, 'db_port': args.port, 'db_user': 'ensro'}}</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.strain","title":"<code>strain = core_dict['species.strain']</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.url_name","title":"<code>url_name = core_dict['species.url']</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.get_assembly_info","title":"<code>get_assembly_info(accession)</code>","text":"<p>Retrieve assembly information from the ENA API for a given accession.</p> <p>Parameters:</p> Name Type Description Default <code>accession</code> <code>str</code> <p>The assembly accession number to fetch information for.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing assembly attributes such as name, level,         submitter, and counts.</p> Source code in <code>src/python/ensembl/genes/content/main_static_murine_content.py</code> <pre><code>def get_assembly_info(accession):\n    \"\"\"\n    Retrieve assembly information from the ENA API for a given accession.\n\n    Args:\n        accession (str): The assembly accession number to fetch information for.\n\n    Returns:\n        dict: A dictionary containing assembly attributes such as name, level, \\\n        submitter, and counts.\n    \"\"\"\n    assembly_url = f\"https://www.ebi.ac.uk/ena/browser/api/xml/{accession}\"\n    assembly_xml = requests.get(assembly_url, timeout=10)\n    assembly_dict = xmltodict.parse(assembly_xml.text)\n    assembly_attribs = assembly_dict[\"ASSEMBLY_SET\"][\"ASSEMBLY\"][\"ASSEMBLY_ATTRIBUTES\"][\n        \"ASSEMBLY_ATTRIBUTE\"\n    ]\n\n    return_dict = {}\n\n    # Retrieve specific attributes with error handling\n    return_dict[\"assembly.name\"] = assembly_dict[\"ASSEMBLY_SET\"][\"ASSEMBLY\"].get(\n        \"NAME\", \"\"\n    )\n    return_dict[\"assembly.level\"] = assembly_dict[\"ASSEMBLY_SET\"][\"ASSEMBLY\"].get(\n        \"ASSEMBLY_LEVEL\", \"\"\n    )\n    return_dict[\"assembly.submitter\"] = assembly_dict[\"ASSEMBLY_SET\"][\"ASSEMBLY\"][\n        \"IDENTIFIERS\"\n    ][\"SUBMITTER_ID\"].get(\"@namespace\", \"\")\n\n    # Fetch specific attributes based on tags\n    for attrib_set in assembly_attribs:\n        if attrib_set[\"TAG\"] == \"count-contig\":\n            return_dict[\"contig.count\"] = attrib_set[\"VALUE\"]\n        elif attrib_set[\"TAG\"] == \"scaffold-count\":\n            return_dict[\"scaffold.count\"] = attrib_set[\"VALUE\"]\n        elif attrib_set[\"TAG\"] == \"ENA-LAST-UPDATED\":\n            return_dict[\"assembly.date\"] = attrib_set[\"VALUE\"]\n        elif attrib_set[\"TAG\"] == \"n50\":\n            return_dict[\"scaffold.n50\"] = attrib_set[\"VALUE\"]\n        elif attrib_set[\"TAG\"] == \"contig-n50\":\n            return_dict[\"contig.n50\"] = attrib_set[\"VALUE\"]\n\n    return return_dict\n</code></pre>"},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.mysql_fetch_data","title":"<code>mysql_fetch_data(query, database, host, port, user)</code>","text":"<p>Fetch data from a MySQL database based on a provided query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SQL query to execute.</p> required <code>database</code> <code>str</code> <p>Database name to connect to.</p> required <code>host</code> <code>str</code> <p>Host address of the MySQL server.</p> required <code>port</code> <code>int</code> <p>Port number of the MySQL server.</p> required <code>user</code> <code>str</code> <p>Username for the MySQL server.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the fetched data.</p> Source code in <code>src/python/ensembl/genes/content/main_static_murine_content.py</code> <pre><code>def mysql_fetch_data(query: str, database, host, port, user):\n    \"\"\"\n    Fetch data from a MySQL database based on a provided query.\n\n    Args:\n        query (str): SQL query to execute.\n        database (str): Database name to connect to.\n        host (str): Host address of the MySQL server.\n        port (int): Port number of the MySQL server.\n        user (str): Username for the MySQL server.\n\n    Returns:\n        tuple: A tuple containing the fetched data.\n    \"\"\"\n    try:\n        conn = pymysql.connect(\n            host=host, user=user, port=port, database=database.strip()\n        )\n        cursor = conn.cursor()\n        cursor.execute(query)\n        info = cursor.fetchall()\n    except pymysql.Error as err:\n        print(f\"Database error: {err}\")\n        info = None\n    finally:\n        cursor.close()\n        conn.close()\n    return info\n</code></pre>"},{"location":"ensembl/genes/content/main_static_murine_content/#ensembl.genes.content.main_static_murine_content.write_content","title":"<code>write_content(info, out_dir, url_path, species_strain)</code>","text":"<p>Write assembly and annotation content to HTML files.</p> <p>Parameters:</p> Name Type Description Default <code>info</code> <code>dict</code> <p>Assembly information to be written.</p> required <code>out_dir</code> <code>Path</code> <p>Directory path for output files.</p> required <code>url_path</code> <code>str</code> <p>Name used to title the output files.</p> required <code>species_strain</code> <code>str</code> <p>Species strain name for the assembly.</p> required Source code in <code>src/python/ensembl/genes/content/main_static_murine_content.py</code> <pre><code>def write_content(info, out_dir, url_path, species_strain):\n    \"\"\"\n    Write assembly and annotation content to HTML files.\n\n    Args:\n        info (dict): Assembly information to be written.\n        out_dir (Path): Directory path for output files.\n        url_path (str): Name used to title the output files.\n        species_strain (str): Species strain name for the assembly.\n    \"\"\"\n    with open(\n        out_dir / f\"{url_path}_assembly.html\", \"w\"\n    ) as assembly_out:  # pylint: disable=unspecified-encoding\n        print(\n            f\"&lt;p&gt;The assembly for {species_strain} was generated as part of \"\n            f'&lt;a href=\"https://www.mousegenomes.org/\"&gt;The Mouse Genomes Project'\n            f\"&lt;/a&gt;, additional species_strain can be found in \"\n            f'&lt;a href=\"https://www.ensembl.org/Mus_musculus/Info/Strains\"&gt;Ensembl&lt;/a&gt;.&lt;/p&gt;'\n            f\"&lt;p&gt;The assembly is on the {info['assembly.level']} \"\n            f\"level, consisting of {info['contig.count']} contigs assembled \"\n            f\"into {info['scaffold.count']} scaffolds. \"\n            f\"The N50 size is the length such that 50% of the assembled genome lies in \"\n            f\"blocks of the N50 size or longer. \"\n            f\"The N50 length for the contigs is {info['contig.n50']} while the \"\n            f\"scaffold N50 is {info['scaffold.n50']}.&lt;/p&gt;\",\n            file=assembly_out,\n        )\n\n    with open(\n        out_dir / f\"{url_path}_annotation.html\", \"w\"\n    ) as annotation_out:  # pylint: disable=unspecified-encoding\n        print(\n            f\"&lt;p&gt;Genome annotation was generated by mapping \"  # pylint: disable=f-string-without-interpolation\n            f'&lt;a href=\"https://www.gencodegenes.org/mouse/release_M30.html\"&gt;GENCODE M30&lt;/a&gt; '\n            f'genes and transcripts via the &lt;a href=\"https://beta.ensembl.org/help/articles/human-genome-automated-annotation\"&gt;Ensembl Human automated annotation system&lt;/a&gt;, supplemented by methods from the '  # pylint: disable=line-too-long\n            f'&lt;a href=\"https://beta.ensembl.org/help/articles/vertebrate-genome-annotation\"&gt;Ensembl vertebrate annotation pipeline&lt;/a&gt;. '  # pylint: disable=line-too-long\n            f\"Mapped GENCODE structures served as the primary evidence with \"\n            f\"gaps in the annotations filled using aligned short-read \"\n            f\"transcriptomic data and full-length transcripts derived from PacBio IsoSeq \"\n            f\"long-read data.\"\n            f\"&lt;/p&gt;&lt;p&gt;In accordance with the \"\n            f'&lt;a href=\"https://en.wikipedia.org/wiki/Fort_Lauderdale_Agreement\"&gt;Fort Lauderdale '\n            f\"Agreement&lt;/a&gt;, please check the publication \"\n            f\"status of the genome/assembly before publishing any genome-wide analyses using \"\n            f\"these data.&lt;/p&gt;\",\n            file=annotation_out,\n        )\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/assign_species_prefix/","title":"<code>ensembl.genes.info_from_registry.assign_species_prefix</code>","text":""},{"location":"ensembl/genes/info_from_registry/assign_species_prefix/#ensembl.genes.info_from_registry.assign_species_prefix","title":"<code>ensembl.genes.info_from_registry.assign_species_prefix</code>","text":"<p>This module handles the assignment of unique species prefixes based on taxon IDs by interacting with the assembly registry and metadata databases.</p>"},{"location":"ensembl/genes/info_from_registry/assign_species_prefix/#ensembl.genes.info_from_registry.assign_species_prefix.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/assign_species_prefix/#ensembl.genes.info_from_registry.assign_species_prefix.create_prefix","title":"<code>create_prefix(existing_prefix, taxon_id, server_info)</code>","text":"<p>Create a new species prefix for a given taxon ID and insert it into the database. It will retry up to 10,000 times to ensure uniqueness.</p> <p>Parameters:</p> Name Type Description Default <code>existing_prefix</code> <code>list[str]</code> <p>A list of existing species prefixes.</p> required <code>taxon_id</code> <code>int</code> <p>The taxon ID for the new prefix.</p> required <code>server_info</code> <code>dict</code> <p>Information about the database server.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If a unique prefix cannot be generated after many attempts.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The newly created species prefix.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/assign_species_prefix.py</code> <pre><code>def create_prefix(existing_prefix: list[str], taxon_id: int, server_info: dict) -&gt; str:\n    \"\"\"Create a new species prefix for a given taxon ID and insert it into the database.\n    It will retry up to 10,000 times to ensure uniqueness.\n\n    Args:\n        existing_prefix (list[str]): A list of existing species prefixes.\n        taxon_id (int): The taxon ID for the new prefix.\n        server_info (dict): Information about the database server.\n\n    Raises:\n        RuntimeError: If a unique prefix cannot be generated after many attempts.\n\n    Returns:\n        str: The newly created species prefix.\n    \"\"\"\n    logger.info(f\"Creating new prefix for taxon ID: {taxon_id}\")\n    conn = pymysql.connect(\n        host=server_info[\"registry\"][\"db_host\"],\n        user=server_info[\"registry\"][\"db_user_w\"],\n        port=server_info[\"registry\"][\"db_port\"],\n        password=server_info[\"registry\"][\"password\"],\n        database=server_info[\"registry\"][\"db_name\"],\n    )\n\n    with conn:\n        for _ in range(10):  # max attempts\n            prefix = generate_random_prefix(existing_prefix)\n            if insert_prefix_into_db(prefix, taxon_id, conn):\n                logger.info(f\"Successfully inserted: {prefix}\")\n                return prefix\n            existing_prefix.append(prefix)  # optimize by adding to \"existing prefixes\"\n    raise RuntimeError(\"Failed to generate unique prefix after many attempts.\")\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/assign_species_prefix/#ensembl.genes.info_from_registry.assign_species_prefix.exiting_prefix","title":"<code>exiting_prefix(server_info)</code>","text":"<p>Get a list of existing species prefixes from the gb assembly registry and metadata databases.</p> <p>Parameters:</p> Name Type Description Default <code>server_info</code> <code>dict</code> <p>Information about the database server.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of existing species prefixes.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/assign_species_prefix.py</code> <pre><code>def exiting_prefix(server_info: dict) -&gt; list[str]:\n    \"\"\"Get a list of existing species prefixes from the gb assembly registry and metadata databases.\n\n    Args:\n        server_info (dict): Information about the database server.\n\n    Returns:\n        list[str]: A list of existing species prefixes.\n    \"\"\"\n    # Getting existing prefix from registry db. To be removed when the registry is updated.\n    prefix_registry_query = f\"SELECT DISTINCT species_prefix FROM assembly ;\"  # pylint: disable=f-string-without-interpolation\n    output_registry = mysql_fetch_data(\n        prefix_registry_query,\n        host=server_info[\"registry\"][\"db_host\"],\n        user=server_info[\"registry\"][\"db_user\"],\n        port=server_info[\"registry\"][\"db_port\"],\n        database=server_info[\"registry\"][\"db_name\"],\n        password=\"\",\n    )\n    # Getting existing prefix from metadata db\n    prefix_metadata_query = f\"SELECT DISTINCT prefix FROM species_prefix ;\"  # pylint: disable=f-string-without-interpolation\n    output_metadata = mysql_fetch_data(\n        prefix_metadata_query,\n        host=server_info[\"registry\"][\"db_host\"],\n        user=server_info[\"registry\"][\"db_user\"],\n        port=server_info[\"registry\"][\"db_port\"],\n        database=server_info[\"registry\"][\"db_name\"],\n        password=\"\",\n    )\n    prefix_list = [\n        list(item.values())[0] for item in list(output_registry) + list(output_metadata)\n    ]\n    existing_prefix = list(set(prefix_list))\n    logger.debug(f\"Num Existing prefix: {len(existing_prefix)}\")\n    return existing_prefix\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/assign_species_prefix/#ensembl.genes.info_from_registry.assign_species_prefix.generate_random_prefix","title":"<code>generate_random_prefix(existing_prefix)</code>","text":"<p>Generate a random species prefix that does not already exist in the provided list.</p> <p>Parameters:</p> Name Type Description Default <code>existing_prefix</code> <code>list[str]</code> <p>A list of existing species prefixes.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A random three/four letter prefix.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/assign_species_prefix.py</code> <pre><code>def generate_random_prefix(existing_prefix: list[str]) -&gt; str:\n    \"\"\"Generate a random species prefix that does not already exist in the provided list.\n\n    Args:\n        existing_prefix (list[str]): A list of existing species prefixes.\n\n    Returns:\n        str: A random three/four letter prefix.\n    \"\"\"\n    letters = string.ascii_uppercase\n    if len(existing_prefix) &gt;= 26**3:\n        logger.info(\"Creating prefix: four random letters\")\n        length = 4\n    else:\n        logger.info(\"Creating prefix: three random letters\")\n        length = 3\n    while True:\n        candidate = \"ENS\" + \"\".join(random.choices(letters, k=length))\n        if candidate not in existing_prefix:\n            return candidate\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/assign_species_prefix/#ensembl.genes.info_from_registry.assign_species_prefix.get_special_cases","title":"<code>get_special_cases()</code>","text":"<p>Retrieve special cases for species prefixes from a JSON file. Returns:     dict: A dictionary mapping taxon IDs to their special species prefixes.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/assign_species_prefix.py</code> <pre><code>def get_special_cases() -&gt; dict[str, str]:\n    \"\"\"Retrieve special cases for species prefixes from a JSON file.\n    Returns:\n        dict: A dictionary mapping taxon IDs to their special species prefixes.\n    \"\"\"\n    enscode = os.environ.get(\"ENSCODE\")\n    if not enscode:\n        raise EnvironmentError(\"Environment variable ENSCODE is not set\")\n    json_path = os.path.join(\n        enscode,\n        \"ensembl-genes\",\n        \"src\",\n        \"python\",\n        \"ensembl\",\n        \"genes\",\n        \"info_from_registry\",\n        \"anno_settings.json\",\n    )\n    with open(json_path, \"r\") as file:  # pylint: disable=unspecified-encoding\n        special_cases = json.load(file)\n    return special_cases\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/assign_species_prefix/#ensembl.genes.info_from_registry.assign_species_prefix.get_species_prefix","title":"<code>get_species_prefix(taxon_id, server_info)</code>","text":"<p>This function retrieves the species prefix from the assembly registry and metadata databases. If the prefix is not found, it creates a new one. There are special cases where the prefix is predefined. - Canis lupus (wolf) -&gt; ENSCAF - Canis lupus familiaris (Domestic dog) -&gt; ENSCAF - Heterocephalus glaber (naked mole rat) -&gt; ENSHGL</p> <p>Parameters:</p> Name Type Description Default <code>taxon_id</code> <code>int</code> <p>lowest taxon id</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the taxon ID is not found.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>Optional[str]</code> <p>unique species prefix that already exist or a new one when no prefix is found.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/assign_species_prefix.py</code> <pre><code>def get_species_prefix(taxon_id: int, server_info: dict) -&gt; Optional[str]:\n    \"\"\"\n    This function retrieves the species prefix from the assembly registry\n    and metadata databases.\n    If the prefix is not found, it creates a new one. There are special cases\n    where the prefix is predefined.\n    - Canis lupus (wolf) -&gt; ENSCAF\n    - Canis lupus familiaris (Domestic dog) -&gt; ENSCAF\n    - Heterocephalus glaber (naked mole rat) -&gt; ENSHGL\n\n    Args:\n        taxon_id (int): lowest taxon id\n\n    Raises:\n        ValueError: If the taxon ID is not found.\n\n    Returns:\n        str: unique species prefix that already exist or a new one when no prefix is found.\n    \"\"\"\n\n    # Special cases\n    special_cases = get_special_cases()\n\n    if str(taxon_id) in special_cases:\n        logger.info(f\"The prefix is a special case for taxon ID: {taxon_id}\")\n        species_prefix = special_cases.get(str(taxon_id))\n    else:\n\n        logger.info(f\"Searching for prefix for taxon ID: {taxon_id}\")\n\n        prefix_registry_query = (\n            f\"SELECT DISTINCT species_prefix FROM assembly WHERE taxonomy = {taxon_id}\"\n        )\n        output_registry = mysql_fetch_data(\n            prefix_registry_query,\n            host=server_info[\"registry\"][\"db_host\"],\n            user=server_info[\"registry\"][\"db_user\"],\n            port=server_info[\"registry\"][\"db_port\"],\n            database=\"gb_assembly_registry\",\n            password=\"\",\n        )\n        if output_registry:\n            logger.info(f\"Prefix found in old registry: {output_registry}\")\n\n        prefix_metadata_query = f\"SELECT DISTINCT prefix FROM species_prefix \\\n            WHERE lowest_taxon_id = {taxon_id}\"\n        output_metadata = mysql_fetch_data(\n            prefix_metadata_query,\n            host=server_info[\"registry\"][\"db_host\"],\n            user=server_info[\"registry\"][\"db_user\"],\n            port=server_info[\"registry\"][\"db_port\"],\n            database=server_info[\"registry\"][\"db_name\"],\n            password=\"\",\n        )\n        if output_metadata:\n            logger.info(f\"Prefix found in new metadata registry: {output_metadata}\")\n\n        # Combine output and get list of unique values\n        output = [\n            list(item.values())[0]\n            for item in list(output_registry) + list(output_metadata)\n        ]\n        prefix_list = list(set(output))\n\n        # no prefix, create new prefix\n        if len(prefix_list) == 0:\n            logger.info(f\"Creating a new prefix for taxon ID: {taxon_id}\")\n            existing_prefix = exiting_prefix(server_info)\n            species_prefix = create_prefix(existing_prefix, taxon_id, server_info)\n\n        # unique prefix detected\n        elif len(prefix_list) == 1:\n            logger.info(f\"Unique prefix detected for taxon ID: {taxon_id}\")\n            species_prefix = str(prefix_list[0])\n            logger.info(f\"Saving exting prefix {species_prefix} in new registry\")\n            # Open a new connection\n            conn = pymysql.connect(\n                host=server_info[\"registry\"][\"db_host\"],\n                user=server_info[\"registry\"][\"db_user_w\"],\n                port=server_info[\"registry\"][\"db_port\"],\n                password=server_info[\"registry\"][\"password\"],\n                database=server_info[\"registry\"][\"db_name\"],\n            )\n\n            if insert_prefix_into_db(\n                species_prefix, taxon_id, conn, store_new_registry=True\n            ):\n                logger.info(f\"Successfully inserted: {species_prefix}\")\n                conn.close()\n\n        else:\n            raise ValueError(\n                f\"The taxon {taxon_id} is already registered and multiple prefix \\\n                    were detected: {prefix_list}\"\n            )\n\n    return species_prefix\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/assign_species_prefix/#ensembl.genes.info_from_registry.assign_species_prefix.insert_prefix_into_db","title":"<code>insert_prefix_into_db(prefix, taxon_id, conn, store_new_registry=False)</code>","text":"<p>Insert a new species prefix into the database. Args:     prefix (str): The species prefix to insert.     taxon_id (int): The lowest taxon ID associated with the prefix.     conn (pymysql.connections.Connection): The database connection object.     store_new_registry (bool): Whether to allow duplicated exception if     the prefix already exists in the database. Returns:     bool: True if the prefix was successfully inserted, False if it already exists. Raises:     pymysql.err.IntegrityError: If there is a duplicate entry for the prefix.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/assign_species_prefix.py</code> <pre><code>def insert_prefix_into_db(\n    prefix: str,\n    taxon_id: int,\n    conn: pymysql.connections.Connection,\n    store_new_registry: bool = False,\n) -&gt; bool:\n    \"\"\"Insert a new species prefix into the database.\n    Args:\n        prefix (str): The species prefix to insert.\n        taxon_id (int): The lowest taxon ID associated with the prefix.\n        conn (pymysql.connections.Connection): The database connection object.\n        store_new_registry (bool): Whether to allow duplicated exception if\n        the prefix already exists in the database.\n    Returns:\n        bool: True if the prefix was successfully inserted, False if it already exists.\n    Raises:\n        pymysql.err.IntegrityError: If there is a duplicate entry for the prefix.\n    \"\"\"\n    logger.info(f\"Inserting prefix {prefix} for taxon id {taxon_id}\")\n    try:\n        with conn.cursor() as cursor:\n            query = (\n                \"INSERT INTO species_prefix (lowest_taxon_id, prefix) \"\n                \"VALUES (%s, %s);\"\n            )\n            cursor.execute(query, (taxon_id, prefix))\n        return True\n    except pymysql.err.IntegrityError as err:\n        if err.args[0] == 1062:\n            if store_new_registry:\n                logger.info(\n                    f\"Existing prefix {prefix} already stored in the new registry. Allow exception\"\n                )\n                return True\n            return False\n        raise\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/assign_stable_space/","title":"<code>ensembl.genes.info_from_registry.assign_stable_space</code>","text":""},{"location":"ensembl/genes/info_from_registry/assign_stable_space/#ensembl.genes.info_from_registry.assign_stable_space","title":"<code>ensembl.genes.info_from_registry.assign_stable_space</code>","text":"<p>This module manages the assignment of stable space IDs for genomic assemblies</p>"},{"location":"ensembl/genes/info_from_registry/assign_stable_space/#ensembl.genes.info_from_registry.assign_stable_space.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/assign_stable_space/#ensembl.genes.info_from_registry.assign_stable_space.assign_stable_id","title":"<code>assign_stable_id(taxon_id, gca_accession, assembly_id, server_info)</code>","text":"<p>Assign a stable space ID for a given taxon and GCA accession.</p> <p>Parameters:</p> Name Type Description Default <code>taxon_id</code> <code>int</code> <p>The taxon identifier for which to assign a stable space ID.</p> required <code>gca_accession</code> <code>str</code> <p>The GCA accession number for the assembly.</p> required <code>assembly_id</code> <code>int</code> <p>The assembly identifier.</p> required <code>server_info</code> <code>dict</code> <p>The server information for database connection.</p> required <p>Returns:</p> Type Description <code>tuple[bool, int, int] | tuple[bool, None, None]</code> <p>tuple[bool, int|None, int|None]: A tuple containing a success flag and             the assigned stable space ID or None if failed.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/assign_stable_space.py</code> <pre><code>def assign_stable_id(\n    taxon_id: int, gca_accession: str, assembly_id: int, server_info: dict\n) -&gt; tuple[bool, int, int] | tuple[bool, None, None]:\n    \"\"\"Assign a stable space ID for a given taxon and GCA accession.\n\n    Args:\n        taxon_id (int): The taxon identifier for which to assign a stable space ID.\n        gca_accession (str): The GCA accession number for the assembly.\n        assembly_id (int): The assembly identifier.\n        server_info (dict): The server information for database connection.\n\n    Returns:\n        tuple[bool, int|None, int|None]: A tuple containing a success flag and \\\n            the assigned stable space ID or None if failed.\n    \"\"\"\n\n    stable_space_id = stable_space_per_taxon(taxon_id, server_info)\n    # Check if stable space range exists\n    logger.info(f\"Check if stable space range exists {stable_space_id}\")\n    stable_space_start = stable_space_range(stable_space_id, server_info)\n\n    if stable_space_start is not False:\n        logger.info(\n            f\"Assigned stable space ID {stable_space_id} for {gca_accession}\\\n                and taxon ID {taxon_id}.\"\n        )\n\n        insert_query = f\"\"\"INSERT INTO stable_space_species_log (stable_space_id, \\\n            lowest_taxon_id, gca_accession, assembly_id) \n            VALUES ({stable_space_id}, {taxon_id}, '{gca_accession}', {assembly_id});\n            \"\"\"\n        conn = pymysql.connect(\n            host=server_info[\"registry\"][\"db_host\"],\n            user=server_info[\"registry\"][\"db_user_w\"],\n            port=server_info[\"registry\"][\"db_port\"],\n            password=server_info[\"registry\"][\"password\"],\n            database=server_info[\"registry\"][\"db_name\"],\n        )\n\n        if insert_to_db(\n            insert_query, conn, store_new_registry=True\n        ):  # pylint: disable=no-else-return\n            logger.info(\n                f\"Successfully inserted stable space ID {stable_space_id} for GCA {gca_accession}.\"\n            )\n            conn.close()\n            return True, stable_space_id, stable_space_start\n        else:\n            logger.error(\n                f\"Failed to insert stable space ID {stable_space_id} for GCA {gca_accession}.\"\n            )\n            return False, None, None\n    else:\n        logger.error(\n            f\"Failed to assign stable space ID {stable_space_id} for GCA {gca_accession}.\"\n        )\n        return False, None, None\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/assign_stable_space/#ensembl.genes.info_from_registry.assign_stable_space.get_stable_space","title":"<code>get_stable_space(taxon_id, gca_accession, assembly_id, server_info)</code>","text":"<p>Get the stable space ID for a given taxon and GCA accession.</p> <p>Parameters:</p> Name Type Description Default <code>taxon_id</code> <code>int</code> <p>The taxon identifier for which to find the stable space ID.</p> required <code>gca_accession</code> <code>str</code> <p>The GCA accession number for the assembly.</p> required <code>assembly_id</code> <code>int</code> <p>The assembly identifier.</p> required <code>server_info</code> <code>dict</code> <p>The server information for database connection.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>assigned stable space ID or existing one if already assigned.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/assign_stable_space.py</code> <pre><code>def get_stable_space(\n    taxon_id: int, gca_accession: str, assembly_id: int, server_info: dict\n) -&gt; int:\n    \"\"\"Get the stable space ID for a given taxon and GCA accession.\n\n    Args:\n        taxon_id (int): The taxon identifier for which to find the stable space ID.\n        gca_accession (str): The GCA accession number for the assembly.\n        assembly_id (int): The assembly identifier.\n        server_info (dict): The server information for database connection.\n\n    Returns:\n        int: assigned stable space ID or existing one if already assigned.\n    \"\"\"\n\n    # Check if GCA already has assigned a stable space\n    logger.info(f\"Check if {gca_accession} already has assigned a stable space\")\n    space_gca_query = f\"SELECT stable_space_species_log.stable_space_id, \\\n        stable_space.stable_space_start FROM stable_space_species_log JOIN stable_space \\\n            ON stable_space.stable_space_id = stable_space_species_log.stable_space_id  \\\n                WHERE stable_space_species_log.gca_accession = '{gca_accession}';\"\n    output_query = mysql_fetch_data(\n        space_gca_query,\n        host=server_info[\"registry\"][\"db_host\"],\n        user=server_info[\"registry\"][\"db_user\"],\n        port=server_info[\"registry\"][\"db_port\"],\n        database=server_info[\"registry\"][\"db_name\"],\n        password=\"\",\n    )\n\n    if output_query:  # pylint: disable=no-else-return\n        stable_space_id = output_query[0].get(\"stable_space_id\")\n        stable_space_start = output_query[0].get(\"stable_space_start\")\n        logger.info(\n            f\"Stable space {stable_space_id} already assigned for GCA {gca_accession}.\"\n        )\n        return stable_space_start\n\n    else:\n        logger.info(\n            f\"No stable space found for assembly {gca_accession}. Checking taxon ID \\\n                {taxon_id} for existing stable space.\"\n        )\n\n        success = False\n        while not success:\n            logger.info(\n                f\"Assigning stable space for taxon ID {taxon_id} and {gca_accession}.\"\n            )\n            success, stable_space_id, stable_space_start = assign_stable_id(\n                taxon_id, gca_accession, assembly_id, server_info\n            )\n\n        return int(stable_space_start)\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/assign_stable_space/#ensembl.genes.info_from_registry.assign_stable_space.insert_to_db","title":"<code>insert_to_db(insert_query, conn, store_new_registry)</code>","text":"<p>Insert data into the database and handle duplicate entries.</p> <p>Parameters:</p> Name Type Description Default <code>insert_query</code> <code>_type_</code> <p>SQL insert query string.</p> required <code>conn</code> <code>Connection</code> <p>Database connection object.</p> required <code>store_new_registry</code> <code>bool</code> <p>Flag to indicate handling of duplicate entries.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if insertion is successful or duplicate is allowed, False otherwise.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/assign_stable_space.py</code> <pre><code>def insert_to_db(\n    insert_query, conn: pymysql.connections.Connection, store_new_registry: bool\n) -&gt; bool:\n    \"\"\"Insert data into the database and handle duplicate entries.\n\n    Args:\n        insert_query (_type_): SQL insert query string.\n        conn (pymysql.connections.Connection): Database connection object.\n        store_new_registry (bool): Flag to indicate handling of duplicate entries.\n\n    Returns:\n        bool: _True_ if insertion is successful or duplicate is allowed, _False_ otherwise.\n    \"\"\"\n    logger.info(f\"Inserting data: {insert_query}\")\n    try:\n        with conn.cursor() as cursor:\n            cursor.execute(insert_query)\n        return True\n    except pymysql.err.IntegrityError as e:\n        if e.args[0] == 1062:\n            if store_new_registry:  # pylint: disable=no-else-return\n                logger.info(\n                    \"Duplicate entry found, but store_new_registry is True. Report as success.\"\n                )\n                return True\n            else:\n                return False\n        raise\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/assign_stable_space/#ensembl.genes.info_from_registry.assign_stable_space.stable_space_per_taxon","title":"<code>stable_space_per_taxon(taxon_id, server_info)</code>","text":"<p>Get the next stable space ID for a given taxon.</p> <p>Parameters:</p> Name Type Description Default <code>taxon_id</code> <code>int</code> <p>The taxon identifier for which to find the stable space ID.</p> required <code>server_info</code> <code>dict</code> <p>The server information for database connection.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The next available stable space ID.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/assign_stable_space.py</code> <pre><code>def stable_space_per_taxon(taxon_id: int, server_info: dict) -&gt; int:\n    \"\"\"Get the next stable space ID for a given taxon.\n\n    Args:\n        taxon_id (int): The taxon identifier for which to find the stable space ID.\n        server_info (dict): The server information for database connection.\n\n    Returns:\n        int: The next available stable space ID.\n    \"\"\"\n    logger.info(f\"Get the next stable space ID for taxon ID {taxon_id}\")\n    space_query = f\"SELECT MAX(stable_space_id) as max_stable_id \\\n        FROM stable_space_species_log WHERE lowest_taxon_id = {taxon_id};\"\n    output_query = mysql_fetch_data(\n        space_query,\n        host=server_info[\"registry\"][\"db_host\"],\n        user=server_info[\"registry\"][\"db_user\"],\n        port=server_info[\"registry\"][\"db_port\"],\n        database=server_info[\"registry\"][\"db_name\"],\n        password=\"\",\n    )\n\n    stable_space_tmp = output_query[0].get(\"max_stable_id\", None)\n\n    ####################\n    # remove when all pipelines have moved to the new registry:\n    old_stable_space_info = get_old_stable_space_info(taxon_id, server_info)\n    ####################\n\n    if old_stable_space_info is None:\n        if stable_space_tmp is None:\n            stable_space_id = 1\n            logger.info(\n                f\"No stable space found for taxon ID {taxon_id}. \"\n                f\"Assigning new stable space ID {stable_space_id}.\"\n            )\n        else:\n            stable_space_id = stable_space_tmp + 1\n            logger.info(\n                f\"No old stable space for taxon ID {taxon_id}. \"\n                f\"Using tmp value {stable_space_tmp}, assigning new ID {stable_space_id}.\"\n            )\n\n    else:  # old_stable_space_info is not None\n        if stable_space_tmp is None:\n            stable_space_id = old_stable_space_info + 1\n            logger.info(\n                f\"Found old stable space {old_stable_space_info} for taxon ID {taxon_id}. \"\n                f\"Assigning new ID {stable_space_id}.\"\n            )\n        elif stable_space_tmp == old_stable_space_info:\n            stable_space_id = stable_space_tmp + 1\n            logger.info(\n                f\"Stable space {stable_space_tmp} matches old record for taxon ID {taxon_id}. \"\n                f\"Assigning new ID {stable_space_id}.\"\n            )\n        else:\n            msg = (\n                f\"Conflicting stable space for taxon ID {taxon_id}: \"\n                f\"{old_stable_space_info} != {stable_space_tmp}\"\n            )\n            logger.error(msg)\n            raise Exception(msg)  # pylint: disable=broad-exception-raised\n\n    return stable_space_id\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/assign_stable_space/#ensembl.genes.info_from_registry.assign_stable_space.stable_space_range","title":"<code>stable_space_range(stable_space_id, server_info)</code>","text":"<p>Check if a stable space range exists for the given stable space ID.</p> <p>Parameters:</p> Name Type Description Default <code>stable_space_id</code> <code>int</code> <p>The stable space ID to check.</p> required <code>server_info</code> <code>dict</code> <p>The server information for database connection.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the stable space range exists, False otherwise.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/assign_stable_space.py</code> <pre><code>def stable_space_range(stable_space_id: int, server_info: dict) -&gt; bool:\n    \"\"\"Check if a stable space range exists for the given stable space ID.\n\n    Args:\n        stable_space_id (int): The stable space ID to check.\n        server_info (dict): The server information for database connection.\n\n    Returns:\n        bool: True if the stable space range exists, False otherwise.\n    \"\"\"\n    logger.info(f\"Get stable space renage for {stable_space_id}\")\n    query = f\"SELECT * FROM stable_space WHERE stable_space_id = '{stable_space_id}';\"\n    output_query = mysql_fetch_data(\n        query,\n        host=server_info[\"registry\"][\"db_host\"],\n        user=server_info[\"registry\"][\"db_user\"],\n        port=server_info[\"registry\"][\"db_port\"],\n        database=server_info[\"registry\"][\"db_name\"],\n        password=\"\",\n    )\n\n    if output_query:  # pylint: disable=no-else-return\n        logger.info(\n            f\"Stable space ID {stable_space_id} already exists with range: {output_query[0]}.\"\n        )\n        return True\n\n    else:\n        logger.info(\n            f\"No existing stable space range found for ID {stable_space_id}. \\\n                Creating a new range space.\"\n        )\n        previous_space_id = stable_space_id - 1\n        query = f\"\"\"SELECT * FROM stable_space WHERE stable_space_id = '{previous_space_id}';\"\"\"\n        output_query = mysql_fetch_data(\n            query,\n            host=server_info[\"registry\"][\"db_host\"],\n            user=server_info[\"registry\"][\"db_user\"],\n            port=server_info[\"registry\"][\"db_port\"],\n            database=server_info[\"registry\"][\"db_name\"],\n            password=\"\",\n        )\n        logger.info(\n            f\"Output query for previous stable space ID {previous_space_id}: {output_query}\"\n        )\n\n        if output_query:\n            new_start = (\n                output_query[0].get(\"stable_space_end\") + 1\n            )  # Increment the end of the previous stable space by 1\n            new_end = new_start + 4999999\n            logger.info(\n                f\"New stable space range for ID {stable_space_id} will be \\\n                    from {new_start} to {new_end}.\"\n            )\n\n            insert_query = f\"INSERT INTO stable_space (stable_space_id, \\\n                stable_space_start, stable_space_end) VALUES ({stable_space_id},\\\n                    {new_start}, {new_end});\"\n            conn = pymysql.connect(\n                host=server_info[\"registry\"][\"db_host\"],\n                user=server_info[\"registry\"][\"db_user_w\"],\n                port=server_info[\"registry\"][\"db_port\"],\n                password=server_info[\"registry\"][\"password\"],\n                database=server_info[\"registry\"][\"db_name\"],\n            )\n\n            if insert_to_db(\n                insert_query, conn, store_new_registry=True\n            ):  # pylint: disable=no-else-return\n                logger.info(\n                    f\"Successfully created stable space range for ID {stable_space_id}.\"\n                )\n                conn.close()\n                return new_start\n            else:  # pylint: disable=no-else-return\n                logger.error(\n                    f\"Failed to insert stable space range for ID {stable_space_id}.\"\n                )\n                return False\n        else:\n            logger.error(\n                f\"Failed to create stable space range for ID {stable_space_id}. \\\n                    Previous space ID {previous_space_id} not found.\"\n            )\n            return False\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/build_anno_commands/","title":"<code>ensembl.genes.info_from_registry.build_anno_commands</code>","text":""},{"location":"ensembl/genes/info_from_registry/build_anno_commands/#ensembl.genes.info_from_registry.build_anno_commands","title":"<code>ensembl.genes.info_from_registry.build_anno_commands</code>","text":"<p>Build command-line strings for genome annotation and repeat analysis.</p>"},{"location":"ensembl/genes/info_from_registry/build_anno_commands/#ensembl.genes.info_from_registry.build_anno_commands.build_annotation_commands","title":"<code>build_annotation_commands(core_adaptor, output_params, anno_settings, settings)</code>","text":"<p>Construct and store command-line strings for genome annotation and repeat analysis.</p> <p>This function builds two command-line strings based on the provided configuration: - <code>anno_commandline</code>: full annotation pipeline - <code>anno_red_commandline</code>: repeat and masking pipeline</p> <p>The resulting command strings are stored in the <code>output_params</code> dictionary under the keys \"anno_commandline\" and \"anno_red_commandline\".</p> <p>Parameters:</p> Name Type Description Default <code>core_adaptor</code> <code>dict</code> <p>Contains database connection info with keys: 'dbname', 'host', 'port', 'user', 'pass'.</p> required <code>output_params</code> <code>dict</code> <p>Dictionary where input/output file paths and directories are specified. The final command strings are added here.</p> required <code>anno_settings</code> <code>dict</code> <p>Annotation settings such as number of threads and diamond validation DB path.</p> required <code>settings</code> <code>dict</code> <p>General pipeline settings, including repeat library usage.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>Modifies <code>output_params</code> in place by adding two command strings.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/build_anno_commands.py</code> <pre><code>def build_annotation_commands(\n    core_adaptor: dict, output_params: dict, anno_settings: dict, settings: dict\n) -&gt; None:\n    \"\"\"\n    Construct and store command-line strings for genome annotation and repeat analysis.\n\n    This function builds two command-line strings based on the provided configuration:\n    - `anno_commandline`: full annotation pipeline\n    - `anno_red_commandline`: repeat and masking pipeline\n\n    The resulting command strings are stored in the `output_params` dictionary under\n    the keys \"anno_commandline\" and \"anno_red_commandline\".\n\n    Args:\n        core_adaptor (dict): Contains database connection info with keys:\n            'dbname', 'host', 'port', 'user', 'pass'.\n        output_params (dict): Dictionary where input/output file paths and\n            directories are specified. The final command strings are added here.\n        anno_settings (dict): Annotation settings such as number of threads and\n            diamond validation DB path.\n        settings (dict): General pipeline settings, including repeat library usage.\n\n    Returns:\n        None: Modifies `output_params` in place by adding two command strings.\n    \"\"\"\n\n    get = lambda k: output_params.get(\n        k, \"\"\n    )  # Short helper #pylint: disable=unnecessary-lambda-assignment\n\n    anno_commandline = (\n        f\" --genome_file {get('reheadered_toplevel_genome_file')}\"\n        f\" --db_details {core_adaptor['dbname']},{core_adaptor['host']},\\\n            {core_adaptor['port']},{core_adaptor['user']},{core_adaptor['pass']}\"\n        f\" --output_dir {get('output_path')}\"\n        f\" --short_read_fastq_dir {get('short_read_dir')}\"\n        f\" --long_read_fastq_dir {get('long_read_dir')}\"\n        f\" --max_intron_length {get('max_intron_length')}\"\n        f\" --protein_file {get('protein_file')}\"\n        f\" --busco_protein_file {get('busco_protein_file')}\"\n        f\" --rfam_accessions_file {get('rfam_accessions_file')}\"\n        f\" --num_threads {anno_settings['num_threads']}\"\n    )\n\n    if settings.get(\"use_existing_repeatmodeler_library\"):\n        anno_commandline += (\n            f\" --repeatmasker_library {settings['use_existing_repeatmodeler_library']}\"\n        )\n\n    if anno_settings.get(\"diamond_validation_db\"):\n        anno_commandline += (\n            f\" --diamond_validation_db {anno_settings['diamond_validation_db']}\"\n        )\n\n    if anno_settings.get(\"validation_type\"):\n        anno_commandline += f\" --validation_type {anno_settings['validation_type']}\"\n\n    anno_commandline += \" --run_full_annotation --load_to_ensembl_db\"\n\n    anno_red_commandline = (\n        f\" --genome_file {get('reheadered_toplevel_genome_file')}\"\n        f\" --db_details {core_adaptor['dbname']},{core_adaptor['host']},\\\n            {core_adaptor['port']},{core_adaptor['user']},{core_adaptor['pass']}\"\n        f\" --output_dir {get('output_path')}\"\n        f\" --num_threads {get('num_threads')}\"\n        \" --run_masking --run_repeats --run_simple_features --load_to_ensembl_db\"\n    )\n\n    # Add both commands back into the params dict\n    output_params[\"anno_commandline\"] = anno_commandline\n    output_params[\"anno_red_commandline\"] = anno_red_commandline\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/check_if_annotated/","title":"<code>ensembl.genes.info_from_registry.check_if_annotated</code>","text":""},{"location":"ensembl/genes/info_from_registry/check_if_annotated/#ensembl.genes.info_from_registry.check_if_annotated","title":"<code>ensembl.genes.info_from_registry.check_if_annotated</code>","text":"<p>check_if_annotated.py</p> <p>This module defines a function to verify if a given genome assembly accession is already annotated in the genebuild registry. It logs annotation status and raises an error if any assembly has already been annotated.</p>"},{"location":"ensembl/genes/info_from_registry/check_if_annotated/#ensembl.genes.info_from_registry.check_if_annotated.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/check_if_annotated/#ensembl.genes.info_from_registry.check_if_annotated.check_if_annotated","title":"<code>check_if_annotated(assembly_accession, server_info)</code>","text":"<p>Check if a genome assembly is already annotated in the genebuild registry.</p>"},{"location":"ensembl/genes/info_from_registry/check_if_annotated/#ensembl.genes.info_from_registry.check_if_annotated.check_if_annotated--parameters","title":"Parameters:","text":"<p>assembly_accession : str     The GCA accession of the assembly to check (e.g., \"GCA_000001405.28\").</p> dict <p>Dictionary containing server connection details, with a 'registry' key pointing to another dict with the following keys:     - db_host : str     - db_user : str     - db_port : int     - db_name : str</p>"},{"location":"ensembl/genes/info_from_registry/check_if_annotated/#ensembl.genes.info_from_registry.check_if_annotated.check_if_annotated--raises","title":"Raises:","text":"<p>RuntimeError     If the given assembly accession is already present in the registry.</p>"},{"location":"ensembl/genes/info_from_registry/check_if_annotated/#ensembl.genes.info_from_registry.check_if_annotated.check_if_annotated--returns","title":"Returns:","text":"<p>None</p> Source code in <code>src/python/ensembl/genes/info_from_registry/check_if_annotated.py</code> <pre><code>def check_if_annotated(\n    assembly_accession: str, server_info: Dict[str, Dict[str, Any]]\n) -&gt; None:\n    \"\"\"\n    Check if a genome assembly is already annotated in the genebuild registry.\n\n    Parameters:\n    ----------\n    assembly_accession : str\n        The GCA accession of the assembly to check (e.g., \"GCA_000001405.28\").\n\n    server_info : dict\n        Dictionary containing server connection details, with a 'registry' key\n        pointing to another dict with the following keys:\n            - db_host : str\n            - db_user : str\n            - db_port : int\n            - db_name : str\n\n    Raises:\n    ------\n    RuntimeError\n        If the given assembly accession is already present in the registry.\n\n    Returns:\n    -------\n    None\n    \"\"\"\n\n    registry_query = \"\"\"\n        SELECT \n            gca_accession, \n            gb_status, \n            genebuilder\n        FROM genebuild_status \n        WHERE gca_accession =  %s\n    \"\"\"  # pylint: disable=f-string-without-interpolation\n\n    registry_rows = mysql_fetch_data(\n        registry_query,\n        host=server_info[\"registry\"][\"db_host\"],\n        user=server_info[\"registry\"][\"db_user\"],\n        port=server_info[\"registry\"][\"db_port\"],\n        database=server_info[\"registry\"][\"db_name\"],\n        password=\"\",\n        params=(assembly_accession,),\n    )\n\n    if registry_rows:\n        for row in registry_rows:\n            gca = row.get(\"gca_accession\")\n            gb_status = row.get(\"gb_status\")\n            genebuilder = row.get(\"genebuilder\")\n            logger.error(f\"\\n Annotation already exists for GCA: {gca}\")\n            logger.error(f\"   Status     : {gb_status}\")\n            logger.error(f\"   Genebuilder: {genebuilder}\")\n        raise RuntimeError(\n            \"Terminating: One or more assemblies are already annotated.\\\n                Please set current_genebuild to 1 in user_settings.json if you wish to proceed.\"\n        )\n\n    logger.info(\"Start check complete: %s\", assembly_accession)\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/check_stable_space_old_registry/","title":"<code>ensembl.genes.info_from_registry.check_stable_space_old_registry</code>","text":""},{"location":"ensembl/genes/info_from_registry/check_stable_space_old_registry/#ensembl.genes.info_from_registry.check_stable_space_old_registry","title":"<code>ensembl.genes.info_from_registry.check_stable_space_old_registry</code>","text":"<p>check_stable_space_from_old_registry.py</p> <p>This module gets legacy stable id from old registry. Module will be deprecated when all pipelines have moved to the new registry. It's main functions is to facilitate using the new registry to start anno runs.</p>"},{"location":"ensembl/genes/info_from_registry/check_stable_space_old_registry/#ensembl.genes.info_from_registry.check_stable_space_old_registry.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/check_stable_space_old_registry/#ensembl.genes.info_from_registry.check_stable_space_old_registry.get_old_stable_space_info","title":"<code>get_old_stable_space_info(taxon_id, server_info)</code>","text":"<p>Get the stable space that has been assigned to old registry.</p> <p>Parameters:</p> Name Type Description Default <code>taxon_id</code> <code>int</code> <p>The taxon identifier for which to find the stable space ID.</p> required <code>server_info</code> <code>dict</code> <p>The server information for database connection.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>Optional[int]</code> <p>Assigned stable space.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/check_stable_space_old_registry.py</code> <pre><code>def get_old_stable_space_info(\n    taxon_id: int, server_info: Dict[str, Dict[str, Any]]\n) -&gt; Optional[int]:\n    \"\"\"Get the stable space that has been assigned to old registry.\n\n    Args:\n        taxon_id (int): The taxon identifier for which to find the stable space ID.\n        server_info (dict): The server information for database connection.\n\n    Returns:\n        int: Assigned stable space.\n    \"\"\"\n    logger.info(f\"Check if taxon ID {taxon_id} has stable space in old registry\")\n    space_query = (\n        f\"SELECT MAX(stable_id_space_id) as old_stable_id \"\n        f\"FROM assembly \"\n        f\"WHERE taxonomy = {taxon_id};\"\n    )\n\n    output_query = mysql_fetch_data(\n        space_query,\n        host=server_info[\"registry\"][\"db_host\"],\n        user=server_info[\"registry\"][\"db_user\"],\n        port=server_info[\"registry\"][\"db_port\"],\n        database=\"gb_assembly_registry\",\n        password=\"\",\n    )\n\n    old_stable_id = output_query[0].get(\"max_stable_id\", None)\n\n    if old_stable_id is None:\n        logger.info(f\"Stable space not found in old registry for taxon ID {taxon_id}.\")\n\n    logger.info(\n        f\"Max stable space in the old registry for taxon ID {taxon_id} is {old_stable_id}.\"\n    )\n\n    return old_stable_id\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/create_config/","title":"<code>ensembl.genes.info_from_registry.create_config</code>","text":""},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config","title":"<code>ensembl.genes.info_from_registry.create_config</code>","text":"<p>create_config.py</p> <p>This module handles copying and editing Ensembl Hive pipeline configuration files based on runtime settings. It supports substituting key pipeline parameters like user credentials, pipeline name, and release version.</p> <p>Functions: - copy_config: Copies the specified pipeline config file to the working directory. - edit_config: Edits configuration values in the copied file using the provided settings.</p> Example usage <p>settings = {     \"config\": \"MyConfig.pm\",     \"base_output_dir\": \"/my/output/path\",     \"current_genebuild\": \"my_genebuild_104\",     \"dbowner\": \"my_db_user\",     \"pipeline_name\": \"my_pipeline\",     \"password\": \"secure_pw\",     \"user\": \"readonly_user\",     \"user_r\": \"reader_user\",     \"release_number\": \"104\" } edit_config(settings)</p>"},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config.copy_config","title":"<code>copy_config(settings, info_dict, pipeline)</code>","text":"<p>Copies a configuration file from the ENSCODE environment into a local output directory.</p>"},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config.copy_config--parameters","title":"Parameters:","text":"<p>settings : dict     Dictionary that must contain:         - 'config': str, filename of the config (e.g., 'MyConfig.pm')         - 'base_output_dir': str, path where the config will be copied</p>"},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config.copy_config--returns","title":"Returns:","text":"<p>str     Path to the copied local config file.</p>"},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config.copy_config--raises","title":"Raises:","text":"<p>RuntimeError     If the file cannot be copied for any reason (e.g., file not found, permissions).</p> Source code in <code>src/python/ensembl/genes/info_from_registry/create_config.py</code> <pre><code>def copy_config(\n    settings: Dict[str, Any], info_dict: Dict[str, Any], pipeline: str\n) -&gt; str:\n    \"\"\"\n    Copies a configuration file from the ENSCODE environment into a local output directory.\n\n    Parameters:\n    ----------\n    settings : dict\n        Dictionary that must contain:\n            - 'config': str, filename of the config (e.g., 'MyConfig.pm')\n            - 'base_output_dir': str, path where the config will be copied\n\n    Returns:\n    -------\n    str\n        Path to the copied local config file.\n\n    Raises:\n    ------\n    RuntimeError\n        If the file cannot be copied for any reason (e.g., file not found, permissions).\n    \"\"\"\n\n    original_config = os.path.join(\n        os.environ.get(\"ENSCODE\"),\n        \"ensembl-analysis\",\n        \"modules\",\n        \"Bio\",\n        \"EnsEMBL\",\n        \"Analysis\",\n        \"Hive\",\n        \"Config\",\n        settings[\"config\"],\n    )\n\n    if pipeline == \"anno\":\n        anno_parent = str(Path(info_dict[\"output_path\"]).parent)\n        local_config = os.path.join(anno_parent, settings[\"config\"])\n    elif pipeline == \"main\":\n        local_config = os.path.join(info_dict[\"output_path\"], settings[\"config\"])\n    else:\n        raise ValueError(\n            f\"Unknown pipeline type: {pipeline}. Can't copy config. Please check taxon ID.\"\n        )\n\n    try:\n        shutil.copy2(original_config, local_config)\n        logging.info(f\"Copied file from {original_config} to {local_config}\")\n    except Exception as e:\n        raise RuntimeError(f\"Error copying file: {e}\")\n\n    return local_config\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config.edit_config_anno","title":"<code>edit_config_anno(anno_settings, settings, info_dict, pipeline, server_settings)</code>","text":"<p>Edits specific parameter values in a copied Ensembl Hive config file.</p> <p>The function performs in-place substitution of key parameters such as: - current_genebuild - dbowner - pipeline_name - password - user - user_r - release_number</p>"},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config.edit_config_anno--parameters","title":"Parameters:","text":"<p>anno_settings: dict settings : dict     Dictionary with required keys:         - 'config': str, name of the config file (e.g., 'MyConfig.pm')         - 'base_output_dir': str, destination folder for the config         - 'current_genebuild': str         - 'dbowner': str         - 'pipeline_name': str         - 'password': str         - 'user': str         - 'user_r': str         - 'release_number': str or int info_dict : dict pipeline : str</p>"},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config.edit_config_anno--raises","title":"Raises:","text":"<p>FileNotFoundError     If the copied file cannot be opened. KeyError     If required settings keys are missing.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/create_config.py</code> <pre><code>def edit_config_anno(\n    anno_settings: Dict[str, Any],\n    settings: Dict[str, Any],\n    info_dict: Dict[str, Any],\n    pipeline: str,\n    server_settings: Dict[str, Dict[str, Any]],\n) -&gt; None:\n    \"\"\"\n    Edits specific parameter values in a copied Ensembl Hive config file.\n\n    The function performs in-place substitution of key parameters such as:\n    - current_genebuild\n    - dbowner\n    - pipeline_name\n    - password\n    - user\n    - user_r\n    - release_number\n\n    Parameters:\n    ----------\n    anno_settings: dict\n    settings : dict\n        Dictionary with required keys:\n            - 'config': str, name of the config file (e.g., 'MyConfig.pm')\n            - 'base_output_dir': str, destination folder for the config\n            - 'current_genebuild': str\n            - 'dbowner': str\n            - 'pipeline_name': str\n            - 'password': str\n            - 'user': str\n            - 'user_r': str\n            - 'release_number': str or int\n    info_dict : dict\n    pipeline : str\n\n    Raises:\n    ------\n    FileNotFoundError\n        If the copied file cannot be opened.\n    KeyError\n        If required settings keys are missing.\n    \"\"\"\n    local_config = copy_config(anno_settings, info_dict, pipeline)\n\n    with open(local_config, \"r\") as f:\n        content = f.read()\n\n    # Replace the lines\n    content = re.sub(\n        r\"'current_genebuild'\\s*=&gt;\\s*[^,]+,\",\n        f\"'current_genebuild'            =&gt; '{settings['current_genebuild']}',\",\n        content,\n    )\n    content = re.sub(\n        r\"'dbowner'\\s*=&gt;\\s*[^,]+,\",\n        f\"'dbowner'                      =&gt; '{settings['dbowner']}',\",\n        content,\n    )\n    content = re.sub(\n        r\"'pipeline_name'\\s*=&gt;\\s*[^,]+,\",\n        f\"'pipeline_name'                =&gt; '{settings['pipeline_name']}',\",\n        content,\n    )\n    content = re.sub(\n        r\"'password'\\s*=&gt;\\s*[^,]+,\",\n        f\"'password'                     =&gt; '{settings['password']}',\",\n        content,\n    )\n    content = re.sub(\n        r\"'user'\\s*=&gt;\\s*[^,]+,\",\n        f\"'user'                     =&gt; '{settings['user']}',\",\n        content,\n    )\n    content = re.sub(\n        r\"'user_r'\\s*=&gt;\\s*[^,]+,\",\n        f\"'user_r'                     =&gt; '{settings['user_r']}',\",\n        content,\n    )\n\n    content = re.sub(\n        r\"'release_number'\\s*=&gt;\\s*[^,]+,\",\n        f\"'release_number'                     =&gt; '{settings['release_number']}',\",\n        content,\n    )\n\n    content = re.sub(\n        r\"'pipe_db_server'\\s*=&gt;\\s*[^,]+,\",\n        f\"'pipe_db_server'                     =&gt; '{server_settings['pipeline_db']['db_host']}',\",\n        content,\n    )\n\n    content = re.sub(\n        r\"'pipe_db_port'\\s*=&gt;\\s*[^,]+,\",\n        f\"'pipe_db_port'                     =&gt; '{server_settings['pipeline_db']['db_port']}',\",\n        content,\n    )\n    content = re.sub(\n        r\"'dna_db_server'\\s*=&gt;\\s*[^,]+,\",\n        f\"'dna_db_server'                     =&gt; '{server_settings['core_db']['db_host']}',\",\n        content,\n    )\n    content = re.sub(\n        r\"'dna_db_port'\\s*=&gt;\\s*[^,]+,\",\n        f\"'dna_db_port'                     =&gt; '{server_settings['core_db']['db_port']}',\",\n        content,\n    )\n\n    content = re.sub(\n        r\"'registry_file'\\s*=&gt;\\s*[^,]+,\",\n        f\"'registry_file'                     =&gt; '{info_dict['registry_file']}',\",\n        content,\n    )\n\n    with open(local_config, \"w\") as f:\n        f.write(content)\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config.edit_config_main","title":"<code>edit_config_main(settings, info_dict, pipeline)</code>","text":"<p>Edits specific parameter values in a copied Ensembl Hive config file safely, preserving comments and avoiding Perl syntax errors.</p>"},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config.edit_config_main--parameters","title":"Parameters","text":"<p>settings : dict     Must contain 'config' and 'base_output_dir'. info_dict : dict     Keys and values to replace in the config. Keys with value None are skipped. pipeline : str     Type of pipeline, e.g., \"anno\" or \"main\".</p>"},{"location":"ensembl/genes/info_from_registry/create_config/#ensembl.genes.info_from_registry.create_config.edit_config_main--raises","title":"Raises","text":"<p>FileNotFoundError     If the copied config file cannot be found. ValueError     If pipeline type is unknown.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/create_config.py</code> <pre><code>def edit_config_main(\n    settings: Dict[str, Any], info_dict: Dict[str, Any], pipeline: str\n) -&gt; str:\n    \"\"\"\n    Edits specific parameter values in a copied Ensembl Hive config file safely,\n    preserving comments and avoiding Perl syntax errors.\n\n    Parameters\n    ----------\n    settings : dict\n        Must contain 'config' and 'base_output_dir'.\n    info_dict : dict\n        Keys and values to replace in the config. Keys with value None are skipped.\n    pipeline : str\n        Type of pipeline, e.g., \"anno\" or \"main\".\n\n    Raises\n    ------\n    FileNotFoundError\n        If the copied config file cannot be found.\n    ValueError\n        If pipeline type is unknown.\n    \"\"\"\n\n    local_config = copy_config(settings, info_dict, pipeline)\n\n    stop_marker = \"# No option below this mark should be modified\"\n\n    with open(local_config, \"r\") as f:\n        lines = f.readlines()\n\n    new_lines = []\n    stop_modifying = False\n\n    for line in lines:\n        # Replace the package declaration at the top\n        if line.strip().startswith(\"package Bio::EnsEMBL::Analysis::Hive::Config::\"):\n            line = \"package Genome_annotation_conf;\\n\"\n\n        if stop_marker in line:\n            stop_modifying = True\n\n        if not stop_modifying:\n            updated = False\n            for key, value in info_dict.items():\n                # Skip keys with None value\n                if value is None:\n                    continue\n\n                # Pattern matches key =&gt; old_value, optionally with spaces and comments\n                pattern = rf\"^\\s*{re.escape(key)}\\s*=&gt;\\s*[^,]*,\"\n\n                if re.match(pattern, line):\n                    # Preserve comment if present\n                    if \"#\" in line:\n                        parts = line.split(\"#\", 1)\n                        line_content = parts[0]\n                        comment = \"#\" + parts[1].rstrip(\"\\n\")\n                    else:\n                        line_content = line\n                        comment = \"\"\n\n                    # Convert Python value to Perl representation\n                    if isinstance(value, str):\n                        perl_value = f\"'{value}'\"\n                    elif isinstance(value, bool):\n                        perl_value = \"1\" if value else \"0\"\n                    else:\n                        perl_value = str(value)\n\n                    # Replace only the value before the comma\n                    new_line = re.sub(r\"=&gt;\\s*[^,]*,\", f\"=&gt; {perl_value},\", line_content)\n                    if comment:\n                        new_line = new_line.rstrip() + \" \" + comment + \"\\n\"\n                    else:\n                        new_line = new_line.rstrip() + \"\\n\"\n\n                    new_lines.append(new_line)\n                    updated = True\n                    break\n\n            if not updated:\n                new_lines.append(line)\n        else:\n            new_lines.append(line)\n\n    # Write back the updated config safely\n    with open(local_config, \"w\") as f:\n        f.writelines(new_lines)\n\n    logging.info(f\"Config edited successfully: {local_config}\")\n    return local_config\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/create_pipe_reg/","title":"<code>ensembl.genes.info_from_registry.create_pipe_reg</code>","text":""},{"location":"ensembl/genes/info_from_registry/create_pipe_reg/#ensembl.genes.info_from_registry.create_pipe_reg","title":"<code>ensembl.genes.info_from_registry.create_pipe_reg</code>","text":"<p>create_pipe_reg.py</p> <p>This module updates the Ensembl pipeline registry configuration and inserts the appropriate database adaptor entries for use in a genebuild pipeline.</p> <p>It performs two key tasks: 1. Updates references to the shared registry file within the pipeline's resource    description to use a copied, local version. 2. Appends new database connection entries into the copied registry file for use    by Hive pipeline workers.</p>"},{"location":"ensembl/genes/info_from_registry/create_pipe_reg/#ensembl.genes.info_from_registry.create_pipe_reg--functions","title":"Functions:","text":"<ul> <li>update_registry_path_and_create_entry: Updates resource_description in pipeline DB.</li> <li>create_registry_entry: Adds new DBAdaptor entries into the local registry file.</li> </ul>"},{"location":"ensembl/genes/info_from_registry/create_pipe_reg/#ensembl.genes.info_from_registry.create_pipe_reg.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/create_pipe_reg/#ensembl.genes.info_from_registry.create_pipe_reg.create_registry_entry","title":"<code>create_registry_entry(settings, server_info, core_adaptor)</code>","text":"<p>Updates the local registry file with new DBAdaptor connection details for a core database, using the provided connection settings.</p>"},{"location":"ensembl/genes/info_from_registry/create_pipe_reg/#ensembl.genes.info_from_registry.create_pipe_reg.create_registry_entry--parameters","title":"Parameters:","text":"<p>settings : dict     Must contain:         - 'base_output_dir': str, where the local Databases.pm file is placed.</p> dict <p>Used to pass to <code>update_registry_path_and_create_entry</code>.</p> dict <p>Must contain:     - 'host', 'port', 'dbname', 'user', 'pass', 'species', 'group'</p>"},{"location":"ensembl/genes/info_from_registry/create_pipe_reg/#ensembl.genes.info_from_registry.create_pipe_reg.create_registry_entry--returns","title":"Returns:","text":"<p>Path to the modified local registry file (Databases.pm)</p>"},{"location":"ensembl/genes/info_from_registry/create_pipe_reg/#ensembl.genes.info_from_registry.create_pipe_reg.create_registry_entry--raises","title":"Raises:","text":"<p>FileNotFoundError:     If the registry file does not exist after copying.</p> RuntimeError <p>If there is an error overwriting the original registry file.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/create_pipe_reg.py</code> <pre><code>def create_registry_entry(\n    settings: Dict[str, Any],\n    server_info: Dict[str, Dict[str, Any]],\n    core_adaptor: Dict[str, str],\n) -&gt; Path:\n    \"\"\"\n    Updates the local registry file with new DBAdaptor connection details for a\n    core database, using the provided connection settings.\n\n    Parameters:\n    ----------\n    settings : dict\n        Must contain:\n            - 'base_output_dir': str, where the local Databases.pm file is placed.\n\n    server_info : dict\n        Used to pass to `update_registry_path_and_create_entry`.\n\n    core_adaptor : dict\n        Must contain:\n            - 'host', 'port', 'dbname', 'user', 'pass', 'species', 'group'\n\n    Returns:\n    -------\n    Path to the modified local registry file (Databases.pm)\n\n    Raises:\n    ------\n    FileNotFoundError:\n        If the registry file does not exist after copying.\n\n    RuntimeError:\n        If there is an error overwriting the original registry file.\n    \"\"\"\n    registry_path = Path(settings[\"base_output_dir\"]) / \"Databases.pm\"\n    registry_file = os.path.join(\n        os.environ.get(\"ENSCODE\"),\n        \"ensembl-analysis\",\n        \"scripts\",\n        \"genebuild\",\n        \"gbiab\",\n        \"support_files\",\n        \"Databases.pm\",\n    )\n\n    if not registry_path.exists():\n        shutil.copy(registry_file, registry_path)\n\n    if not registry_path.exists():\n        raise FileNotFoundError(f\"A registry file was not found at: {registry_path}\")\n\n    def db_string(db_details):\n        return (\n            f\"Bio::EnsEMBL::DBSQL::DBAdaptor-&gt;new(\\n\"\n            f\"  -host =&gt; '{db_details['host']}',\\n\"\n            f\"  -port =&gt; '{db_details['port']}',\\n\"\n            f\"  -dbname =&gt; '{db_details['dbname']}',\\n\"\n            f\"  -user =&gt; '{db_details['user']}',\\n\"\n            f\"  -pass =&gt; '{db_details['pass']}',\\n\"\n            f\"  -species =&gt; '{db_details['species']}',\\n\"\n            f\"  -group =&gt; '{db_details['group']}',\\n\"\n            f\");\\n\"\n        )\n\n    # Generate registry entries\n    core_string = db_string(core_adaptor)\n\n    # Read the original registry content\n    lines = registry_path.read_text().splitlines(keepends=True)\n\n    # Insert database connection strings after first `{`\n    new_lines = []\n    inserted = False\n    for line in lines:\n        new_lines.append(line)\n        if not inserted and \"{\" in line:\n            new_lines.append(core_string)\n            inserted = True\n\n    # Write to a temporary file\n    tmp_path = registry_path.with_suffix(\".pm.tmp\")\n    tmp_path.write_text(\"\".join(new_lines))\n\n    # Overwrite the original registry file\n    try:\n        shutil.move(str(tmp_path), str(registry_path))\n    except Exception as e:\n        raise RuntimeError(f\"Issue overwriting the old registry: {e}\")\n\n    return registry_path\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/create_pipe_reg/#ensembl.genes.info_from_registry.create_pipe_reg.update_registry_path_in_pipedb","title":"<code>update_registry_path_in_pipedb(parent_dir, server_info)</code>","text":"<p>Updates the resource_description table in the pipeline database by replacing the shared registry path with a local copy. This ensures worker nodes access the correct local registry.</p>"},{"location":"ensembl/genes/info_from_registry/create_pipe_reg/#ensembl.genes.info_from_registry.create_pipe_reg.update_registry_path_in_pipedb--parameters","title":"Parameters:","text":"<p>settings : dict     Must contain:         - 'base_output_dir': Path to where the new registry will be copied.</p> dict <p>Connection info for the pipeline database under:     - server_info[\"pipeline_db\"][\"db_host\"]     - server_info[\"pipeline_db\"][\"db_user\"]     - server_info[\"pipeline_db\"][\"db_port\"]     - server_info[\"pipeline_db\"][\"db_password\"]     - server_info[\"pipeline_db\"][\"db_name\"]</p> Source code in <code>src/python/ensembl/genes/info_from_registry/create_pipe_reg.py</code> <pre><code>def update_registry_path_in_pipedb(\n    parent_dir: str, server_info: Dict[str, Dict[str, Any]]\n) -&gt; None:\n    \"\"\"\n    Updates the resource_description table in the pipeline database by replacing\n    the shared registry path with a local copy. This ensures worker nodes access\n    the correct local registry.\n\n    Parameters:\n    ----------\n    settings : dict\n        Must contain:\n            - 'base_output_dir': Path to where the new registry will be copied.\n\n    server_info : dict\n        Connection info for the pipeline database under:\n            - server_info[\"pipeline_db\"][\"db_host\"]\n            - server_info[\"pipeline_db\"][\"db_user\"]\n            - server_info[\"pipeline_db\"][\"db_port\"]\n            - server_info[\"pipeline_db\"][\"db_password\"]\n            - server_info[\"pipeline_db\"][\"db_name\"]\n    \"\"\"\n    logger.info(\"Updating registry path in pipeline DB\")\n    registry_file = os.path.join(\n        os.environ.get(\"ENSCODE\"),\n        \"ensembl-analysis\",\n        \"scripts\",\n        \"genebuild\",\n        \"gbiab\",\n        \"support_files\",\n        \"Databases.pm\",\n    )\n    logger.debug(f\"parennt_dir : {parent_dir}\")\n    new_registry_file = Path(parent_dir).resolve() / \"Databases.pm\"\n\n    if not new_registry_file.exists():\n        raise OSError(f\"Registry file doesn't exist: {new_registry_file}\")\n\n    logger.info(f\"Registry file exist at {new_registry_file}\")\n\n    update_resources_query = \"\"\"\n\t\tUPDATE resource_description \n\t\tSET worker_cmd_args = REPLACE(worker_cmd_args, %s, %s);\n\t\"\"\"\n\n    success = mysql_update(\n        query=update_resources_query,\n        host=server_info[\"pipeline_db\"][\"db_host\"],\n        user=server_info[\"pipeline_db\"][\"db_user\"],\n        port=server_info[\"pipeline_db\"][\"db_port\"],\n        password=server_info[\"pipeline_db\"][\"db_password\"],\n        database=server_info[\"pipeline_db\"][\"db_name\"],\n        params=(registry_file, new_registry_file),\n    )\n\n    if success:\n        logger.info(\"Registry path updated successfully.\")\n    else:\n        raise RuntimeError(f\"Failed to update registry path.\")\n        logger.error(\"Failed to update registry path.\")\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/genebuild_start_pipeline/","title":"<code>ensembl.genes.info_from_registry.genebuild_start_pipeline</code>","text":""},{"location":"ensembl/genes/info_from_registry/genebuild_start_pipeline/#ensembl.genes.info_from_registry.genebuild_start_pipeline","title":"<code>ensembl.genes.info_from_registry.genebuild_start_pipeline</code>","text":"<p>Script to extract metadata, initialise an annotation pipeline using eHive, and seed the pipeline with jobs based on a generated JSON file.</p> Modules used <ul> <li>start_pipeline_from_registry.py (main)</li> <li>seed_nonvert.py (seed_jobs_from_json)</li> </ul> Usage <p>python genebuild_init_pipeline.py --gcas path/to/gcas.txt --settings_file path/to/user_pipeline_settings.json</p>"},{"location":"ensembl/genes/info_from_registry/genebuild_start_pipeline/#ensembl.genes.info_from_registry.genebuild_start_pipeline.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/genebuild_start_pipeline/#ensembl.genes.info_from_registry.genebuild_start_pipeline.ehive_urls","title":"<code>ehive_urls = main(args.gcas, args.settings_file, args.seed_url)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/genebuild_start_pipeline/#ensembl.genes.info_from_registry.genebuild_start_pipeline.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/genebuild_start_pipeline/#ensembl.genes.info_from_registry.genebuild_start_pipeline.parser","title":"<code>parser = argparse.ArgumentParser(description='Extract metadata, initialize and seed annotation pipelines.')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/genebuild_start_pipeline/#ensembl.genes.info_from_registry.genebuild_start_pipeline.init_pipeline_anno","title":"<code>init_pipeline_anno(config_file, hive_force_init=1)</code>","text":"<p>Initialize an eHive pipeline using a given config file.</p> <p>Parameters:</p> Name Type Description Default <code>config_file</code> <code>str</code> <p>Path to the .pm configuration file (e.g. EnsemblAnnoHelixer_conf.pm).</p> required <code>hive_force_init</code> <code>int</code> <p>Whether to force initialization (default is 1).</p> <code>1</code> <p>Returns:</p> Name Type Description <code>str</code> <code>Optional[str]</code> <p>Extracted eHive database URL if successful.</p> <p>Raises:</p> Type Description <code>CalledProcessError</code> <p>If the <code>init_pipeline.pl</code> command fails.</p> <code>RuntimeError</code> <p>If the expected MySQL URL is not found in the output.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/genebuild_start_pipeline.py</code> <pre><code>def init_pipeline_anno(config_file: str, hive_force_init: int = 1) -&gt; Optional[str]:\n    \"\"\"\n    Initialize an eHive pipeline using a given config file.\n\n    Args:\n        config_file (str): Path to the .pm configuration file (e.g. EnsemblAnnoHelixer_conf.pm).\n        hive_force_init (int): Whether to force initialization (default is 1).\n\n    Returns:\n        str: Extracted eHive database URL if successful.\n\n    Raises:\n        subprocess.CalledProcessError: If the `init_pipeline.pl` command fails.\n        RuntimeError: If the expected MySQL URL is not found in the output.\n    \"\"\"\n    logger.info(\"Innitialising anno pipeline\")\n    cmd = [\"init_pipeline.pl\", config_file, \"--hive_force_init\", str(hive_force_init)]\n\n    logger.info(\"Running: %s\", \" \".join(str(x) for x in cmd))\n    try:\n        result = subprocess.run(\n            cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n        )\n        output = result.stdout\n        for line in output.splitlines():\n            match = re.search(r\"(mysql://[^\\s]+)\", line)\n            if match:\n                return match.group(1)  # Just the URL part\n        return\n    except subprocess.CalledProcessError as e:\n        logger.error(f\"Error running init_pipeline.pl: {e.stdout}\")\n        raise\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/genebuild_start_pipeline/#ensembl.genes.info_from_registry.genebuild_start_pipeline.init_pipeline_main","title":"<code>init_pipeline_main(config_file, hive_force_init=1)</code>","text":"<p>Initialize an eHive pipeline using a given config file.</p> <p>Parameters:</p> Name Type Description Default <code>config_file</code> <code>str</code> <p>Path to the .pm configuration file.</p> required <code>hive_force_init</code> <code>int</code> <p>Whether to force initialization (default is 1).</p> <code>1</code> <p>Returns:</p> Name Type Description <code>str</code> <code>Optional[str]</code> <p>Extracted eHive database URL if successful.</p> <p>Raises:</p> Type Description <code>CalledProcessError</code> <p>If the <code>init_pipeline.pl</code> command fails.</p> <code>RuntimeError</code> <p>If the expected MySQL URL is not found in the output.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/genebuild_start_pipeline.py</code> <pre><code>def init_pipeline_main(config_file: str, hive_force_init: int = 1) -&gt; Optional[str]:\n    \"\"\"\n    Initialize an eHive pipeline using a given config file.\n\n    Args:\n        config_file (str): Path to the .pm configuration file.\n        hive_force_init (int): Whether to force initialization (default is 1).\n\n    Returns:\n        str: Extracted eHive database URL if successful.\n\n    Raises:\n        subprocess.CalledProcessError: If the `init_pipeline.pl` command fails.\n        RuntimeError: If the expected MySQL URL is not found in the output.\n    \"\"\"\n    config_path = Path(config_file)\n    config_dir = config_path.parent\n    config_name = config_path.stem  # Gets filename without .pm extension\n\n    cmd = [\n        \"init_pipeline.pl\",\n        config_name,  # Just the module name, not the full path\n        \"--hive_force_init\",\n        str(hive_force_init),\n    ]\n\n    logger.info(\"Running: %s\", \" \".join(str(x) for x in cmd))\n    logger.info(f\"Working directory: {config_dir}\")\n\n    try:\n        result = subprocess.run(\n            cmd,\n            check=True,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,\n            cwd=str(config_dir),  # Run from the config directory\n        )\n        output = result.stdout\n        for line in output.splitlines():\n            match = re.search(r\"(mysql://[^\\s]+)\", line)\n            if match:\n                return match.group(1)\n        return None\n    except subprocess.CalledProcessError as e:\n        logger.error(f\"Error running init_pipeline.pl: {e.stdout}\")\n        raise\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/genebuild_start_pipeline/#ensembl.genes.info_from_registry.genebuild_start_pipeline.main","title":"<code>main(gcas, settings_file, seed_url)</code>","text":"<p>Main execution logic: extract metadata, initialize the pipeline, and seed jobs.</p> <p>Parameters:</p> Name Type Description Default <code>gcas</code> <code>str</code> <p>Path to file containing GCA accessions (one per line).</p> required <code>settings_file</code> <code>str</code> <p>Path to settings file (JSON).</p> required <code>seed_url</code> <code>str</code> <p>Existing URL to seed the pipeline. If provided initialisation will be skipped.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If no config file is found.</p> <code>RuntimeError</code> <p>If multiple config files are found.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/genebuild_start_pipeline.py</code> <pre><code>def main(gcas: str, settings_file: str, seed_url: Optional[str]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Main execution logic: extract metadata, initialize the pipeline, and seed jobs.\n\n    Args:\n        gcas (str): Path to file containing GCA accessions (one per line).\n        settings_file (str): Path to settings file (JSON).\n        seed_url (str): Existing URL to seed the pipeline. If provided initialisation will be skipped.\n\n    Raises:\n        FileNotFoundError: If no config file is found.\n        RuntimeError: If multiple config files are found.\n    \"\"\"\n\n    # Get info and create input JSON\n    server_info, all_output_params, saved_paths = info(gcas, settings_file)\n\n    # Save EHIVE URLs\n    ehive_urls = {}\n\n    # Anno\n    if saved_paths.get(\"anno\"):\n        json_file = saved_paths[\"anno\"]\n\n        if seed_url:\n            logger.info(\"Skipping pipeline initialisation.\")\n            logger.info(\"Using provided seed URL: %s\", seed_url)\n            ehive_urls[\"anno\"] = seed_url\n        else:\n            logger.info(\"No seed URL provided. Initialising new pipeline.\")\n            first_key = next(iter(all_output_params))\n            output_path = Path(all_output_params[first_key][\"output_path\"])\n            parent_dir = output_path.parent\n            conf_files = list(parent_dir.glob(\"*_conf.pm\"))\n\n            if not conf_files:\n                raise FileNotFoundError(f\"No .conf file found in {parent_dir}\")\n            if len(conf_files) &gt; 1:\n                raise RuntimeError(\n                    f\"Multiple .conf files found in {parent_dir}: {conf_files}\"\n                )\n\n            conf_path = conf_files[0]\n            logger.info(f\"Config found at {conf_path}\")\n\n            ehive_url = init_pipeline_anno(conf_path)\n            ehive_urls[\"anno\"] = ehive_url\n            logger.info(f\"Extracted EHIVE_URL: {ehive_url}\")\n\n            update_registry_path_in_pipedb(parent_dir, server_info)\n            seed_url = ehive_url  # unify below\n\n        # Common seeding step\n        logger.info(f\"Seeding non-vertebrate pipeline from {json_file}\")\n        with open(json_file) as f:\n            params = json.load(f)\n\n        seed_jobs_from_json(json_file=params, analysis_id=1, ehive_url=seed_url)\n\n    # --- Handle main (one JSON per GCA) ---\n    if saved_paths.get(\"main\"):\n        ehive_urls[\"main\"] = {}\n        for gca, json_path in saved_paths[\"main\"].items():\n            logger.info(f\"Initialising vertebrate pipeline for {gca} from {json_path}\")\n\n            output_path = Path(all_output_params[gca][\"output_path\"])\n            conf_files = list(output_path.glob(\"*_conf.pm\"))\n\n            if not conf_files:\n                raise FileNotFoundError(f\"No .conf file found in {parent_dir}\")\n            elif len(conf_files) &gt; 1:\n                raise RuntimeError(\n                    f\"Multiple .conf files found in {parent_dir}: {conf_files}\"\n                )\n\n            conf_path = conf_files[0]\n\n            ehive_url = init_pipeline_main(str(conf_path))\n            ehive_urls[\"main\"][gca] = ehive_url\n            logger.info(f\"Extracted EHIVE_URL for {gca}: {ehive_url}\")\n\n    logger.info(f\"Initalised pipelines. EHIVE_URL(s): {ehive_urls}\")\n\n    output_dir_current = Path.cwd()\n    ehive_url_file = output_dir_current / \"ehive_urls.json\"\n\n    with open(ehive_url_file, \"w\") as f:\n        json.dump(ehive_urls, f, indent=2)\n\n    logger.info(f\"Saved EHIVE URLs to {ehive_url_file}\")\n\n    return ehive_urls\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/mysql_helper/","title":"<code>ensembl.genes.info_from_registry.mysql_helper</code>","text":""},{"location":"ensembl/genes/info_from_registry/mysql_helper/#ensembl.genes.info_from_registry.mysql_helper","title":"<code>ensembl.genes.info_from_registry.mysql_helper</code>","text":"<p>MySQL Helper Module</p> <p>This module provides utility functions for connecting to a MySQL database, fetching data, and performing updates. Logging is enabled to capture informative messages and errors during execution.</p> <p>Functions:</p> Name Description <code>- mysql_fetch_data</code> <p>Executes a SELECT query and returns the result as a list of dictionaries.</p> <code>- mysql_update</code> <p>Executes an UPDATE/INSERT/DELETE query with optional parameters.</p>"},{"location":"ensembl/genes/info_from_registry/mysql_helper/#ensembl.genes.info_from_registry.mysql_helper.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/mysql_helper/#ensembl.genes.info_from_registry.mysql_helper.mysql_fetch_data","title":"<code>mysql_fetch_data(query, database, host, port, user, password, params=None)</code>","text":"<p>Execute a SELECT query on the specified MySQL database and return results.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SQL SELECT query to execute.</p> required <code>database</code> <code>str</code> <p>Name of the database.</p> required <code>host</code> <code>str</code> <p>Host address of the MySQL server.</p> required <code>port</code> <code>int</code> <p>Port number of the MySQL server.</p> required <code>user</code> <code>str</code> <p>Username to connect to the database.</p> required <code>password</code> <code>str</code> <p>Password for the user.</p> required <code>params</code> <code>tuple or list</code> <p>Parameters to safely interpolate into the query.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>list[dict]: A list of dictionaries representing query results.         Returns an empty list on failure.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/mysql_helper.py</code> <pre><code>def mysql_fetch_data(\n    query: str,\n    database: str,\n    host: str,\n    port: int,\n    user: str,\n    password: str,\n    params: Optional[tuple[Any, ...] | list[Any]] = None,\n) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Execute a SELECT query on the specified MySQL database and return results.\n\n    Args:\n        query (str): SQL SELECT query to execute.\n        database (str): Name of the database.\n        host (str): Host address of the MySQL server.\n        port (int): Port number of the MySQL server.\n        user (str): Username to connect to the database.\n        password (str): Password for the user.\n        params (tuple or list, optional): Parameters to safely interpolate into the query.\n\n    Returns:\n        list[dict]: A list of dictionaries representing query results.\n                    Returns an empty list on failure.\n    \"\"\"\n    try:\n        conn = pymysql.connect(\n            host=host,\n            user=user,\n            port=port,\n            password=password,\n            database=database.strip(),\n            cursorclass=pymysql.cursors.DictCursor,\n        )\n        with conn.cursor() as cursor:\n            cursor.execute(query, params or ())\n            results = cursor.fetchall()\n        conn.close()\n        logger.info(\"Query successful\")\n        return results\n\n    except pymysql.Error as err:\n        logger.error(f\"MySQL error during fetch: {err}\")\n        return []\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/mysql_helper/#ensembl.genes.info_from_registry.mysql_helper.mysql_get_connection","title":"<code>mysql_get_connection(database, host, port, user, password)</code>","text":"<p>Establish a connection to the MySQL database.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/mysql_helper.py</code> <pre><code>def mysql_get_connection(\n    database: str, host: str, port: int, user: str, password: str\n) -&gt; Optional[pymysql.connections.Connection]:\n    \"\"\"\n    Establish a connection to the MySQL database.\n    \"\"\"\n    try:\n        conn = pymysql.connect(\n            host=host,\n            user=user,\n            port=port,\n            password=password,\n            database=database.strip(),\n            cursorclass=pymysql.cursors.DictCursor,\n        )\n        return conn\n    except pymysql.Error as err:\n        print(f\"MySQL error: {err}\")\n        return None\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/mysql_helper/#ensembl.genes.info_from_registry.mysql_helper.mysql_update","title":"<code>mysql_update(query, database, host, port, user, password, params=None)</code>","text":"<p>Execute an UPDATE, INSERT, or DELETE query on the specified MySQL database.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SQL query to execute.</p> required <code>database</code> <code>str</code> <p>Name of the database.</p> required <code>host</code> <code>str</code> <p>Host address of the MySQL server.</p> required <code>port</code> <code>int</code> <p>Port number of the MySQL server.</p> required <code>user</code> <code>str</code> <p>Username to connect to the database.</p> required <code>password</code> <code>str</code> <p>Password for the user.</p> required <code>params</code> <code>tuple or list</code> <p>Parameters to safely interpolate into the query.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the query was executed successfully, False otherwise.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/mysql_helper.py</code> <pre><code>def mysql_update(\n    query: str,\n    database: str,\n    host: str,\n    port: int,\n    user: str,\n    password: str,\n    params: Optional[tuple[Any, ...] | list[Any]] = None,\n) -&gt; bool:\n    \"\"\"\n    Execute an UPDATE, INSERT, or DELETE query on the specified MySQL database.\n\n    Args:\n        query (str): SQL query to execute.\n        database (str): Name of the database.\n        host (str): Host address of the MySQL server.\n        port (int): Port number of the MySQL server.\n        user (str): Username to connect to the database.\n        password (str): Password for the user.\n        params (tuple or list, optional): Parameters to safely interpolate into the query.\n\n    Returns:\n        bool: True if the query was executed successfully, False otherwise.\n    \"\"\"\n    try:\n        conn = pymysql.connect(\n            host=host,\n            user=user,\n            port=port,\n            password=password,\n            database=database.strip(),\n            cursorclass=pymysql.cursors.DictCursor,\n        )\n        with conn.cursor() as cursor:\n            cursor.execute(query, params or ())\n            conn.commit()\n        conn.close()\n        logger.info(\"Update successful.\")\n        return True\n\n    except pymysql.Error as err:\n        logger.error(f\"MySQL error during update: {err}\")\n        return False\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/registry_helper/","title":"<code>ensembl.genes.info_from_registry.registry_helper</code>","text":""},{"location":"ensembl/genes/info_from_registry/registry_helper/#ensembl.genes.info_from_registry.registry_helper","title":"<code>ensembl.genes.info_from_registry.registry_helper</code>","text":"<p>Registry Helper Module</p> <p>This module provides utility functions for common registry database queries that are shared across multiple scripts.</p>"},{"location":"ensembl/genes/info_from_registry/registry_helper/#ensembl.genes.info_from_registry.registry_helper.fetch_assembly_id","title":"<code>fetch_assembly_id(connection, assembly)</code>","text":"<p>Fetch the assembly ID for a given assembly accession.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Connection</code> <p>MySQL connection object</p> required <code>assembly</code> <code>str</code> <p>Assembly Accession (GCA format like GCA_123456789.1)</p> required <p>Returns:     int: Assembly ID if found, else None</p> Source code in <code>src/python/ensembl/genes/info_from_registry/registry_helper.py</code> <pre><code>def fetch_assembly_id(\n    connection: pymysql.connections.Connection, assembly: str\n) -&gt; Optional[int]:\n    \"\"\"\n    Fetch the assembly ID for a given assembly accession.\n\n    Args:\n        connection: MySQL connection object\n        assembly (str): Assembly Accession (GCA format like GCA_123456789.1)\n    Returns:\n        int: Assembly ID if found, else None\n    \"\"\"\n    query = \"\"\"\n    SELECT assembly_id FROM assembly\n    WHERE CONCAT(gca_chain, '.', gca_version) = %s\n    \"\"\"\n\n    with connection.cursor() as cursor:\n        cursor.execute(query, (assembly,))\n        result = cursor.fetchone()\n\n    return result[\"assembly_id\"] if result else None\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/registry_helper/#ensembl.genes.info_from_registry.registry_helper.fetch_current_genebuild_record","title":"<code>fetch_current_genebuild_record(connection, assembly, genebuilder=None)</code>","text":"<p>Fetch the full current genebuild record for a given assembly.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Connection</code> <p>MySQL connection object</p> required <code>assembly</code> <code>str</code> <p>Assembly Accession (GCA format)</p> required <code>genebuilder</code> <code>str</code> <p>Genebuilder name to filter by. If None, fetches any active record.</p> <code>None</code> <p>Returns:     dict: Record with genebuild_status_id, gb_status, genebuilder, annotation_method, genebuild_version, and other fields if found, else None</p> Source code in <code>src/python/ensembl/genes/info_from_registry/registry_helper.py</code> <pre><code>def fetch_current_genebuild_record(\n    connection: pymysql.connections.Connection,\n    assembly: str,\n    genebuilder: Optional[str] = None,\n) -&gt; Optional[dict[str, any]]:\n    \"\"\"\n    Fetch the full current genebuild record for a given assembly.\n\n    Args:\n        connection: MySQL connection object\n        assembly (str): Assembly Accession (GCA format)\n        genebuilder (str, optional): Genebuilder name to filter by. If None, fetches any active record.\n    Returns:\n        dict: Record with genebuild_status_id, gb_status, genebuilder, annotation_method, genebuild_version, and other fields if found, else None\n    \"\"\"\n    if genebuilder:\n        query = \"\"\"\n        SELECT genebuild_status_id, gb_status, genebuilder, annotation_method, genebuild_version\n        FROM genebuild_status\n        WHERE gca_accession = %s AND genebuilder = %s AND last_attempt = 1\n        \"\"\"\n        params = (assembly, genebuilder)\n    else:\n        query = \"\"\"\n        SELECT genebuild_status_id, gb_status, genebuilder, annotation_method, genebuild_version\n        FROM genebuild_status\n        WHERE gca_accession = %s AND last_attempt = 1\n        \"\"\"\n        params = (assembly,)\n\n    with connection.cursor() as cursor:\n        cursor.execute(query, params)\n        result = cursor.fetchone()\n\n    return result\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/registry_helper/#ensembl.genes.info_from_registry.registry_helper.fetch_genebuild_status_id","title":"<code>fetch_genebuild_status_id(connection, assembly)</code>","text":"<p>Fetch the current genebuild status ID for a given assembly.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Connection</code> <p>MySQL connection object</p> required <code>assembly</code> <code>str</code> <p>Assembly Accession (GCA format)</p> required <p>Returns:     int: genebuild_status_id if found (where last_attempt=1), else None</p> Source code in <code>src/python/ensembl/genes/info_from_registry/registry_helper.py</code> <pre><code>def fetch_genebuild_status_id(\n    connection: pymysql.connections.Connection, assembly: str\n) -&gt; Optional[int]:\n    \"\"\"\n    Fetch the current genebuild status ID for a given assembly.\n\n    Args:\n        connection: MySQL connection object\n        assembly (str): Assembly Accession (GCA format)\n    Returns:\n        int: genebuild_status_id if found (where last_attempt=1), else None\n    \"\"\"\n    record = fetch_current_genebuild_record(connection, assembly)\n    return record[\"genebuild_status_id\"] if record else None\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/registry_helper/#ensembl.genes.info_from_registry.registry_helper.fetch_registry_ids","title":"<code>fetch_registry_ids(connection, assembly, genebuilder=None)</code>","text":"<p>Fetch both assembly_id and genebuild_status_id for a given assembly.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Connection</code> <p>MySQL connection object</p> required <code>assembly</code> <code>str</code> <p>Assembly Accession (GCA format)</p> required <code>genebuilder</code> <code>str</code> <p>Genebuilder name to filter by. If None and multiple                          active records exist, returns the first one found.</p> <code>None</code> <p>Returns:     tuple: (assembly_id, genebuild_status_id) where genebuild_status_id may be None Raises:     ValueError: If assembly is not found in registry</p> Source code in <code>src/python/ensembl/genes/info_from_registry/registry_helper.py</code> <pre><code>def fetch_registry_ids(\n    connection: pymysql.connections.Connection,\n    assembly: str,\n    genebuilder: Optional[str] = None,\n) -&gt; tuple[int, Optional[int]]:\n    \"\"\"\n    Fetch both assembly_id and genebuild_status_id for a given assembly.\n\n    Args:\n        connection: MySQL connection object\n        assembly (str): Assembly Accession (GCA format)\n        genebuilder (str, optional): Genebuilder name to filter by. If None and multiple\n                                     active records exist, returns the first one found.\n    Returns:\n        tuple: (assembly_id, genebuild_status_id) where genebuild_status_id may be None\n    Raises:\n        ValueError: If assembly is not found in registry\n    \"\"\"\n    assembly_id = fetch_assembly_id(connection, assembly)\n    if not assembly_id:\n        raise ValueError(f\"Assembly not found in registry: {assembly}\")\n\n    record = fetch_current_genebuild_record(connection, assembly, genebuilder)\n    genebuild_status_id = record[\"genebuild_status_id\"] if record else None\n\n    return assembly_id, genebuild_status_id\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/seed_nonvert/","title":"<code>ensembl.genes.info_from_registry.seed_nonvert</code>","text":""},{"location":"ensembl/genes/info_from_registry/seed_nonvert/#ensembl.genes.info_from_registry.seed_nonvert","title":"<code>ensembl.genes.info_from_registry.seed_nonvert</code>","text":"<p>seed_nonvert.py</p> <p>This script allows you to seed jobs into an eHive pipeline using a JSON file or a dictionary of job parameters. It converts Python dictionaries to Perl hash syntax and invokes the <code>seed_pipeline.pl</code> script via subprocess.</p> Typical usage example <p>python seed_jobs.py -j jobs.json -a 1 -u mysql://user:pass@host/db</p> <p>Functions:</p> Name Description <code>- dict_to_perl_hash</code> <p>Recursively converts a Python dictionary into a Perl-style hash string.</p> <code>- seed_jobs_from_json</code> <p>Loads parameters and invokes eHive seeding commands.</p> <code>- main</code> <p>Parses command-line arguments and calls the seeding function.</p>"},{"location":"ensembl/genes/info_from_registry/seed_nonvert/#ensembl.genes.info_from_registry.seed_nonvert.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/seed_nonvert/#ensembl.genes.info_from_registry.seed_nonvert.dict_to_perl_hash","title":"<code>dict_to_perl_hash(d)</code>","text":"<p>Recursively convert a Python dictionary to a Perl hash string. Automatically converts database connection parameters to Ensembl format.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>Python dictionary to convert.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>A string representing the dictionary in Perl hash format.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/seed_nonvert.py</code> <pre><code>def dict_to_perl_hash(d):\n    \"\"\"\n    Recursively convert a Python dictionary to a Perl hash string.\n    Automatically converts database connection parameters to Ensembl format.\n\n    Args:\n        d (dict): Python dictionary to convert.\n\n    Returns:\n        str: A string representing the dictionary in Perl hash format.\n    \"\"\"\n\n    def convert_db_keys(dictionary):\n        \"\"\"Convert db_* keys to Ensembl format if this looks like a DB connection.\"\"\"\n        if not isinstance(dictionary, dict):\n            return dictionary\n\n        # Check if this looks like a database connection dictionary\n        db_keys = {\"db_host\", \"db_user\", \"db_port\", \"db_password\", \"db_name\"}\n        if any(key in dictionary for key in db_keys):\n            converted = {}\n            key_mapping = {\n                \"db_host\": \"-host\",\n                \"db_user\": \"-user\",\n                \"db_port\": \"-port\",\n                \"db_password\": \"-pass\",\n                \"db_name\": \"-dbname\",\n            }\n\n            for k, v in dictionary.items():\n                if k in key_mapping:\n                    converted[key_mapping[k]] = v\n                else:\n                    converted[k] = v\n\n            # Add driver if not present\n            if \"-driver\" not in converted and any(\n                k.startswith(\"-\") for k in converted.keys()\n            ):\n                converted[\"-driver\"] = \"mysql\"\n\n            return converted\n\n        return dictionary\n\n    # Convert database keys if needed\n    d = convert_db_keys(d)\n\n    items = []\n    for k, v in d.items():\n        key_str = f\"'{k}'\"\n        if isinstance(v, dict):\n            # Recursively convert nested dictionaries and check for DB format\n            converted_v = convert_db_keys(v)\n            val_str = dict_to_perl_hash(converted_v)\n        elif isinstance(v, str):\n            val_str = f\"'{v}'\"\n        elif v is None:\n            val_str = \"undef\"\n        else:\n            val_str = str(v)\n        items.append(f\"{key_str} =&gt; {val_str}\")\n    return \"{{{}}}\".format(\", \".join(items))\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/seed_nonvert/#ensembl.genes.info_from_registry.seed_nonvert.main","title":"<code>main()</code>","text":"Source code in <code>src/python/ensembl/genes/info_from_registry/seed_nonvert.py</code> <pre><code>def main():\n    parser = argparse.ArgumentParser(\n        description=\"Seed eHive pipeline jobs from a JSON file\"\n    )\n    parser.add_argument(\n        \"-j\",\n        \"--json_file\",\n        required=True,\n        help=\"Path to the JSON file with job parameters\",\n    )\n    parser.add_argument(\n        \"-a\",\n        \"--analysis_id\",\n        type=int,\n        default=1,\n        help=f\"Analysis ID to seed (default: 1)\",\n    )\n    parser.add_argument(\"-u\", \"--url\", required=True, help=\"EHIVE URL\")\n    args = parser.parse_args()\n\n    seed_jobs_from_json(\n        json_file=args.json_file, analysis_id=args.analysis_id, ehive_url=args.url\n    )\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/seed_nonvert/#ensembl.genes.info_from_registry.seed_nonvert.seed_jobs_from_json","title":"<code>seed_jobs_from_json(json_file, analysis_id, ehive_url)</code>","text":"<p>Seed jobs in an eHive pipeline using job parameters from a JSON file or dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>json_file</code> <code>Union[str, dict]</code> <p>Path to a JSON file or a Python dictionary with job parameters.</p> required <code>analysis_id</code> <code>int</code> <p>eHive analysis ID to assign jobs to.</p> required <code>ehive_url</code> <code>str</code> <p>URL of the eHive database (e.g., mysql://user:pass@host/db).</p> required <p>Raises:</p> Type Description <code>CalledProcessError</code> <p>If the seeding script fails.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/seed_nonvert.py</code> <pre><code>def seed_jobs_from_json(\n    json_file: Union[str, dict],\n    analysis_id: int,\n    ehive_url: str,\n):\n    \"\"\"\n    Seed jobs in an eHive pipeline using job parameters from a JSON file or dictionary.\n\n    Args:\n        json_file (Union[str, dict]): Path to a JSON file or a Python dictionary with job parameters.\n        analysis_id (int): eHive analysis ID to assign jobs to.\n        ehive_url (str): URL of the eHive database (e.g., mysql://user:pass@host/db).\n\n    Raises:\n        subprocess.CalledProcessError: If the seeding script fails.\n    \"\"\"\n\n    if isinstance(json_file, str):\n        with open(json_file) as f:\n            params = json.load(f)\n    else:\n        params = json_file  # assume dict already\n\n    for input_id, param_dict in params.items():\n        perl_hash = dict_to_perl_hash(param_dict)\n        cmd = [\n            \"seed_pipeline.pl\",\n            \"-analysis_id\",\n            str(analysis_id),\n            \"-input_id\",\n            perl_hash,\n            \"-url\",\n            ehive_url,\n        ]\n        subprocess.run(cmd, check=True)\n        logging.info(\"Seeding complete\")\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/","title":"<code>ensembl.genes.info_from_registry.start_pipeline_from_registry</code>","text":""},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry","title":"<code>ensembl.genes.info_from_registry.start_pipeline_from_registry</code>","text":"<p>This script connects to a genomic assembly registry, extracts assembly metadata, and initializes annotation pipelines based on predefined configurations.</p> <p>It supports both database-driven metadata retrieval and custom INI file loading, handles directory setup, and creates necessary configuration and command files for running genome annotation pipelines.</p> Typical usage <p>python start_pipeline_from_registry.py --gcas gca_list.txt ---settings_file settings.json</p>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.parser","title":"<code>parser = argparse.ArgumentParser(description='Extract metadata and initialize annotation pipelines.')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.add_generated_data","title":"<code>add_generated_data(server_info, assembly_accession, settings)</code>","text":"<p>Enrich registry metadata with clade assignments and derived pipeline variables.</p> <p>Parameters:</p> Name Type Description Default <code>server_info</code> <code>dict</code> <p>Server connection details.</p> required <code>assembly_accession</code> <code>str</code> <p>Genome assembly accession.</p> required <code>settings</code> <code>dict</code> <p>Pipeline settings.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Enriched metadata dictionary with added fields for pipeline usage.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def add_generated_data(\n    server_info: dict, assembly_accession: str, settings: dict\n) -&gt; dict:\n    \"\"\"\n    Enrich registry metadata with clade assignments and derived pipeline variables.\n\n    Args:\n        server_info (dict): Server connection details.\n        assembly_accession (str): Genome assembly accession.\n        settings (dict): Pipeline settings.\n\n    Returns:\n        dict: Enriched metadata dictionary with added fields for pipeline usage.\n    \"\"\"\n\n    registry_info = get_metadata_from_registry(\n        server_info, assembly_accession, settings\n    )\n    logger.info(f\"Data collected from registry {assembly_accession}\")\n    clade, genus_id, clade_metadata = assign_clade(server_info, registry_info)\n    registry_info[\"clade\"] = clade\n    registry_info[\"genus_taxon_id\"] = genus_id\n\n    if clade_metadata:\n        registry_info.update(clade_metadata)\n\n    info_dict = registry_info\n    # Create variables for pipeline\n    info_dict[\"strain_type\"] = \"strain\"\n\n    if \"assembly_name\" in registry_info and \" \" in registry_info[\"assembly_name\"]:\n        registry_info[\"assembly_name\"] = registry_info[\"assembly_name\"].replace(\n            \" \", \"_\"\n        )\n\n    if \"alternate_haplotype\" in registry_info.get(\"assembly_name\", \"\"):\n        info_dict[\"common_name\"] = \"alternate haplotype\"\n        info_dict[\"species_strain\"] = \"alternate haplotype\"\n\n    if not registry_info.get(\"common_name\"):\n        info_dict[\"common_name\"] = \"NA\"\n\n    info_dict[\"species_display_name\"] = (\n        f\"{registry_info['species_name']} ({registry_info['common_name']}) - {assembly_accession}\"\n    )\n    info_dict[\"species_strain\"] = \"reference\"\n\n    raw_species = (\n        registry_info.get(\"species_name\", \"\").strip().lower().replace(\" \", \"_\")\n    )\n    species_name = raw_species.rstrip(\"_\")  # Remove trailing underscore\n\n    # Extract binomial name\n    parts = species_name.split(\"_\")\n    if len(parts) &gt;= 2:\n        p1, p2 = parts[:2]\n        max_len = 15\n        production_name = f\"{p1[:max_len]}_{p2[:max_len]}\"\n    else:\n        production_name = \"\"\n\n    production_gca = assembly_accession.replace(\".\", \"v\").replace(\"_\", \"\").lower()\n    production_name += f\"_{production_gca}\"\n\n    # Update dictionary\n    info_dict[\"species_name\"] = species_name\n    info_dict[\"production_name\"] = production_name\n    info_dict[\"species_strain_group\"] = production_name\n    info_dict[\"species_url\"] = (\n        f\"{registry_info['species_name'].capitalize()}_{assembly_accession}\"\n    )\n    info_dict[\"core_dbname\"] = (\n        f\"{settings['dbowner']}_{production_gca}_core_{settings['release_number']}_1\"\n    )\n\n    logger.info(f\"Values formatted for {assembly_accession}\")\n\n    return info_dict\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.copy_general_module","title":"<code>copy_general_module()</code>","text":"Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def copy_general_module():\n    logger.info(\"Copying general module\")\n    enscode = os.environ.get(\"ENSCODE\")\n    if not enscode:\n        raise OSError(\"Environment variable 'ENSCODE' is not set\")\n\n    analysis_path = os.path.join(enscode, \"ensembl-analysis\")\n    general_file = (\n        Path(analysis_path)\n        / \"modules\"\n        / \"Bio\"\n        / \"EnsEMBL\"\n        / \"Analysis\"\n        / \"Config\"\n        / \"General.pm\"\n    )\n    example_file = general_file.with_suffix(\".pm.example\")\n\n    # Copy if missing\n    if not general_file.exists():\n        if example_file.exists():\n            shutil.copy(example_file, general_file)\n            logger.info(f\"Copied {example_file} \u2192 {general_file}\")\n        else:\n            raise FileNotFoundError(f\"Missing example file: {example_file}\")\n    else:\n        logger.info(f\"{general_file} already exists, nothing to do.\")\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.create_dir","title":"<code>create_dir(path, mode=None)</code>","text":"<p>Create a directory and optionally set its permissions.</p> <p>This function creates the directory at 'path' including any necessary parent directories. If 'mode' is provided, it changes the directory's permissions.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>The directory path to create.</p> required <code>mode</code> <code>int</code> <p>File system permissions mode (e.g., 0o775). Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the directory creation or permission change fails.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def create_dir(path: str | Path, mode: Optional[int] = None) -&gt; None:\n    \"\"\"\n    Create a directory and optionally set its permissions.\n\n    This function creates the directory at 'path' including any necessary\n    parent directories. If 'mode' is provided, it changes the directory's permissions.\n\n    Args:\n        path (str or Path): The directory path to create.\n        mode (int, optional): File system permissions mode (e.g., 0o775). Defaults to None.\n\n    Raises:\n        RuntimeError: If the directory creation or permission change fails.\n    \"\"\"\n\n    try:\n        os.makedirs(path, exist_ok=True)\n        if mode is not None:\n            os.chmod(path, mode)\n    except Exception as e:\n        raise RuntimeError(f\"Failed to create dir: {path}\") from e\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.current_projection_source_db","title":"<code>current_projection_source_db(projection_source_production_name)</code>","text":"<p>Find the reference core database and server info for the given projection_source_production_name. If not found, fall back to homo_sapiens core. Args:     projection_source_production_name (str): Name to look for in core name (comes from clade_settings). Returns a dictionary with keys: db_name, server, port Raises:     RuntimeError: If database could not be found.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def current_projection_source_db(projection_source_production_name: str) -&gt; dict:\n    \"\"\"\n    Find the reference core database and server info for the given projection_source_production_name.\n    If not found, fall back to homo_sapiens core.\n    Args:\n        projection_source_production_name (str): Name to look for in core name (comes from clade_settings).\n    Returns a dictionary with keys: db_name, server, port\n    Raises:\n        RuntimeError: If database could not be found.\n\n    \"\"\"\n    projection_json = os.path.join(\n        os.environ.get(\"ENSCODE\"),\n        \"ensembl-genes\",\n        \"src\",\n        \"python\",\n        \"ensembl\",\n        \"genes\",\n        \"info_from_registry\",\n        \"projection_source.json\",\n    )\n    try:\n        with open(projection_json, \"r\") as f:\n            data = json.load(f)\n    except Exception as e:\n        raise RuntimeError(f\"Failed to read JSON file {projection_json}: {e}\")\n\n    # Find a matching nested dictionary\n    matched_key = None\n    for key, subdict in data.items():\n        if (\n            isinstance(subdict, dict)\n            and projection_source_production_name in subdict.values()\n        ):\n            matched_key = key\n            break\n\n    # Fallback logic\n    if matched_key:\n        logger.info(\n            f\"Match found for '{projection_source_production_name}' in '{matched_key}'\"\n        )\n        return data[matched_key]\n    elif \"homo_sapiens\" in data:\n        logger.warning(\n            f\"No match for '{projection_source_production_name}'. Falling back to 'homo_sapiens'.\"\n        )\n        return data[\"homo_sapiens\"]\n    else:\n        raise RuntimeError(\n            f\"No match for '{projection_source_production_name}' and 'homo_sapiens' not found in {json_path}.\"\n        )\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.custom_loading","title":"<code>custom_loading(settings)</code>","text":"<p>Load custom key-value pairs from an INI-style initialization file specified in settings.</p> <p>Reads the file line-by-line, extracting key=value pairs into a dictionary. Lines that do not conform to key=value format or are blank are skipped with a message.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>dict</code> <p>Pipeline settings dictionary that must include              the key 'init_file' pointing to the INI file path.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, str]</code> <p>Dictionary containing key-value pairs loaded from the INI file.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the file cannot be opened or read.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def custom_loading(settings: dict) -&gt; dict[str, str]:\n    \"\"\"\n    Load custom key-value pairs from an INI-style initialization file specified in settings.\n\n    Reads the file line-by-line, extracting key=value pairs into a dictionary.\n    Lines that do not conform to key=value format or are blank are skipped with a message.\n\n    Args:\n        settings (dict): Pipeline settings dictionary that must include\n                         the key 'init_file' pointing to the INI file path.\n\n    Returns:\n        dict: Dictionary containing key-value pairs loaded from the INI file.\n\n    Raises:\n        Exception: If the file cannot be opened or read.\n    \"\"\"\n    logger.info(\"Custom loading started\")\n    init_file = Path(settings[\"init_file\"])\n\n    # Initialize variables\n    custom_dict = {}\n    custom_loading = False\n\n    if init_file.exists():\n        try:\n            with init_file.open(\"r\") as f:\n                print(\"Using custom loading .ini file.\")\n                custom_loading = True\n\n                for line in f:\n                    line = line.strip()\n\n                    if \"=\" in line:\n                        key, value = map(str.strip, line.split(\"=\", 1))\n                        print(f\"Found key/value pair: {key} =&gt; {value}\")\n                        custom_dict[key] = value\n                    elif line == \"\":\n                        continue\n                    else:\n                        print(f\"Line format not recognised. Skipping line:\\n{line}\")\n\n        except OSError as e:\n            raise Exception(f\"Could not open or read {init_file}\") from e\n\n    return custom_dict\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.get_info_for_pipeline_anno","title":"<code>get_info_for_pipeline_anno(settings, info_dict, assembly_accession, anno_settings)</code>","text":"<p>Prepare and add file paths and pipeline-specific parameters needed for running annotation.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>dict</code> <p>Pipeline settings.</p> required <code>info_dict</code> <code>dict</code> <p>Metadata dictionary for the assembly.</p> required <code>assembly_accession</code> <code>str</code> <p>Assembly accession string.</p> required <code>anno_settings</code> <code>dict</code> <p>Annotation-specific settings.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Updated info_dict with added file paths and pipeline parameters.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def get_info_for_pipeline_anno(\n    settings: dict, info_dict: dict, assembly_accession: str, anno_settings: dict\n) -&gt; dict:\n    \"\"\"\n    Prepare and add file paths and pipeline-specific parameters needed for running annotation.\n\n    Args:\n        settings (dict): Pipeline settings.\n        info_dict (dict): Metadata dictionary for the assembly.\n        assembly_accession (str): Assembly accession string.\n        anno_settings (dict): Annotation-specific settings.\n\n    Returns:\n        dict: Updated info_dict with added file paths and pipeline parameters.\n    \"\"\"\n\n    logger.info(\"Getting info for pipeline settings for %s\", assembly_accession)\n    output_path = Path(settings[\"base_output_dir\"]) / assembly_accession\n    genome_files_dir = output_path / \"genome_files\"\n    toplevel_genome_file = output_path / f\"{info_dict['species_name']}_toplevel.fa\"\n\n    short_read_dir = output_path / \"short_read_fastq\"\n    if \"use_existing_short_read_dir\" in anno_settings and os.path.isdir(\n        anno_settings[\"use_existing_short_read_dir\"]\n    ):\n        short_read_dir = anno_settings[\"use_existing_short_read_dir\"]\n\n    long_read_dir = output_path / \"long_read_fastq\"\n    gst_dir = output_path / \"gst\"\n    rnaseq_summary_file = short_read_dir / f\"{info_dict['production_name']}.csv\"\n    rnaseq_summary_file_genus = (\n        short_read_dir / f\"{info_dict['production_name']}_gen.csv\"\n    )\n    long_read_summary_file = (\n        long_read_dir / f\"{info_dict['production_name']}_long_read.csv\"\n    )\n    reheadered_toplevel_genome_file = (\n        output_path / f\"{info_dict['species_name']}_reheadered_toplevel.fa\"\n    )\n    diamond_validation_db = Path(anno_settings[\"diamond_validation_db\"])\n    current_genebuild = settings[\"current_genebuild\"]\n    num_threads = anno_settings[\"num_threads\"]\n    ensembl_release = settings[\"release_number\"]\n\n    # Add values back to dictionary\n    info_dict.update(\n        {\n            \"output_path\": str(output_path),\n            \"genome_files_dir\": str(genome_files_dir),\n            \"toplevel_genome_file\": str(toplevel_genome_file),\n            \"reheadered_toplevel_genome_file\": str(reheadered_toplevel_genome_file),\n            \"short_read_dir\": str(short_read_dir),\n            \"long_read_dir\": str(long_read_dir),\n            \"gst_dir\": str(gst_dir),\n            \"diamond_validation_db\": Path(diamond_validation_db),\n            \"rnaseq_summary_file\": str(rnaseq_summary_file),\n            \"rnaseq_summary_file_genus\": str(rnaseq_summary_file_genus),\n            \"long_read_summary_file\": str(long_read_summary_file),\n            \"current_genebuild\": current_genebuild,\n            \"assembly_accession\": str(assembly_accession),\n            \"num_threads\": str(num_threads),\n            \"ensembl_release\": ensembl_release,\n        }\n    )\n\n    return info_dict\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.get_info_for_pipeline_main","title":"<code>get_info_for_pipeline_main(settings, info_dict, assembly_accession)</code>","text":"<p>Prepare and add file paths and pipeline-specific parameters needed for running annotation.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>dict</code> <p>Pipeline settings.</p> required <code>info_dict</code> <code>dict</code> <p>Metadata dictionary for the assembly.</p> required <code>assembly_accession</code> <code>str</code> <p>Assembly accession string.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Updated info_dict with added file paths and pipeline parameters.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def get_info_for_pipeline_main(\n    settings: dict, info_dict: dict, assembly_accession: str\n) -&gt; dict:\n    \"\"\"\n    Prepare and add file paths and pipeline-specific parameters needed for running annotation.\n\n    Args:\n        settings (dict): Pipeline settings.\n        info_dict (dict): Metadata dictionary for the assembly.\n        assembly_accession (str): Assembly accession string.\n\n    Returns:\n        dict: Updated info_dict with added file paths and pipeline parameters.\n    \"\"\"\n\n    logger.info(\"Getting info for pipeline settings for GCA %s\", assembly_accession)\n    output_path = (\n        Path(settings[\"base_output_dir\"])\n        / info_dict[\"species_name\"]\n        / assembly_accession\n    )\n    rnaseq_dir = output_path / \"rnaseq\"\n    long_read_dir = output_path / \"long_read\"\n    gst_dir = output_path / \"gst\"\n    rnaseq_summary_file = rnaseq_dir / f\"{info_dict['species_name']}.csv\"\n    rnaseq_summary_file_genus = rnaseq_dir / f\"{info_dict['species_name']}_gen.csv\"\n    long_read_fastq_dir = long_read_dir / \"input\"\n    current_genebuild = settings[\"current_genebuild\"]\n    registry_file = output_path / \"Databases.pm\"\n    release_number = settings[\"release_number\"]\n    dbname_accession = assembly_accession.replace(\".\", \"v\").replace(\"_\", \"\").lower()\n    email_address = settings[\"email\"]\n    dbowner = settings[\"dbowner\"]\n    user_r = settings[\"user_r\"]\n    user = settings[\"user\"]\n    password = settings[\"password\"]\n    server_set = settings[\"server_set\"]\n    pipeline_name = settings[\"pipeline_name\"]\n    long_read_summary_file = (\n        long_read_dir / f\"{info_dict['species_name']}_long_read.csv\"\n    )\n    long_read_summary_file_genus = (\n        long_read_dir / f\"{info_dict['species_name']}_long_read_gen.csv\"\n    )\n    pipe_db_name = f\"{dbowner}_{dbname_accession}_pipe_{release_number}\"\n\n    # Add values back to dictionary\n    info_dict.update(\n        {\n            \"output_path\": str(output_path),\n            \"rnaseq_dir\": str(rnaseq_dir),\n            \"long_read_fastq_dir\": str(long_read_fastq_dir),\n            \"registry_file\": str(registry_file),\n            \"long_read_dir\": str(long_read_dir),\n            \"gst_dir\": str(gst_dir),\n            \"rnaseq_summary_file\": str(rnaseq_summary_file),\n            \"rnaseq_summary_file_genus\": str(rnaseq_summary_file_genus),\n            \"current_genebuild\": current_genebuild,\n            \"assembly_accession\": str(assembly_accession),\n            \"release_number\": release_number,\n            \"dbname_accession\": str(dbname_accession),\n            \"email_address\": str(email_address),\n            \"dbowner\": str(dbowner),\n            \"user_r\": str(user_r),\n            \"user\": str(user),\n            \"password\": str(password),\n            \"server_set\": server_set,\n            \"pipeline_name\": str(pipeline_name),\n            \"long_read_summary_file\": str(long_read_summary_file),\n            \"long_read_summary_file_genus\": str(long_read_summary_file_genus),\n            \"pipe_db_name\": str(pipe_db_name),\n        }\n    )\n\n    return info_dict\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.get_metadata_from_registry","title":"<code>get_metadata_from_registry(server_info, assembly_accession, settings)</code>","text":"<p>Retrieve registry metadata for a given genome assembly accession or list of accessions.</p> <p>Supports two modes: - If 'init_file' is specified in settings, loads registry info via custom INI file parsing. - Otherwise, queries the MySQL database for metadata matching the accession(s).</p> <p>Parameters:</p> Name Type Description Default <code>server_info</code> <code>dict</code> <p>MySQL server connection info with 'registry' key.</p> required <code>assembly_accession</code> <code>str or list</code> <p>Single GCA accession or list of GCAs.</p> required <code>settings</code> <code>dict</code> <p>Additional parameters, may include 'init_file'.</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>dict or None: Assembly metadata dictionary if found, None if no record matches,           or empty dict if an error occurs.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If 'init_file' is specified but not found.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def get_metadata_from_registry(\n    server_info: dict, assembly_accession, settings: dict\n) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"\n    Retrieve registry metadata for a given genome assembly accession or list of accessions.\n\n    Supports two modes:\n    - If 'init_file' is specified in settings, loads registry info via custom INI file parsing.\n    - Otherwise, queries the MySQL database for metadata matching the accession(s).\n\n    Args:\n        server_info (dict): MySQL server connection info with 'registry' key.\n        assembly_accession (str or list): Single GCA accession or list of GCAs.\n        settings (dict): Additional parameters, may include 'init_file'.\n\n    Returns:\n        dict or None: Assembly metadata dictionary if found, None if no record matches,\n                      or empty dict if an error occurs.\n\n    Raises:\n        FileNotFoundError: If 'init_file' is specified but not found.\n    \"\"\"\n\n    # Check if using custom init file\n    if \"init_file\" in settings and settings[\"init_file\"]:\n        logger.info(\"Initialization file detected\")\n        init_file = Path(settings[\"init_file\"])\n        if init_file.exists():\n            logger.info(\"Loading info from init file\")\n            registry_info = custom_loading(settings)\n            registry_info = assign_clade_info_custom_loading(registry_info)\n            return registry_info\n        raise FileNotFoundError(f\"INI file not found: {init_file}\")\n\n    try:\n        if isinstance(assembly_accession, str):\n            # single accession \u2192 wrap in list\n            assembly_accessions = [assembly_accession]\n        else:\n            assembly_accessions = assembly_accession\n\n        # Build placeholders for SQL query\n        placeholders = \",\".join([\"%s\"] * len(assembly_accessions))\n\n        registry_query = f\"\"\"\n            SELECT \n                s.species_taxon_id, \n                a.lowest_taxon_id AS taxon_id,\n                a.asm_name AS assembly_name,\n                s.common_name, \n                a.refseq_accession AS assembly_refseq_accession,\n                a.release_date AS assembly_date,\n                s.scientific_name AS species_name,\n                a.assembly_id, \n                mb.bioproject_name AS assembly_group\n            FROM assembly a\n            JOIN bioproject b ON a.assembly_id = b.assembly_id\n            JOIN species s ON a.lowest_taxon_id = s.lowest_taxon_id\n            LEFT JOIN main_bioproject mb ON b.bioproject_id = mb.bioproject_id\n            WHERE CONCAT(a.gca_chain, '.', a.gca_version) IN ({placeholders})\n        \"\"\"\n\n        registry_info = mysql_fetch_data(\n            registry_query,\n            host=server_info[\"registry\"][\"db_host\"],\n            user=server_info[\"registry\"][\"db_user\"],\n            port=server_info[\"registry\"][\"db_port\"],\n            database=server_info[\"registry\"][\"db_name\"],\n            password=\"\",\n            params=assembly_accessions,\n        )\n        if not registry_info:\n            raise ValueError(\n                f\"No registry data found for accessions: {assembly_accessions}\"\n            )\n\n        logger.info(f\"Registry query successful for {assembly_accessions}\")\n        return registry_info[0]\n\n    except pymysql.Error as err:\n        logger.error(\"MySQL error: %s\", err)\n        return {}\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.get_rna_and_busco_check_threshold","title":"<code>get_rna_and_busco_check_threshold(anno_settings)</code>","text":"<p>Extract thresholds for RNA-seq and BUSCO checks from the pipeline settings.</p> <p>Parameters:</p> Name Type Description Default <code>anno_settings</code> <code>dict</code> <p>Pipeline settings dictionary.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary with keys 'busco_threshold', 'busco_lower_threshold',   'busco_difference_threshold', 'rnaseq_main_file_min_lines',   and 'rnaseq_genus_file_min_lines'.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def get_rna_and_busco_check_threshold(anno_settings: dict) -&gt; dict:\n    \"\"\"\n    Extract thresholds for RNA-seq and BUSCO checks from the pipeline settings.\n\n    Args:\n        anno_settings (dict): Pipeline settings dictionary.\n\n    Returns:\n        dict: Dictionary with keys 'busco_threshold', 'busco_lower_threshold',\n              'busco_difference_threshold', 'rnaseq_main_file_min_lines',\n              and 'rnaseq_genus_file_min_lines'.\n    \"\"\"\n\n    return {\n        \"busco_threshold\": anno_settings[\"busco_threshold\"],\n        \"busco_lower_threshold\": anno_settings[\"busco_lower_threshold\"],\n        \"busco_difference_threshold\": anno_settings[\"busco_difference_threshold\"],\n        \"rnaseq_main_file_min_lines\": anno_settings[\"rnaseq_main_file_min_lines\"],\n        \"rnaseq_genus_file_min_lines\": anno_settings[\"rnaseq_genus_file_min_lines\"],\n    }\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.get_server_settings_anno","title":"<code>get_server_settings_anno(settings)</code>","text":"<p>Determine and return server connection settings for pipeline and core databases.</p> <p>Uses either custom server settings from the configuration or falls back to environment-variable-based defaults depending on the 'server_set' parameter.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>dict</code> <p>The pipeline settings dictionary.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Nested dictionary with keys 'pipeline_db' and 'core_db', each containing   connection parameters like 'db_host', 'db_user', 'db_port', and 'db_password'.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the 'server_set' value is unknown or unsupported.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def get_server_settings_anno(settings: dict) -&gt; dict:\n    \"\"\"\n    Determine and return server connection settings for pipeline and core databases.\n\n    Uses either custom server settings from the configuration or falls back\n    to environment-variable-based defaults depending on the 'server_set' parameter.\n\n    Args:\n        settings (dict): The pipeline settings dictionary.\n\n    Returns:\n        dict: Nested dictionary with keys 'pipeline_db' and 'core_db', each containing\n              connection parameters like 'db_host', 'db_user', 'db_port', and 'db_password'.\n\n    Raises:\n        ValueError: If the 'server_set' value is unknown or unsupported.\n    \"\"\"\n\n    logger.info(\"Getting server settings\")\n    custom = settings.get(\"custom_server\", {})\n    # Check if all custom_server values are non-empty\n    if all(\n        custom.get(k)\n        for k in [\n            \"pipeline_db_host\",\n            \"pipeline_db_port\",\n            \"core_db_host\",\n            \"core_db_port\",\n        ]\n    ):\n        logger.info(\"Custom server settings detected\")\n        return {\n            \"pipeline_db\": {\n                \"db_host\": custom[\"pipeline_db_host\"],\n                \"db_user\": settings[\"user\"],\n                \"db_port\": custom[\"pipeline_db_port\"],\n                \"db_password\": settings[\"password\"],\n            },\n            \"core_db\": {\n                \"db_host\": custom[\"core_db_host\"],\n                \"db_user\": settings[\"user\"],\n                \"db_port\": custom[\"core_db_port\"],\n                \"db_password\": settings[\"password\"],\n            },\n        }\n    else:\n        # Fallback based on server_set\n        server_set = str(settings.get(\"server_set\", \"1\"))  # default to \"1\" if missing\n\n        if server_set == \"1\":\n            logger.info(\"Server set 1 detected\")\n            return {\n                \"pipeline_db\": {\n                    \"db_host\": os.environ.get(\"GBS4\"),\n                    \"db_user\": settings[\"user\"],\n                    \"db_port\": int(os.environ.get(\"GBP4\")),\n                    \"db_password\": settings[\"password\"],\n                },\n                \"core_db\": {\n                    \"db_host\": os.environ.get(\"GBS3\"),\n                    \"db_user\": settings[\"user\"],\n                    \"db_port\": int(os.environ.get(\"GBP3\")),\n                    \"db_password\": settings[\"password\"],\n                },\n            }\n\n        elif server_set == \"2\":\n            logger.info(\"Server set 2 detected\")\n            return {\n                \"pipeline_db\": {\n                    \"db_host\": os.environ.get(\"GBS7\"),\n                    \"db_user\": settings[\"user\"],\n                    \"db_port\": int(os.environ.get(\"GBP7\")),\n                    \"db_password\": settings[\"password\"],\n                },\n                \"core_db\": {\n                    \"db_host\": os.environ.get(\"GBS6\"),\n                    \"db_user\": settings[\"user\"],\n                    \"db_port\": int(os.environ.get(\"GBP6\")),\n                    \"db_password\": settings[\"password\"],\n                },\n            }\n        else:\n            raise ValueError(f\"Unknown server_set value: {server_set}\")\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.get_server_settings_main","title":"<code>get_server_settings_main(settings)</code>","text":"<p>Determine and return server connection settings for pipeline and core databases.</p> <p>Uses either custom server settings from the configuration or falls back to environment-variable-based defaults depending on the 'server_set' parameter.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>dict</code> <p>The pipeline settings dictionary.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Nested dictionary with keys 'pipeline_db' and 'core_db', each containing   connection parameters like 'db_host', 'db_user', 'db_port', and 'db_password'.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the 'server_set' value is unknown or unsupported.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def get_server_settings_main(settings: dict) -&gt; dict:\n    \"\"\"\n    Determine and return server connection settings for pipeline and core databases.\n\n    Uses either custom server settings from the configuration or falls back\n    to environment-variable-based defaults depending on the 'server_set' parameter.\n\n    Args:\n        settings (dict): The pipeline settings dictionary.\n\n    Returns:\n        dict: Nested dictionary with keys 'pipeline_db' and 'core_db', each containing\n              connection parameters like 'db_host', 'db_user', 'db_port', and 'db_password'.\n\n    Raises:\n        ValueError: If the 'server_set' value is unknown or unsupported.\n    \"\"\"\n\n    logger.info(\"Getting server settings\")\n    custom = settings.get(\"custom_server\", {})\n    # Check if all custom_server values are non-empty\n    if all(\n        custom.get(k)\n        for k in [\n            \"pipeline_db_host\",\n            \"pipeline_db_port\",\n            \"core_db_host\",\n            \"core_db_port\",\n            \"databases_host\",\n            \"databases_port\",\n        ]\n    ):\n        logger.info(\"Custom server settings detected\")\n        return {\n            \"pipeline_db\": {\n                \"db_host\": custom[\"pipeline_db_host\"],\n                \"db_user\": settings[\"user\"],\n                \"db_port\": custom[\"pipeline_db_port\"],\n                \"db_password\": settings[\"password\"],\n            },\n            \"core_db\": {\n                \"db_host\": custom[\"core_db_host\"],\n                \"db_user\": settings[\"user\"],\n                \"db_port\": custom[\"core_db_port\"],\n                \"db_password\": settings[\"password\"],\n            },\n            \"databases\": {\n                \"db_host\": custom[\"databases_host\"],\n                \"db_user\": settings[\"user\"],\n                \"db_port\": custom[\"databases_port\"],\n                \"db_password\": settings[\"password\"],\n            },\n        }\n    else:\n        # Fallback based on server_set\n        server_set = str(settings.get(\"server_set\", \"1\"))  # default to \"1\" if missing\n\n        if server_set == \"1\":\n            logger.info(\"Server set 1 detected\")\n            return {\n                \"pipeline_db\": {\n                    \"db_host\": os.environ.get(\"GBS4\"),\n                    \"db_user\": settings[\"user\"],\n                    \"db_port\": int(os.environ.get(\"GBP4\")),\n                    \"db_password\": settings[\"password\"],\n                },\n                \"core_db\": {\n                    \"db_host\": os.environ.get(\"GBS2\"),\n                    \"db_user\": settings[\"user\"],\n                    \"db_port\": int(os.environ.get(\"GBP2\")),\n                    \"db_password\": settings[\"password\"],\n                },\n                \"databases\": {\n                    \"db_host\": os.environ.get(\"GBS3\"),\n                    \"db_user\": settings[\"user\"],\n                    \"db_port\": int(os.environ.get(\"GBP3\")),\n                    \"db_password\": settings[\"password\"],\n                },\n            }\n\n        elif server_set == \"2\":\n            logger.info(\"Server set 2 detected\")\n            return {\n                \"pipeline_db\": {\n                    \"db_host\": os.environ.get(\"GBS7\"),\n                    \"db_user\": settings[\"user\"],\n                    \"db_port\": int(os.environ.get(\"GBP7\")),\n                    \"db_password\": settings[\"password\"],\n                },\n                \"core_db\": {\n                    \"db_host\": os.environ.get(\"GBS5\"),\n                    \"db_user\": settings[\"user\"],\n                    \"db_port\": int(os.environ.get(\"GBP5\")),\n                    \"db_password\": settings[\"password\"],\n                },\n                \"databases\": {\n                    \"db_host\": os.environ.get(\"GBS6\"),\n                    \"db_user\": settings[\"user\"],\n                    \"db_port\": int(os.environ.get(\"GBP6\")),\n                    \"db_password\": settings[\"password\"],\n                },\n            }\n        else:\n            raise ValueError(f\"Unknown server_set value: {server_set}\")\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.load_anno_settings","title":"<code>load_anno_settings()</code>","text":"<p>Load the annotation-specific settings from a hardcoded path relative to the environment variable 'ENSCODE'.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Parsed annotation settings dictionary.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the anno_settings.json file is not found.</p> <code>JSONDecodeError</code> <p>If the file contents are not valid JSON.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def load_anno_settings() -&gt; dict:\n    \"\"\"\n    Load the annotation-specific settings from a hardcoded path relative to\n    the environment variable 'ENSCODE'.\n\n    Returns:\n        dict: Parsed annotation settings dictionary.\n\n    Raises:\n        FileNotFoundError: If the anno_settings.json file is not found.\n        json.JSONDecodeError: If the file contents are not valid JSON.\n    \"\"\"\n    logger.info(\"Loading anno settings json\")\n    settings = os.path.join(\n        os.environ.get(\"ENSCODE\"),\n        \"ensembl-genes\",\n        \"src\",\n        \"python\",\n        \"ensembl\",\n        \"genes\",\n        \"info_from_registry\",\n        \"anno_settings.json\",\n    )\n    with open(settings, \"r\") as f:\n        return json.load(f)\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.load_main_settings","title":"<code>load_main_settings()</code>","text":"<p>Load the annotation-specific settings from a hardcoded path relative to the environment variable 'ENSCODEf'.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Parsed annotation settings dictionary.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the anno_settings.json file is not found.</p> <code>JSONDecodeError</code> <p>If the file contents are not valid JSON.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def load_main_settings() -&gt; dict:\n    \"\"\"\n    Load the annotation-specific settings from a hardcoded path relative to\n    the environment variable 'ENSCODEf'.\n\n    Returns:\n        dict: Parsed annotation settings dictionary.\n\n    Raises:\n        FileNotFoundError: If the anno_settings.json file is not found.\n        json.JSONDecodeError: If the file contents are not valid JSON.\n    \"\"\"\n    logger.info(\"Loading main settings json\")\n    settings = os.path.join(\n        os.environ.get(\"ENSCODE\"),\n        \"ensembl-genes\",\n        \"src\",\n        \"python\",\n        \"ensembl\",\n        \"genes\",\n        \"info_from_registry\",\n        \"main_settings.json\",\n    )\n    with open(settings, \"r\") as f:\n        return json.load(f)\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.load_settings","title":"<code>load_settings(settings_file)</code>","text":"<p>Load JSON-formatted pipeline settings from a given file path.</p> <p>Parameters:</p> Name Type Description Default <code>settings_file</code> <code>str</code> <p>Path to the JSON settings file.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Parsed settings dictionary.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the settings file does not exist.</p> <code>JSONDecodeError</code> <p>If the file contents are not valid JSON.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def load_settings(settings_file: str) -&gt; dict:\n    \"\"\"\n    Load JSON-formatted pipeline settings from a given file path.\n\n    Args:\n        settings_file (str): Path to the JSON settings file.\n\n    Returns:\n        dict: Parsed settings dictionary.\n\n    Raises:\n        FileNotFoundError: If the settings file does not exist.\n        json.JSONDecodeError: If the file contents are not valid JSON.\n    \"\"\"\n\n    logger.info(f\"Loading settings from: {settings_file}\")\n    settings_path = Path(settings_file)\n    if not settings_path.exists():\n        raise FileNotFoundError(f\"Settings file not found: {settings_path}\")\n    with open(settings_path, \"r\") as f:\n        return json.load(f)\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/start_pipeline_from_registry/#ensembl.genes.info_from_registry.start_pipeline_from_registry.main","title":"<code>main(gcas, settings_file)</code>","text":"<p>Create parameters for annotation pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>gcas</code> <code>str</code> <p>Path to the list of GCAs</p> required <code>settings_file </code> <p>Pipeline settings JSON</p> required <p>Returns:</p> Name Type Description <code>all_output_params</code> <code>dict</code> <p>Dictionary of all GCA output parameters</p> <code>saved_paths</code> <code>dict</code> <p>Paths to saved JSONs, with separate entries for 'anno' and 'main'</p> Source code in <code>src/python/ensembl/genes/info_from_registry/start_pipeline_from_registry.py</code> <pre><code>def main(gcas: str, settings_file: str) -&gt; tuple[dict, dict, dict]:\n    \"\"\"\n    Create parameters for annotation pipeline.\n\n    Args:\n        gcas (str): Path to the list of GCAs\n        settings_file : Pipeline settings JSON\n\n    Returns:\n        all_output_params (dict): Dictionary of all GCA output parameters\n        saved_paths (dict): Paths to saved JSONs, with separate entries for 'anno' and 'main'\n    \"\"\"\n\n    # Load settings\n    settings = load_settings(settings_file)\n\n    # Read in GCAs from file\n    with open(gcas, \"r\") as f:\n        lines = [line.strip() for line in f if line.strip()]\n\n    gca_dict = {gca: {} for gca in lines}\n    logger.info(f\"Found {len(gca_dict)} GCAs\")\n\n    # Check if init_file exists\n    has_init_file = settings.get(\"init_file\") and os.path.isfile(settings[\"init_file\"])\n\n    all_output_params = {}\n\n    # Loop through GCAs\n    for gca in gca_dict:\n        gca_dict[gca][\"assembly_accession\"] = gca\n\n        # Registry info\n        server_info = {\n            \"registry\": {\n                \"db_host\": os.environ.get(\"GBS1\"),\n                \"db_user\": settings[\"user_r\"],\n                \"db_user_w\": settings[\"user\"],\n                \"db_port\": int(os.environ.get(\"GBP1\")),\n                \"db_name\": \"gb_assembly_metadata\",\n                \"password\": settings[\"password\"],\n            }\n        }\n        logger.info(server_info[\"registry\"])\n\n        # Check if it has annotation history\n        if not has_init_file and int(settings.get(\"current_genebuild\", 0)) == 0:\n            check_if_annotated(gca, server_info)\n\n        # Create output params\n        info_dict = add_generated_data(server_info, gca, settings)\n\n        if \"repbase_library\" in info_dict and isinstance(\n            info_dict[\"repbase_library\"], str\n        ):\n            # Vertebrate (main) pipeline\n            pipeline_type = \"main\"\n\n            server_settings = get_server_settings_main(settings)\n            server_info.update(server_settings)\n            main_settings = load_main_settings()\n\n            info_dict[\"databases_host\"] = server_info[\"databases\"][\"db_host\"]\n            info_dict[\"databases_port\"] = server_info[\"databases\"][\"db_port\"]\n            info_dict[\"registry_host\"] = server_info[\"registry\"][\"db_host\"]\n            info_dict[\"registry_port\"] = server_info[\"registry\"][\"db_port\"]\n            info_dict[\"registry_db\"] = server_info[\"registry\"][\"db_name\"]\n            info_dict[\"pipe_db_host\"] = server_info[\"pipeline_db\"][\"db_host\"]\n            info_dict[\"pipe_db_port\"] = server_info[\"pipeline_db\"][\"db_port\"]\n            info_dict[\"dna_db_host\"] = server_info[\"core_db\"][\"db_host\"]\n            info_dict[\"dna_db_port\"] = server_info[\"core_db\"][\"db_port\"]\n\n            if main_settings.get(\"replace_repbase_with_red_to_mask\") == 1:\n                info_dict[\"first_choice_repeat\"] = \"repeatdetector\"\n\n            # Protein BLAST DB based on clade\n            clade = info_dict.get(\"clade\", \"\").lower()\n            if clade in [\"mammalia\", \"rodentia\", \"primates\", \"marsupials\"]:\n                info_dict[\"protein_blast_db_file\"] = \"uniprot_mammalia_sp\"\n            elif clade in [\"teleostei\", \"sharks\"]:\n                info_dict[\"protein_blast_db_file\"] = \"uniprot_vertebrataSP_plus_fishTR\"\n            else:\n                info_dict[\"protein_blast_db_file\"] = \"uniprot_vertebrata_sp\"\n\n            # RepeatModeler library\n            parent_name = get_parent_taxon(server_info, info_dict[\"species_taxon_id\"])\n            parent_name = parent_name.lower().replace(\" \", \"_\")\n            info_dict[\"repeatmodeler_library\"] = os.path.join(\n                os.environ[\"REPEATMODELER_DIR\"],\n                \"species\",\n                parent_name,\n                f\"{parent_name}.repeatmodeler.fa\",\n            )\n\n            output_params = get_info_for_pipeline_main(settings, info_dict, gca)\n            create_dir(output_params[\"output_path\"])\n            edit_config_main(main_settings, output_params, pipeline_type)\n\n            projection_source_info = current_projection_source_db(\n                output_params[\"projection_source_production_name\"]\n            )\n            output_params.update(\n                projection_source_info\n            )  # Adds db_name, server, port to output_params\n\n            output_params[\"stable_id_prefix\"] = get_species_prefix(\n                output_params[\"taxon_id\"], server_info\n            )\n            output_params[\"stable_id_start\"] = get_stable_space(\n                output_params[\"taxon_id\"],\n                gca,\n                output_params[\"assembly_id\"],\n                server_info,\n            )\n            edit_config_main(main_settings, output_params, pipeline_type)\n            copy_general_module()\n\n        else:\n            # Non-vertebrate (anno) pipeline\n            pipeline_type = \"anno\"\n            gca_dict[gca][\n                \"pipe_db_name\"\n            ] = f\"{settings['dbowner']}_{settings['pipeline_name']}_pipe_{settings['release_number']}\"\n            server_settings = get_server_settings_anno(settings)\n            server_info.update(server_settings)\n\n            server_info.setdefault(\"pipeline_db\", {})[\"db_name\"] = gca_dict[gca][\n                \"pipe_db_name\"\n            ]\n            server_info.setdefault(\"core_db\", {})[\"db_name\"] = info_dict[\"core_dbname\"]\n            info_dict[\"core_db\"] = server_info[\"core_db\"]\n            info_dict[\"registry_db\"] = server_info[\"registry\"]\n\n            # Assign BUSCO lineage\n            busco_lineage_file = os.path.join(\n                os.environ.get(\"ENSCODE\"),\n                \"ensembl-genes\",\n                \"src\",\n                \"python\",\n                \"ensembl\",\n                \"genes\",\n                \"metrics\",\n                \"busco_lineage.json\",\n            )\n\n            with open(busco_lineage_file, \"r\") as f:\n                dataset = json.load(f)\n\n            ncbi_url = f\"https://api.ncbi.nlm.nih.gov/datasets/v2alpha/taxonomy/taxon/{info_dict['taxon_id']}/dataset_report\"\n\n            busco_group_find = get_dataset_match(ncbi_url, dataset)\n\n            if busco_group_find is not None:\n                logger.info(\n                    f\"Closest BUSCO lineage identified as {busco_group_find} for taxon ID {info_dict['taxon_id']}\"\n                )\n                info_dict[\"busco_group\"] = busco_group_find\n            else:\n                logger.info(\n                    f\"Falling back on BUSCO lineage from clade settings {info_dict['busco_group']}\"\n                )\n\n            # Load anno settings\n            anno_settings = load_anno_settings()\n\n            # DB adaptors\n            core_adaptor = {\n                \"host\": server_info[\"core_db\"][\"db_host\"],\n                \"port\": server_info[\"core_db\"][\"db_port\"],\n                \"dbname\": info_dict[\"core_dbname\"],\n                \"user\": settings[\"user\"],\n                \"pass\": settings[\"password\"],\n                \"species\": info_dict[\"production_name\"],\n                \"group\": \"core\",\n            }\n            registry_path = create_registry_entry(settings, server_info, core_adaptor)\n\n            output_params = get_info_for_pipeline_anno(\n                settings, info_dict, gca, anno_settings\n            )\n            output_params[\"registry_file\"] = Path(registry_path)\n\n            build_annotation_commands(\n                core_adaptor, output_params, anno_settings, settings\n            )\n\n            rna_busco_settings = get_rna_and_busco_check_threshold(anno_settings)\n            output_params.update(rna_busco_settings)\n            output_params[\"stable_id_prefix\"] = get_species_prefix(\n                output_params[\"taxon_id\"], server_info\n            )\n            output_params[\"stable_id_start\"] = get_stable_space(\n                output_params[\"taxon_id\"],\n                gca,\n                output_params[\"assembly_id\"],\n                server_info,\n            )\n            # Create directories\n            create_dir(output_params[\"output_path\"])\n            dirs_to_create = [\n                output_params[\"genome_files_dir\"],\n                output_params[\"short_read_dir\"],\n                output_params[\"long_read_dir\"],\n                output_params[\"gst_dir\"],\n            ]\n\n            for d in dirs_to_create:\n                try:\n                    os.makedirs(d, exist_ok=True)\n                except Exception as e:\n                    raise RuntimeError(f\"Failed to create dir: {d}\") from e\n\n        # Store output params\n        output_params[\"pipeline\"] = pipeline_type\n        all_output_params[gca] = output_params\n        logger.info(f\"Finished with {gca}\")\n\n    # -------------------------\n    # Save JSONs\n    # -------------------------\n    saved_paths = {}\n\n    # Save anno GCAs as a single file\n    anno_params = {\n        g: p for g, p in all_output_params.items() if p[\"pipeline\"] == \"anno\"\n    }\n\n    # Edit anno config\n    if anno_params:\n        # Call edit_config_anno ONCE here with only the generic settings\n        first_gca_params = next(iter(anno_params.values()))\n        edit_config_anno(\n            anno_settings,\n            settings,\n            first_gca_params,  # just need a representative dict with registry_file, db names, etc.\n            \"anno\",\n            server_settings,\n        )\n\n        anno_json_path = (\n            Path(settings[\"base_output_dir\"]) / \"non_vert_pipeline_params.json\"\n        )\n        anno_json_path.parent.mkdir(parents=True, exist_ok=True)\n        with anno_json_path.open(\"w\") as f:\n            json.dump(anno_params, f, indent=2, default=str)\n        logger.info(f\"Saved anno parameters to: {anno_json_path}\")\n        saved_paths[\"anno\"] = anno_json_path\n\n    # Save main GCAs as separate files\n    main_params = {\n        g: p for g, p in all_output_params.items() if p[\"pipeline\"] == \"main\"\n    }\n    main_json_paths = {}\n    for gca, params in main_params.items():\n        path = Path(params[\"output_path\"]) / \"main_pipeline_params.json\"\n        path.parent.mkdir(parents=True, exist_ok=True)\n        with path.open(\"w\") as f:\n            json.dump({gca: params}, f, indent=2, default=str)\n        logger.info(f\"Saved main parameters for {gca} to: {path}\")\n        main_json_paths[gca] = path\n\n    if main_json_paths:\n        saved_paths[\"main\"] = main_json_paths\n\n    # Log if mixed pipelines are present\n    pipelines_present = set(p[\"pipeline\"] for p in all_output_params.values())\n    if \"anno\" in pipelines_present and \"main\" in pipelines_present:\n        msg = \"ATTENTION: Both 'anno' and 'main' GCAs detected in input!\"\n        logger.info(msg)\n        print(msg)\n\n    logger.info(\"DONE\")\n    return server_info, all_output_params, saved_paths\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/taxonomy_helper/","title":"<code>ensembl.genes.info_from_registry.taxonomy_helper</code>","text":""},{"location":"ensembl/genes/info_from_registry/taxonomy_helper/#ensembl.genes.info_from_registry.taxonomy_helper","title":"<code>ensembl.genes.info_from_registry.taxonomy_helper</code>","text":"<p>Module to assign clade information based on taxonomy data retrieved from a registry MySQL database and static JSON configuration.</p> <p>Functions:</p> Name Description <code>- create_tax_dictionary_from_registry</code> <p>Fetches taxonomy hierarchy from the registry.</p> <code>- load_clade_data</code> <p>Loads clade definitions from a static JSON file.</p> <code>- assign_clade</code> <p>Matches a taxon to a clade based on hierarchy.</p> <code>- assign_clade_info_custom_loading</code> <p>Loads clade details by name from JSON config.</p>"},{"location":"ensembl/genes/info_from_registry/taxonomy_helper/#ensembl.genes.info_from_registry.taxonomy_helper.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/taxonomy_helper/#ensembl.genes.info_from_registry.taxonomy_helper.assign_clade","title":"<code>assign_clade(server_info, registry_info)</code>","text":"<p>Assign a clade to a given taxon based on clade data and taxonomy hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>server_info</code> <code>dict</code> <p>MySQL connection information under 'registry'.</p> required <code>registry_info</code> <code>dict</code> <p>Dictionary with at least a 'taxon_id' key.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[str, Optional[int], Optional[dict[str, any]]]</code> <ul> <li>internal_clade (str): Name of the assigned clade (or 'Unassigned').</li> <li>genus_taxon_id (int or None): Genus-level taxon ID, if found.</li> <li>clade_details (dict or None): Dictionary of clade properties excluding taxon_id.</li> </ul> Source code in <code>src/python/ensembl/genes/info_from_registry/taxonomy_helper.py</code> <pre><code>def assign_clade(\n    server_info: dict, registry_info: dict\n) -&gt; tuple[str, Optional[int], Optional[dict[str, any]]]:\n    \"\"\"\n    Assign a clade to a given taxon based on clade data and taxonomy hierarchy.\n\n    Args:\n        server_info (dict): MySQL connection information under 'registry'.\n        registry_info (dict): Dictionary with at least a 'taxon_id' key.\n\n    Returns:\n        tuple:\n            - internal_clade (str): Name of the assigned clade (or 'Unassigned').\n            - genus_taxon_id (int or None): Genus-level taxon ID, if found.\n            - clade_details (dict or None): Dictionary of clade properties excluding taxon_id.\n    \"\"\"\n\n    clade_data = load_clade_data()\n    taxonomy_dict = create_tax_dictionary_from_registry(server_info, registry_info)\n\n    # Accept both int and str keys\n    lowest_taxon_id = registry_info[\"taxon_id\"]\n    taxonomy_hierarchy = taxonomy_dict.get(str(lowest_taxon_id)) or taxonomy_dict.get(\n        lowest_taxon_id, []\n    )\n\n    if not taxonomy_hierarchy:\n        logging.warning(\n            f\"Taxonomy hierarchy not found for taxon ID {registry_info['taxon_id']}\"\n        )\n        return \"Unassigned\", None, None\n\n    internal_clade = \"Unassigned\"\n    genus_taxon_id = None\n    clade_details = None\n\n    # Get genus taxon_id\n    for taxon in taxonomy_hierarchy:\n        if taxon[\"taxon_class\"] == \"genus\":\n            genus_taxon_id = taxon[\"taxon_class_id\"]\n\n    # Step 1: try exact match on the lowest_taxon_id\n    for clade_name, details in clade_data.items():\n        clade_taxon_id = int(details.get(\"taxon_id\", -1))\n        if clade_taxon_id == lowest_taxon_id:\n            internal_clade = clade_name\n            clade_details = {k: v for k, v in details.items() if k != \"taxon_id\"}\n            clade_details[\"helixer_lineage\"] = clade_details.get(\"helixer_lineage\", \"\")\n\n            logging.info(\n                f\"Exact match: Assigned clade '{internal_clade}' for taxon {registry_info['taxon_id']}\"\n            )\n            return internal_clade, genus_taxon_id, clade_details\n\n    # Step 2: Walk up the taxonomy hierarchy\n    taxon_classes_order = [\n        \"species\",\n        \"genus\",\n        \"family\",\n        \"order\",\n        \"class\",\n        \"phylum\",\n        \"kingdom\",\n    ]\n\n    for taxon_class in taxon_classes_order:\n        matching = next(\n            (t for t in taxonomy_hierarchy if t[\"taxon_class\"] == taxon_class), None\n        )\n        if not matching:\n            continue\n        current_taxon_id = int(matching[\"taxon_class_id\"])\n\n        for clade_name, details in clade_data.items():\n            clade_taxon_id = int(details.get(\"taxon_id\", -1))\n            if clade_taxon_id == current_taxon_id:\n                internal_clade = clade_name\n                clade_details = {k: v for k, v in details.items() if k != \"taxon_id\"}\n                clade_details[\"helixer_lineage\"] = clade_details.get(\n                    \"helixer_lineage\", \"\"\n                )\n\n                logging.info(\n                    f\"Hierarchy match: Assigned clade '{internal_clade}' via {taxon_class} taxon_id {current_taxon_id}\"\n                )\n                return internal_clade, genus_taxon_id, clade_details\n\n    # No match found\n    logging.error(\n        f\"No clade found for taxon {registry_info['taxon_id']} in full hierarchy.\"\n    )\n    return \"Unassigned\", genus_taxon_id, None\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/taxonomy_helper/#ensembl.genes.info_from_registry.taxonomy_helper.assign_clade_info_custom_loading","title":"<code>assign_clade_info_custom_loading(registry_info)</code>","text":"<p>Look for a specific clade in the JSON data and return all values except for taxon_id.</p> <p>Parameters:</p> Name Type Description Default <code>registry_info</code> <code>dict</code> <p>Dictionary containing clade information with 'clade' key</p> required <p>Returns:</p> Type Description <code>Optional[dict[str, any]]</code> <p>dict or None: Dictionary containing all clade details except taxon_id,                  or None if clade not found</p> Source code in <code>src/python/ensembl/genes/info_from_registry/taxonomy_helper.py</code> <pre><code>def assign_clade_info_custom_loading(registry_info: dict) -&gt; Optional[dict[str, any]]:\n    \"\"\"\n    Look for a specific clade in the JSON data and return all values except for taxon_id.\n\n    Args:\n            registry_info (dict): Dictionary containing clade information with 'clade' key\n\n    Returns:\n            dict or None: Dictionary containing all clade details except taxon_id,\n                                     or None if clade not found\n    \"\"\"\n    clade_data = load_clade_data()\n\n    # Extract the clade name from the dictionary\n    clade_name = registry_info.get(\"clade\")\n\n    if not clade_name:\n        logging.error(\"No 'clade' key found in provided dictionary\")\n        return None\n\n    # Look for the specific clade in the dictionary\n    if clade_name in clade_data:\n        details = clade_data[clade_name]\n        # Return all details except taxon_id\n        clade_details = {k: v for k, v in details.items() if k != \"taxon_id\"}\n        clade_details[\"helixer_lineage\"] = clade_details.get(\"helixer_lineage\", \"\")\n\n        return clade_details\n    else:\n        logging.warning(f\"Clade '{clade_name}' not found in clade data\")\n        return None\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/taxonomy_helper/#ensembl.genes.info_from_registry.taxonomy_helper.create_tax_dictionary_from_registry","title":"<code>create_tax_dictionary_from_registry(server_info, registry_info)</code>","text":"<p>Query the registry MySQL database to construct taxonomy hierarchy for a given taxon ID.</p> <p>Parameters:</p> Name Type Description Default <code>server_info</code> <code>dict</code> <p>Dictionary containing MySQL connection parameters under 'registry' key.</p> required <code>registry_info</code> <code>dict</code> <p>Dictionary containing the 'taxon_id' key.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, list[dict[str, any]]]</code> <p>A dictionary mapping taxon IDs to a list of taxonomy class information,   or an empty dictionary if query fails.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/taxonomy_helper.py</code> <pre><code>def create_tax_dictionary_from_registry(\n    server_info: dict, registry_info: dict\n) -&gt; dict[str, list[dict[str, any]]]:\n    \"\"\"\n    Query the registry MySQL database to construct taxonomy hierarchy for a given taxon ID.\n\n    Args:\n        server_info (dict): Dictionary containing MySQL connection parameters under 'registry' key.\n        registry_info (dict): Dictionary containing the 'taxon_id' key.\n\n    Returns:\n        dict: A dictionary mapping taxon IDs to a list of taxonomy class information,\n              or an empty dictionary if query fails.\n    \"\"\"\n\n    taxon_id = registry_info[\"taxon_id\"]\n\n    taxonomy_query = \"\"\"\n        SELECT lowest_taxon_id, taxon_class_id, taxon_class\n        FROM taxonomy\n        WHERE lowest_taxon_id = %s\n        ORDER BY FIELD(taxon_class, 'species', 'genus', 'family', 'order', 'class', 'phylum', 'kingdom');\n    \"\"\"\n\n    try:\n        taxonomy_info = mysql_fetch_data(\n            taxonomy_query,\n            host=server_info[\"registry\"][\"db_host\"],\n            user=server_info[\"registry\"][\"db_user\"],\n            port=server_info[\"registry\"][\"db_port\"],\n            database=server_info[\"registry\"][\"db_name\"],\n            password=\"\",\n            params=taxon_id,\n        )\n\n        taxonomy_dict = {}\n        for row in taxonomy_info:\n            lowest_taxon_id = row[\"lowest_taxon_id\"]\n            if lowest_taxon_id not in taxonomy_dict:\n                taxonomy_dict[lowest_taxon_id] = []\n            taxonomy_dict[lowest_taxon_id].append(\n                {\n                    \"taxon_class_id\": row[\"taxon_class_id\"],\n                    \"taxon_class\": row[\"taxon_class\"],\n                }\n            )\n\n        logger.info(f\"Found taxonomy for {taxon_id}\")\n        return taxonomy_dict\n\n    except pymysql.Error as err:\n        logger.error(\"Error while fetching taxonomy info: %s\", err)\n        return {}\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/taxonomy_helper/#ensembl.genes.info_from_registry.taxonomy_helper.get_parent_taxon","title":"<code>get_parent_taxon(server_info, species_taxon_id)</code>","text":"<p>Fetch the parent taxon name from the taxonomy table for a given taxon ID.</p> <p>Parameters:</p> Name Type Description Default <code>server_info</code> <code>dict</code> <p>Server connection info with keys 'db_host', 'db_user', 'db_port', 'db_name'.</p> required <code>species_taxon_id</code> <code>int</code> <p>The taxon ID for which to find the parent taxon.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Parent taxon name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the taxon is not found.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/taxonomy_helper.py</code> <pre><code>def get_parent_taxon(server_info: dict, species_taxon_id: int) -&gt; str:\n    \"\"\"\n    Fetch the parent taxon name from the taxonomy table for a given taxon ID.\n\n    Args:\n        server_info (dict): Server connection info with keys 'db_host', 'db_user', 'db_port', 'db_name'.\n        species_taxon_id (int): The taxon ID for which to find the parent taxon.\n\n    Returns:\n        str: Parent taxon name.\n\n    Raises:\n        ValueError: If the taxon is not found.\n    \"\"\"\n    parent_query = \"\"\"\n        SELECT taxon_class_name\n        FROM taxonomy_name\n        WHERE taxon_class_id = %s;\n    \"\"\"\n\n    try:\n        result = mysql_fetch_data(\n            parent_query,\n            host=server_info[\"registry\"][\"db_host\"],\n            user=server_info[\"registry\"][\"db_user\"],\n            port=server_info[\"registry\"][\"db_port\"],\n            database=server_info[\"registry\"][\"db_name\"],\n            password=\"\",\n            params=(species_taxon_id,),  # must be a tuple\n        )\n\n        if not result:\n            raise ValueError(f\"No parent taxon found for taxon ID {species_taxon_id}\")\n\n        # Return as a single string\n        return str(result[0][\"taxon_class_name\"])\n\n    except Exception as e:\n        raise RuntimeError(f\"Error fetching parent taxon: {e}\")\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/taxonomy_helper/#ensembl.genes.info_from_registry.taxonomy_helper.load_clade_data","title":"<code>load_clade_data()</code>","text":"<p>Load clade definitions from a static JSON file.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, dict[str, any]]</code> <p>Dictionary containing clade configuration data.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the JSON file cannot be located.</p> <code>JSONDecodeError</code> <p>If the JSON is malformed.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/taxonomy_helper.py</code> <pre><code>def load_clade_data() -&gt; dict[str, dict[str, any]]:\n    \"\"\"\n    Load clade definitions from a static JSON file.\n\n    Returns:\n        dict: Dictionary containing clade configuration data.\n\n    Raises:\n        FileNotFoundError: If the JSON file cannot be located.\n        json.JSONDecodeError: If the JSON is malformed.\n    \"\"\"\n    json_file = os.path.join(\n        os.environ.get(\"ENSCODE\"),\n        \"ensembl-genes\",\n        \"src\",\n        \"python\",\n        \"ensembl\",\n        \"genes\",\n        \"info_from_registry\",\n        \"clade_settings.json\",\n    )\n\n    with open(json_file, \"r\") as f:\n        logging.info(\"Loading clade settings json file.\")\n        return json.load(f)\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/update_assembly_registry/","title":"<code>ensembl.genes.info_from_registry.update_assembly_registry</code>","text":""},{"location":"ensembl/genes/info_from_registry/update_assembly_registry/#ensembl.genes.info_from_registry.update_assembly_registry","title":"<code>ensembl.genes.info_from_registry.update_assembly_registry</code>","text":"<p>Utility to update the status of a genebuild in the registry db</p>"},{"location":"ensembl/genes/info_from_registry/update_assembly_registry/#ensembl.genes.info_from_registry.update_assembly_registry.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/update_assembly_registry/#ensembl.genes.info_from_registry.update_assembly_registry.parser","title":"<code>parser = argparse.ArgumentParser(description='Update the status of a genebuild in the registry database.', formatter_class=(argparse.RawDescriptionHelpFormatter), epilog='\\n            Status values should match the gb_status enum:\\n            in_progress, insufficient_data, check_busco, completed, \\n            pre_released, handed_over, archive\\n\\n            Examples:\\n %(prog)s --host localhost --user myuser --password mypass --database registry \\n                    --assembly GCA_123456789.1 --status completed --genebuilder john_doe\\n\\n %(prog)s --host localhost --user myuser --password mypass --database registry \\n                    --assembly GCA_123456789.1 --status in_progress --genebuilder jane_smith --dev\\n        ')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/update_assembly_registry/#ensembl.genes.info_from_registry.update_assembly_registry.ensure_genebuilder_exists","title":"<code>ensure_genebuilder_exists(connection, genebuilder)</code>","text":"<p>Ensure genebuilder exists in the genebuilder table.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Connection</code> <p>MySQL connection object</p> required <code>genebuilder</code> <code>str</code> <p>Genebuilder name</p> required Source code in <code>src/python/ensembl/genes/info_from_registry/update_assembly_registry.py</code> <pre><code>def ensure_genebuilder_exists(\n    connection: pymysql.connections.Connection, genebuilder: str\n) -&gt; None:\n    \"\"\"\n    Ensure genebuilder exists in the genebuilder table.\n\n    Args:\n        connection: MySQL connection object\n        genebuilder (str): Genebuilder name\n    \"\"\"\n    check_query = \"SELECT genebuilder FROM genebuilder WHERE genebuilder = %s\"\n\n    with connection.cursor() as cursor:\n        cursor.execute(check_query, (genebuilder,))\n        if not cursor.fetchone():\n            raise ValueError(\n                f\"Genebuilder '{genebuilder}' does not exist in the genebuilder table. Please add it first.\"\n            )\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/update_assembly_registry/#ensembl.genes.info_from_registry.update_assembly_registry.insert_new_record","title":"<code>insert_new_record(connection, assembly_id, assembly, genebuilder, status, annotation_source, annotation_method, current_date, release_type, genebuild_version, dev)</code>","text":"<p>Insert a new genebuild status record.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Connection</code> <p>MySQL connection object</p> required <code>assembly_id</code> <code>int</code> <p>Assembly ID</p> required <code>assembly</code> <code>str</code> <p>Assembly accession</p> required <code>genebuilder</code> <code>str</code> <p>Genebuilder name</p> required <code>status</code> <code>str</code> <p>Status to set</p> required <code>annotation_source</code> <code>str</code> <p>Annotation source</p> required <code>annotation_method</code> <code>str</code> <p>Annotation method</p> required <code>current_date</code> <code>str</code> <p>Current date</p> required <code>release_type</code> <code>str</code> <p>Release type (default: \"not_available\")</p> required <code>dev</code> <code>bool</code> <p>If True, only print SQL without executing</p> required Source code in <code>src/python/ensembl/genes/info_from_registry/update_assembly_registry.py</code> <pre><code>def insert_new_record(\n    connection: pymysql.connections.Connection,\n    assembly_id: int,\n    assembly: str,\n    genebuilder: str,\n    status: str,\n    annotation_source: str,\n    annotation_method: str,\n    current_date: str,\n    release_type: str,\n    genebuild_version: str,\n    dev: bool,\n) -&gt; None:\n    \"\"\"\n    Insert a new genebuild status record.\n\n    Args:\n        connection: MySQL connection object\n        assembly_id (int): Assembly ID\n        assembly (str): Assembly accession\n        genebuilder (str): Genebuilder name\n        status (str): Status to set\n        annotation_source (str): Annotation source\n        annotation_method (str): Annotation method\n        current_date (str): Current date\n        release_type (str): Release type (default: \"not_available\")\n        dev (bool): If True, only print SQL without executing\n    \"\"\"\n    # date completed is being used to track the last time this record was updated\n    # so we set it to the current date\n    date_status_update = current_date\n\n    # Add not avaialable for release type\n    query = \"\"\"\n    INSERT INTO genebuild_status (\n        assembly_id, gca_accession, gb_status, last_attempt, \n        genebuilder, annotation_source, annotation_method,\n        date_started, date_status_update, release_type,\n        genebuild_version\n    )\n    VALUES (%s, %s, %s, 1, %s, %s, %s, %s, %s, %s, %s)\n    \"\"\"\n\n    params = (\n        assembly_id,\n        assembly,\n        status,\n        genebuilder,\n        annotation_source,\n        annotation_method,\n        current_date,\n        date_status_update,\n        release_type,\n        genebuild_version,\n    )\n\n    if dev:\n        print(\"Would execute:\")\n        print(query % params)\n    else:\n        with connection.cursor() as cursor:\n            cursor.execute(query, params)\n        print(f\"Inserted new record for GCA {assembly} with status '{status}'\")\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/update_assembly_registry/#ensembl.genes.info_from_registry.update_assembly_registry.main","title":"<code>main(host, port, user, password, database, assembly, status, genebuilder, annotation_source, annotation_method, release_type, genebuild_version, dev=False)</code>","text":"<p>Main function to update the genebuild status in the registry database.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>MySQL host</p> required <code>port</code> <code>int</code> <p>MySQL port</p> required <code>user</code> <code>str</code> <p>MySQL user</p> required <code>password</code> <code>str</code> <p>MySQL password</p> required <code>database</code> <code>str</code> <p>MySQL database name</p> required <code>assembly</code> <code>str</code> <p>Assembly Accession (GCA format)</p> required <code>status</code> <code>str</code> <p>Status to update to</p> required <code>genebuilder</code> <code>str</code> <p>Genebuilder name</p> required <code>annotation_source</code> <code>str</code> <p>Annotation source</p> required <code>annotation_method</code> <code>str</code> <p>Annotation method</p> required <code>release_type</code> <code>str</code> <p>Release type (default: \"not_available\")</p> required <code>genebuild_version</code> <code>str</code> <p>Genebuild version</p> required <code>dev</code> <code>bool</code> <p>If True, only print SQL statements without executing</p> <code>False</code> Source code in <code>src/python/ensembl/genes/info_from_registry/update_assembly_registry.py</code> <pre><code>def main(\n    host: str,\n    port: int,\n    user: str,\n    password: str,\n    database: str,\n    assembly: str,\n    status: str,\n    genebuilder: str,\n    annotation_source: Optional[str],\n    annotation_method: Optional[str],\n    release_type: str,\n    genebuild_version: Optional[str],\n    dev: bool = False,\n) -&gt; None:\n    \"\"\"\n    Main function to update the genebuild status in the registry database.\n\n    Args:\n        host (str): MySQL host\n        port (int): MySQL port\n        user (str): MySQL user\n        password (str): MySQL password\n        database (str): MySQL database name\n        assembly (str): Assembly Accession (GCA format)\n        status (str): Status to update to\n        genebuilder (str): Genebuilder name\n        annotation_source (str): Annotation source\n        annotation_method (str): Annotation method\n        release_type (str): Release type (default: \"not_available\")\n        genebuild_version (str): Genebuild version\n        dev (bool): If True, only print SQL statements without executing\n    \"\"\"\n    connection = None\n\n    try:\n        # Connect to database\n        connection = mysql_get_connection(\n            database=database, host=host, port=port, user=user, password=password\n        )\n\n        if not connection:\n            raise Exception(\"Failed to connect to the database\")\n\n        # Start transaction\n        connection.begin()\n\n        ensure_genebuilder_exists(connection, genebuilder)\n\n        assembly_id = fetch_assembly_id(connection, assembly)\n        if not assembly_id:\n            raise Exception(f\"Assembly not found for GCA: {assembly}\")\n\n        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n        existing_record = fetch_current_genebuild_record(\n            connection, assembly, genebuilder\n        )\n\n        if not existing_record:\n            # No existing record for this genebuilder - INSERT new\n            print(f\"No existing record found for {assembly} by {genebuilder}\")\n            print(f\"Creating new record with status: {status}\")\n\n            # Use defaults for new records if not specified\n            method_to_insert = annotation_method if annotation_method else \"pending\"\n            source_to_insert = annotation_source if annotation_source else \"ensembl\"\n            version_to_insert = genebuild_version if genebuild_version else \"ENS01\"\n\n            insert_new_record(\n                connection,\n                assembly_id,\n                assembly,\n                genebuilder,\n                status,\n                source_to_insert,\n                method_to_insert,\n                current_date,\n                release_type,\n                version_to_insert,\n                dev,\n            )\n\n        else:\n            # Existing record found for this genebuilder\n            current_status = existing_record[\"gb_status\"]\n            current_method = existing_record.get(\"annotation_method\")\n            current_source = existing_record.get(\"annotation_source\")\n            current_version = existing_record.get(\"genebuild_version\")\n            record_id = existing_record[\"genebuild_status_id\"]\n\n            print(f\"Found existing record for {assembly} by {genebuilder}\")\n            print(f\"Current status: '{current_status}', requested status: '{status}'\")\n\n            # Status categories\n            terminal_statuses = [\"live\", \"pre_released\", \"handed_over\", \"archive\"]\n            active_statuses = [\"insufficient_data\", \"in_progress\", \"check_busco\"]\n            completed_status = \"completed\"  # terminal-like status\n\n            # Determine if method/source/version should be updated (preserve existing if not specified)\n            method_to_update = (\n                annotation_method if annotation_method is not None else None\n            )\n            source_to_update = (\n                annotation_source if annotation_source is not None else None\n            )\n            version_to_update = (\n                genebuild_version\n                if (\n                    genebuild_version is not None\n                    and genebuild_version != current_version\n                )\n                else None\n            )\n\n            # Same status - check for method/source/version changes\n            if current_status == status:\n                # Check if annotation_method, annotation_source, or genebuild_version is provided and different\n                method_changed = (\n                    annotation_method and annotation_method != current_method\n                )\n                source_changed = (\n                    annotation_source and annotation_source != current_source\n                )\n                version_changed = (\n                    genebuild_version is not None\n                    and genebuild_version != current_version\n                )\n\n                if method_changed or source_changed or version_changed:\n                    changes = []\n                    if method_changed:\n                        changes.append(\n                            f\"method from '{current_method}' to '{annotation_method}'\"\n                        )\n                    if source_changed:\n                        changes.append(\n                            f\"source from '{current_source}' to '{annotation_source}'\"\n                        )\n                    if version_changed:\n                        changes.append(\n                            f\"version from '{current_version}' to '{genebuild_version}'\"\n                        )\n                    print(\n                        f\"Status is already '{status}', but updating {' and '.join(changes)}\"\n                    )\n                    update_existing_record(\n                        connection,\n                        record_id,\n                        status,\n                        current_date,\n                        dev,\n                        annotation_method if method_changed else None,\n                        annotation_source if source_changed else None,\n                        genebuild_version if version_changed else None,\n                    )\n                else:\n                    print(f\"Status is already '{status}'. No changes needed.\")\n                    sys.exit(0)\n\n            # Block backwards transitions from completed\n            elif current_status == completed_status and status in active_statuses:\n                print(f\"ERROR: Cannot move backwards from 'completed' to '{status}'\")\n                print(\n                    f\"Completed is a terminal-like status. To restart work, use a new genebuild_version.\"\n                )\n                sys.exit(1)\n\n            # Block backwards transitions from terminal statuses\n            elif current_status in terminal_statuses and status in (\n                active_statuses + [completed_status]\n            ):\n                # Check if version changed - if so, allow new attempt\n                # If genebuild_version not provided, use current version (no version change)\n                effective_version = (\n                    genebuild_version if genebuild_version else current_version\n                )\n\n                if effective_version != current_version:\n                    print(\n                        f\"Moving from terminal status '{current_status}' to '{status}' with new version {effective_version}\"\n                    )\n                    print(f\"Creating new attempt.\")\n\n                    method_to_insert = (\n                        annotation_method if annotation_method else \"pending\"\n                    )\n                    source_to_insert = (\n                        annotation_source if annotation_source else current_source\n                    )\n\n                    set_old_record_historical(connection, record_id, dev)\n                    insert_new_record(\n                        connection,\n                        assembly_id,\n                        assembly,\n                        genebuilder,\n                        status,\n                        source_to_insert,\n                        method_to_insert,\n                        current_date,\n                        release_type,\n                        effective_version,\n                        dev,\n                    )\n                else:\n                    print(\n                        f\"ERROR: Cannot move from terminal status '{current_status}' to '{status}' with same genebuild_version '{current_version}'\"\n                    )\n                    print(\n                        f\"To restart work, you must provide a new --genebuild_version (e.g., ENS02, ENS03, etc.)\"\n                    )\n                    sys.exit(1)\n\n            # Terminal to terminal transition - UPDATE same record\n            elif current_status in terminal_statuses and status in terminal_statuses:\n                print(\n                    f\"Moving from terminal status '{current_status}' to terminal status '{status}'\"\n                )\n                print(f\"Updating existing record.\")\n                update_existing_record(\n                    connection,\n                    record_id,\n                    status,\n                    current_date,\n                    dev,\n                    method_to_update,\n                    source_to_update,\n                    version_to_update,\n                )\n\n            # Completed to terminal transition - UPDATE same record\n            elif current_status == completed_status and status in terminal_statuses:\n                print(f\"Moving from 'completed' to terminal status '{status}'\")\n                print(f\"Updating existing record.\")\n                update_existing_record(\n                    connection,\n                    record_id,\n                    status,\n                    current_date,\n                    dev,\n                    method_to_update,\n                    source_to_update,\n                    version_to_update,\n                )\n\n            # Active to active or active to completed - UPDATE same record\n            elif current_status in active_statuses and (\n                status in active_statuses or status == completed_status\n            ):\n                print(\n                    f\"Current status '{current_status}' is active. Updating to '{status}'.\"\n                )\n                update_existing_record(\n                    connection,\n                    record_id,\n                    status,\n                    current_date,\n                    dev,\n                    method_to_update,\n                    source_to_update,\n                    version_to_update,\n                )\n\n            # Active to terminal - UPDATE same record\n            elif current_status in active_statuses and status in terminal_statuses:\n                print(\n                    f\"Moving from active status '{current_status}' to terminal status '{status}'\"\n                )\n                print(f\"Updating existing record.\")\n                update_existing_record(\n                    connection,\n                    record_id,\n                    status,\n                    current_date,\n                    dev,\n                    method_to_update,\n                    source_to_update,\n                    version_to_update,\n                )\n\n            else:\n                raise ValueError(\n                    f\"Unexpected status transition: '{current_status}' to '{status}'\"\n                )\n\n        if not dev:\n            # Commit transaction\n            connection.commit()\n            print(\"Transaction completed successfully\")\n        else:\n            print(\"DEV MODE: No changes were made to the database\")\n\n    except Exception as e:\n        if connection:\n            connection.rollback()\n        print(f\"ERROR: {str(e)}\", file=sys.stderr)\n        sys.exit(1)\n\n    finally:\n        if connection:\n            connection.close()\n\n    sys.exit(0)\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/update_assembly_registry/#ensembl.genes.info_from_registry.update_assembly_registry.set_old_record_historical","title":"<code>set_old_record_historical(connection, record_id, dev)</code>","text":"<p>Set an existing record to historical (last_attempt = 0).</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Connection</code> <p>MySQL connection object</p> required <code>record_id</code> <code>int</code> <p>genebuild_status_id to update</p> required <code>dev</code> <code>bool</code> <p>If True, only print SQL without executing</p> required Source code in <code>src/python/ensembl/genes/info_from_registry/update_assembly_registry.py</code> <pre><code>def set_old_record_historical(\n    connection: pymysql.connections.Connection, record_id: int, dev: bool\n) -&gt; None:\n    \"\"\"\n    Set an existing record to historical (last_attempt = 0).\n\n    Args:\n        connection: MySQL connection object\n        record_id (int): genebuild_status_id to update\n        dev (bool): If True, only print SQL without executing\n    \"\"\"\n    query = (\n        \"UPDATE genebuild_status SET last_attempt = 0 WHERE genebuild_status_id = %s\"\n    )\n\n    if dev:\n        print(\"Would execute:\")\n        print(query % (record_id,))\n    else:\n        with connection.cursor() as cursor:\n            cursor.execute(query, (record_id,))\n        print(f\"Set record {record_id} to historical\")\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/update_assembly_registry/#ensembl.genes.info_from_registry.update_assembly_registry.update_existing_record","title":"<code>update_existing_record(connection, record_id, status, current_date, dev, annotation_method=None, annotation_source=None, genebuild_version=None)</code>","text":"Source code in <code>src/python/ensembl/genes/info_from_registry/update_assembly_registry.py</code> <pre><code>def update_existing_record(\n    connection: pymysql.connections.Connection,\n    record_id: int,\n    status: str,\n    current_date: str,\n    dev: bool,\n    annotation_method: Optional[str] = None,\n    annotation_source: Optional[str] = None,\n    genebuild_version: Optional[str] = None,\n) -&gt; None:\n    query_parts = [\"gb_status = %s\", \"date_status_update = %s\"]\n    params = [status, current_date]\n    if annotation_method:\n        query_parts.append(\"annotation_method = %s\")\n        params.append(annotation_method)\n    if annotation_source:\n        query_parts.append(\"annotation_source = %s\")\n        params.append(annotation_source)\n    if genebuild_version:\n        query_parts.append(\"genebuild_version = %s\")\n        params.append(genebuild_version)\n    query = f\"\"\"\nUPDATE genebuild_status\nSET {', '.join(query_parts)}\nWHERE genebuild_status_id = %s\n\"\"\"\n    params.append(record_id)\n\n    if dev:\n        print(\"Would execute:\")\n        print(query, params)\n    else:\n        with connection.cursor() as cursor:\n            cursor.execute(query, params)\n        print(f\"Updated record {record_id} to status '{status}'\")\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/write_metrics_to_registry/","title":"<code>ensembl.genes.info_from_registry.write_metrics_to_registry</code>","text":""},{"location":"ensembl/genes/info_from_registry/write_metrics_to_registry/#ensembl.genes.info_from_registry.write_metrics_to_registry","title":"<code>ensembl.genes.info_from_registry.write_metrics_to_registry</code>","text":"<p>Write metrics from core database to registry database.</p> Reads metrics from core DB meta table and writes them to registry tables <ul> <li>assembly.* keys -&gt; assembly_metrics</li> <li>genebuild.* keys -&gt; annotation_metrics</li> </ul> <p>Uses DELETE then INSERT pattern to avoid stale/duplicated metrics.</p>"},{"location":"ensembl/genes/info_from_registry/write_metrics_to_registry/#ensembl.genes.info_from_registry.write_metrics_to_registry.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/write_metrics_to_registry/#ensembl.genes.info_from_registry.write_metrics_to_registry.parser","title":"<code>parser = argparse.ArgumentParser(description='Write metrics from core database to registry database.', formatter_class=(argparse.RawDescriptionHelpFormatter), epilog='\\n            Fetches metrics from core meta table and writes to registry tables.\\n\\n            Examples:\\n %(prog)s --registry_host localhost --registry_user myuser --registry_password mypass \\\\\\n                     --registry_db registry --core_host corehost --core_user myuser \\\\\\n                     --core_password mypass --core_db my_core_db --assembly GCA_123456789.1 \\\\\\n                     --genebuilder john_doe\\n\\n %(prog)s --registry_host localhost --registry_user myuser --registry_password mypass \\\\\\n                     --registry_db registry --core_host corehost --core_user myuser \\\\\\n                     --core_password mypass --core_db my_core_db --assembly GCA_123456789.1 \\\\\\n                     --genebuilder john_doe --dev\\n        ')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/info_from_registry/write_metrics_to_registry/#ensembl.genes.info_from_registry.write_metrics_to_registry.fetch_core_metrics","title":"<code>fetch_core_metrics(core_connection, species_id)</code>","text":"<p>Fetch metrics from core database meta table.</p> <p>Parameters:</p> Name Type Description Default <code>core_connection</code> <code>Connection</code> <p>MySQL connection object for core DB</p> required <code>species_id</code> <code>int</code> <p>Species ID in core meta table</p> required <p>Returns:     list: List of dictionaries with meta_key and meta_value</p> Source code in <code>src/python/ensembl/genes/info_from_registry/write_metrics_to_registry.py</code> <pre><code>def fetch_core_metrics(\n    core_connection: pymysql.connections.Connection, species_id: int\n) -&gt; list[dict[str, str]]:\n    \"\"\"\n    Fetch metrics from core database meta table.\n\n    Args:\n        core_connection: MySQL connection object for core DB\n        species_id (int): Species ID in core meta table\n    Returns:\n        list: List of dictionaries with meta_key and meta_value\n    \"\"\"\n    query = \"\"\"\n    SELECT meta_key, meta_value\n    FROM meta\n    WHERE species_id=%s AND (\n    meta_key LIKE 'assembly.busco%%' OR\n    meta_key LIKE 'assembly.stats.%%' OR\n    meta_key LIKE 'genebuild.busco%%' OR\n    meta_key LIKE 'genebuild.stats.%%' OR\n        meta_key = 'genebuild.last_geneset_update'\n    )\n    \"\"\"\n    with core_connection.cursor() as cursor:\n        cursor.execute(query, (species_id,))\n        return cursor.fetchall()\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/write_metrics_to_registry/#ensembl.genes.info_from_registry.write_metrics_to_registry.main","title":"<code>main(registry_host, registry_port, registry_user, registry_password, registry_db, core_host, core_port, core_user, core_password, core_db, assembly, species_id, genebuilder, dev)</code>","text":"<p>Main function to write metrics from core DB to registry DB.</p> <p>Parameters:</p> Name Type Description Default <code>registry_host, registry_port, registry_user, registry_password, registry_db</code> <p>Registry DB connection</p> required <code>core_host, core_port, core_user, core_password, core_db</code> <p>Core DB connection</p> required <code>assembly</code> <code>str</code> <p>Assembly Accession (GCA format)</p> required <code>species_id</code> <code>int</code> <p>Species ID in core meta table</p> required <code>genebuilder</code> <code>str</code> <p>Genebuilder name to identify which genebuild record to update</p> required <code>dev</code> <code>bool</code> <p>If True, only print SQL statements without executing</p> required Source code in <code>src/python/ensembl/genes/info_from_registry/write_metrics_to_registry.py</code> <pre><code>def main(\n    registry_host: str,\n    registry_port: int,\n    registry_user: str,\n    registry_password: str,\n    registry_db: str,\n    core_host: str,\n    core_port: int,\n    core_user: str,\n    core_password: Optional[str],\n    core_db: str,\n    assembly: str,\n    species_id: int,\n    genebuilder: str,\n    dev: bool,\n) -&gt; None:\n    \"\"\"\n    Main function to write metrics from core DB to registry DB.\n\n    Args:\n        registry_host, registry_port, registry_user, registry_password, registry_db: Registry DB connection\n        core_host, core_port, core_user, core_password, core_db: Core DB connection\n        assembly (str): Assembly Accession (GCA format)\n        species_id (int): Species ID in core meta table\n        genebuilder (str): Genebuilder name to identify which genebuild record to update\n        dev (bool): If True, only print SQL statements without executing\n    \"\"\"\n    registry_connection = None\n    core_connection = None\n\n    try:\n        registry_connection = mysql_get_connection(\n            database=registry_db,\n            host=registry_host,\n            port=registry_port,\n            user=registry_user,\n            password=registry_password,\n        )\n\n        if not registry_connection:\n            raise Exception(\"Failed to connect to the registry database\")\n\n        core_connection = mysql_get_connection(\n            database=core_db,\n            host=core_host,\n            port=core_port,\n            user=core_user,\n            password=core_password,\n        )\n\n        if not core_connection:\n            raise Exception(\"Failed to connect to the core database\")\n\n        # Start transaction on registry\n        registry_connection.begin()\n\n        print(\n            f\"Fetching registry IDs for assembly {assembly} and genebuilder {genebuilder}...\"\n        )\n        assembly_id, genebuild_status_id = fetch_registry_ids(\n            registry_connection, assembly, genebuilder\n        )\n        print(\n            f\"Found assembly_id: {assembly_id}, genebuild_status_id: {genebuild_status_id}\"\n        )\n\n        print(f\"Fetching metrics from core database...\")\n        meta_rows = fetch_core_metrics(core_connection, species_id)\n        if not meta_rows:\n            print(\"No metrics found in core database\")\n            sys.exit(0)\n\n        # Partition metrics\n        assembly_rows, genebuild_rows = partition_metrics(meta_rows)\n        print(\n            f\"Found {len(assembly_rows)} assembly metrics and {len(genebuild_rows)} genebuild metrics\"\n        )\n\n        # Write metrics to registry\n        write_assembly_metrics(registry_connection, assembly_id, assembly_rows, dev)\n        write_genebuild_metrics(\n            registry_connection, genebuild_status_id, assembly_id, genebuild_rows, dev\n        )\n\n        if not dev:\n            # Commit transaction\n            registry_connection.commit()\n            print(\"Metrics written successfully\")\n        else:\n            print(\"DEV MODE: No changes were made to the registry database\")\n\n    except Exception as e:\n        if registry_connection:\n            registry_connection.rollback()\n        print(f\"ERROR: {str(e)}\", file=sys.stderr)\n        sys.exit(1)\n\n    finally:\n        if registry_connection:\n            registry_connection.close()\n        if core_connection:\n            core_connection.close()\n\n    sys.exit(0)\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/write_metrics_to_registry/#ensembl.genes.info_from_registry.write_metrics_to_registry.partition_metrics","title":"<code>partition_metrics(rows)</code>","text":"<p>Partition metrics into assembly and genebuild categories.</p> <p>Parameters:</p> Name Type Description Default <code>rows</code> <code>list</code> <p>List of dicts with meta_key and meta_value</p> required <p>Returns:     tuple: (assembly_rows, genebuild_rows) as lists of (key, value) tuples</p> Source code in <code>src/python/ensembl/genes/info_from_registry/write_metrics_to_registry.py</code> <pre><code>def partition_metrics(\n    rows: list[dict[str, str]],\n) -&gt; tuple[list[tuple[str, str]], list[tuple[str, str]]]:\n    \"\"\"\n    Partition metrics into assembly and genebuild categories.\n\n    Args:\n        rows (list): List of dicts with meta_key and meta_value\n    Returns:\n        tuple: (assembly_rows, genebuild_rows) as lists of (key, value) tuples\n    \"\"\"\n    assembly_rows = []\n    genebuild_rows = []\n\n    for row in rows:\n        key = row[\"meta_key\"]\n        value = row[\"meta_value\"]\n\n        if key.startswith(\"assembly.busco\") or key.startswith(\"assembly.stats.\"):\n            assembly_rows.append((key, value))\n        elif (\n            key.startswith(\"genebuild.busco\")\n            or key.startswith(\"genebuild.stats.\")\n            or key == \"genebuild.last_geneset_update\"\n        ):\n            genebuild_rows.append((key, value))\n\n    return assembly_rows, genebuild_rows\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/write_metrics_to_registry/#ensembl.genes.info_from_registry.write_metrics_to_registry.write_assembly_metrics","title":"<code>write_assembly_metrics(registry_connection, assembly_id, rows, dev)</code>","text":"<p>Write assembly metrics to registry using DELETE then INSERT pattern.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/write_metrics_to_registry.py</code> <pre><code>def write_assembly_metrics(\n    registry_connection: pymysql.connections.Connection,\n    assembly_id: int,\n    rows: list[tuple[str, str]],\n    dev: bool,\n) -&gt; None:\n    \"\"\"\n    Write assembly metrics to registry using DELETE then INSERT pattern.\n    \"\"\"\n    if not rows:\n        print(\"No assembly metrics to write\")\n        return\n\n    # Extract metric names for deletion\n    metric_names = [name for name, value in rows]\n\n    # Single DELETE for all metrics at once\n    placeholders = \",\".join([\"%s\"] * len(metric_names))\n    delete_query = f\"\"\"\n    DELETE FROM assembly_metrics\n    WHERE assembly_id=%s AND metrics_name IN ({placeholders})\n    \"\"\"\n\n    insert_query = \"\"\"\n    INSERT INTO assembly_metrics (assembly_id, metrics_name, metrics_value)\n    VALUES (%s, %s, %s)\n    \"\"\"\n\n    if dev:\n        print(\"Would execute:\")\n        print(delete_query, (assembly_id, *metric_names))\n        for name, value in rows:\n            print(insert_query, (assembly_id, name, value))\n    else:\n        with registry_connection.cursor() as cursor:\n            print(delete_query, (assembly_id, *metric_names))\n\n            # Single DELETE for all metrics\n            cursor.execute(delete_query, (assembly_id, *metric_names))\n            deleted = cursor.rowcount\n            print(\n                f\"Deleted {deleted} existing assembly metrics for assembly_id {assembly_id}\"\n            )\n\n            # Bulk INSERT\n            cursor.executemany(\n                insert_query, [(assembly_id, name, value) for name, value in rows]\n            )\n        print(f\"Wrote {len(rows)} assembly metrics for assembly_id {assembly_id}\")\n</code></pre>"},{"location":"ensembl/genes/info_from_registry/write_metrics_to_registry/#ensembl.genes.info_from_registry.write_metrics_to_registry.write_genebuild_metrics","title":"<code>write_genebuild_metrics(registry_connection, genebuild_status_id, assembly_id, rows, dev)</code>","text":"<p>Write genebuild metrics to registry using DELETE then INSERT pattern.</p> Source code in <code>src/python/ensembl/genes/info_from_registry/write_metrics_to_registry.py</code> <pre><code>def write_genebuild_metrics(\n    registry_connection: pymysql.connections.Connection,\n    genebuild_status_id: Optional[int],\n    assembly_id: int,\n    rows: list[tuple[str, str]],\n    dev: bool,\n) -&gt; None:\n    \"\"\"\n    Write genebuild metrics to registry using DELETE then INSERT pattern.\n    \"\"\"\n    if not rows:\n        print(\"No genebuild metrics to write\")\n        return\n\n    if not genebuild_status_id:\n        print(\"No genebuild_status_id available; skipping genebuild metrics\")\n        return\n\n    metric_names = [name for name, value in rows]\n\n    placeholders = \",\".join([\"%s\"] * len(metric_names))\n    delete_query = f\"\"\"\n    DELETE FROM annotation_metrics\n    WHERE genebuild_status_id=%s AND metrics_name IN ({placeholders})\n    \"\"\"\n\n    insert_query = \"\"\"\n    INSERT INTO annotation_metrics (genebuild_status_id, assembly_id, metrics_name, metrics_value)\n    VALUES (%s, %s, %s, %s)\n    \"\"\"\n\n    if dev:\n        print(\"Would execute:\")\n        print(delete_query, (genebuild_status_id, *metric_names))\n        for name, value in rows:\n            print(insert_query, (genebuild_status_id, assembly_id, name, value))\n    else:\n        with registry_connection.cursor() as cursor:\n            cursor.execute(delete_query, (genebuild_status_id, *metric_names))\n            deleted = cursor.rowcount\n            print(\n                f\"Deleted {deleted} existing genebuild metrics for genebuild_status_id {genebuild_status_id}\"\n            )\n\n            cursor.executemany(\n                insert_query,\n                [\n                    (genebuild_status_id, str(assembly_id), name, value)\n                    for name, value in rows\n                ],\n            )\n        print(\n            f\"Wrote {len(rows)} genebuild metrics for genebuild_status_id {genebuild_status_id}\"\n        )\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/","title":"<code>ensembl.genes.metadata.beta_patcher</code>","text":""},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher","title":"<code>ensembl.genes.metadata.beta_patcher</code>","text":"<p>Beta Metadata Patcher Script</p> <p>Generates standardized SQL patch files for fixing metadata issues in: 1. Production metadata database (ensembl_genome_metadata) 2. Core database (meta table)</p> <p>This ensures metadata consistency between both databases and provides a standardized workflow for creating and applying patches.</p> Usage <p>python beta_patcher.py patches.csv --jira-ticket EBD-1111 --output-dir ./patches/ python beta_patcher.py patches.csv --jira-ticket EBD-1111 --core-suffix _core_115_1</p>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.METADATA_API_AVAILABLE","title":"<code>METADATA_API_AVAILABLE = True</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.generate_all_patches","title":"<code>generate_all_patches(grouped_patches, output_dir, jira_ticket, logger)</code>","text":"<p>Generate consolidated patch files for all genomes.</p> <p>Parameters:</p> Name Type Description Default <code>grouped_patches</code> <code>Dict[str, Dict]</code> <p>Dictionary of genome patches grouped by UUID</p> required <code>output_dir</code> <code>Path</code> <p>Output directory for patch files</p> required <code>jira_ticket</code> <code>str</code> <p>Jira ticket reference</p> required <code>logger</code> <code>Logger</code> <p>Logger instance</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False otherwise</p> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def generate_all_patches(\n    grouped_patches: Dict[str, Dict],\n    output_dir: Path,\n    jira_ticket: str,\n    logger: logging.Logger,\n) -&gt; bool:\n    \"\"\"\n    Generate consolidated patch files for all genomes.\n\n    Args:\n        grouped_patches: Dictionary of genome patches grouped by UUID\n        output_dir: Output directory for patch files\n        jira_ticket: Jira ticket reference\n        logger: Logger instance\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n\n    # Metadata DB files\n    metadata_patch_file = output_dir / f\"patch_metadata_{jira_ticket}.sql\"\n    metadata_validate_file = output_dir / f\"validate_metadata_{jira_ticket}.sql\"\n\n    # Core DB files\n    core_patch_file = output_dir / f\"patch_core_{jira_ticket}.sql\"\n    core_validate_file = output_dir / f\"validate_core_{jira_ticket}.sql\"\n\n    try:\n        # Write metadata patches\n        with (\n            open(metadata_validate_file, \"w\") as val_f,\n            open(metadata_patch_file, \"w\") as patch_f,\n        ):\n            val_f.write(\n                f\"-- Validation: Metadata DB | {jira_ticket} | {datetime.now().isoformat()}\\n\"\n            )\n            val_f.write(\"USE ensembl_genome_metadata;\\n\\n\")\n\n            patch_f.write(\n                f\"-- Patch: Metadata DB | {jira_ticket} | {datetime.now().isoformat()}\\n\"\n            )\n            patch_f.write(f\"-- Validate first: {metadata_validate_file.name}\\n\")\n            patch_f.write(\"USE ensembl_genome_metadata;\\n\\n\")\n\n            for genome_uuid, genome_data in grouped_patches.items():\n                production_name = genome_data[\"production_name\"]\n                patches = genome_data[\"patches\"]\n                logger.info(\n                    f\"  Metadata: {production_name} ({genome_uuid}): {len(patches)} patches\"\n                )\n\n                write_metadata_patch_for_genome(\n                    val_f, patch_f, genome_uuid, patches, genome_data[\"dataset_type\"]\n                )\n\n        # Write core patches\n        with (\n            open(core_validate_file, \"w\") as val_f,\n            open(core_patch_file, \"w\") as patch_f,\n        ):\n            val_f.write(\n                f\"-- Validation: Core DBs | {jira_ticket} | {datetime.now().isoformat()}\\n\\n\"\n            )\n\n            patch_f.write(\n                f\"-- Patch: Core DBs | {jira_ticket} | {datetime.now().isoformat()}\\n\"\n            )\n            patch_f.write(f\"-- Validate first: {core_validate_file.name}\\n\\n\")\n\n            for genome_uuid, genome_data in grouped_patches.items():\n                production_name = genome_data[\"production_name\"]\n                core_db_name = genome_data[\"core_db_name\"]\n                patches = genome_data[\"patches\"]\n                logger.info(f\"  Core: {core_db_name}: {len(patches)} patches\")\n\n                write_core_patch_for_genome(\n                    val_f, patch_f, core_db_name, patches, genome_data[\"species_id\"]\n                )\n\n        logger.info(f\"Generated files:\")\n        logger.info(f\"  {metadata_validate_file}\")\n        logger.info(f\"  {metadata_patch_file}\")\n        logger.info(f\"  {core_validate_file}\")\n        logger.info(f\"  {core_patch_file}\")\n\n        return True\n\n    except Exception as e:\n        logger.error(f\"Failed to generate patches: {e}\")\n        return False\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.get_genome_adaptor","title":"<code>get_genome_adaptor()</code>","text":"<p>Create a GenomeAdaptor instance using environment variables.</p> Requires <p>METADATA_URI: Connection string for metadata database TAXONOMY_URI: Connection string for taxonomy database</p> <p>Returns:</p> Type Description <code>Optional[GenomeAdaptor]</code> <p>GenomeAdaptor instance or None if not available</p> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def get_genome_adaptor() -&gt; Optional[GenomeAdaptor]:\n    \"\"\"\n    Create a GenomeAdaptor instance using environment variables.\n\n    Requires:\n        METADATA_URI: Connection string for metadata database\n        TAXONOMY_URI: Connection string for taxonomy database\n\n    Returns:\n        GenomeAdaptor instance or None if not available\n    \"\"\"\n    if not METADATA_API_AVAILABLE:\n        logging.error(\"ensembl-metadata-api package not available\")\n        return None\n\n    metadata_uri = os.getenv(\"METADATA_URI\")\n    taxonomy_uri = os.getenv(\"TAXONOMY_URI\")\n\n    if not metadata_uri or not taxonomy_uri:\n        logging.error(\n            \"METADATA_URI and TAXONOMY_URI environment variables required. \"\n            \"Format: mysql+pymysql://user:pass@host:port/database\"\n        )\n        return None\n\n    try:\n        return GenomeAdaptor(metadata_uri=metadata_uri, taxonomy_uri=taxonomy_uri)\n    except Exception as e:\n        logging.error(f\"Failed to create GenomeAdaptor: {e}\")\n        return None\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.get_genome_by_production_name","title":"<code>get_genome_by_production_name(production_name)</code>","text":"<p>Fetch genome UUID by production name.</p> <p>Parameters:</p> Name Type Description Default <code>production_name</code> <code>str</code> <p>Species production name (e.g., homo_sapiens)</p> required <p>Returns:</p> Type Description <code>Optional[Dict]</code> <p>Dict containing genome information or None if not found</p> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def get_genome_by_production_name(production_name: str) -&gt; Optional[Dict]:\n    \"\"\"\n    Fetch genome UUID by production name.\n\n    Args:\n        production_name: Species production name (e.g., homo_sapiens)\n\n    Returns:\n        Dict containing genome information or None if not found\n    \"\"\"\n    adaptor = get_genome_adaptor()\n    if not adaptor:\n        return None\n\n    try:\n        results = adaptor.fetch_genomes(production_name=production_name)\n        if results:\n            genome, organism, assembly, release, _site = results[0]\n            return {\n                \"genome_uuid\": genome.genome_uuid,\n                \"production_name\": genome.production_name,\n                \"assembly_accession\": assembly.accession,\n            }\n        return None\n    except Exception as e:\n        logging.error(\n            f\"Failed to fetch genome by production name {production_name}: {e}\"\n        )\n        return None\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.get_genome_by_uuid","title":"<code>get_genome_by_uuid(genome_uuid)</code>","text":"<p>Fetch genome details by UUID using ensembl-metadata-api.</p> <p>Parameters:</p> Name Type Description Default <code>genome_uuid</code> <code>str</code> <p>Genome UUID to query</p> required <p>Returns:</p> Type Description <code>Optional[Dict]</code> <p>Dict containing genome information or None if not found</p> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def get_genome_by_uuid(genome_uuid: str) -&gt; Optional[Dict]:\n    \"\"\"\n    Fetch genome details by UUID using ensembl-metadata-api.\n\n    Args:\n        genome_uuid: Genome UUID to query\n\n    Returns:\n        Dict containing genome information or None if not found\n    \"\"\"\n    adaptor = get_genome_adaptor()\n    if not adaptor:\n        return None\n\n    try:\n        results = adaptor.fetch_genomes_by_genome_uuid(genome_uuid=genome_uuid)\n        if results:\n            genome, organism, assembly, release, site = results[0]\n            return {\n                \"genome_uuid\": genome.genome_uuid,\n                \"production_name\": genome.production_name,\n                \"genebuild_version\": genome.genebuild_version,\n                \"genebuild_date\": genome.genebuild_date,\n                \"organism\": {\n                    \"organism_uuid\": organism.organism_uuid,\n                    \"taxonomy_id\": organism.taxonomy_id,\n                    \"scientific_name\": organism.scientific_name,\n                    \"strain\": organism.strain,\n                    \"biosample_id\": organism.biosample_id,\n                },\n                \"assembly\": {\n                    \"assembly_uuid\": assembly.assembly_uuid,\n                    \"accession\": assembly.accession,\n                    \"name\": assembly.name,\n                    \"level\": assembly.level,\n                },\n            }\n        return None\n    except Exception as e:\n        logging.error(f\"Failed to fetch genome {genome_uuid}: {e}\")\n        return None\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.group_patches_by_genome","title":"<code>group_patches_by_genome(patches, logger, jira_ticket='')</code>","text":"<p>Group patches by genome UUID.</p> <p>Parameters:</p> Name Type Description Default <code>patches</code> <code>List[Dict]</code> <p>List of patch dictionaries from CSV</p> required <code>logger</code> <code>Logger</code> <p>Logger instance</p> required <code>jira_ticket</code> <code>str</code> <p>Jira ticket reference</p> <code>''</code> <p>Returns:</p> Type Description <code>Dict[str, Dict]</code> <p>Dict mapping genome_uuid to genome info and list of patches</p> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def group_patches_by_genome(\n    patches: List[Dict], logger: logging.Logger, jira_ticket: str = \"\"\n) -&gt; Dict[str, Dict]:\n    \"\"\"\n    Group patches by genome UUID.\n\n    Args:\n        patches: List of patch dictionaries from CSV\n        logger: Logger instance\n        jira_ticket: Jira ticket reference\n\n    Returns:\n        Dict mapping genome_uuid to genome info and list of patches\n    \"\"\"\n    grouped = {}\n\n    for patch in patches:\n        # Resolve genome information\n        genome_info = resolve_genome_info(patch, logger)\n\n        if not genome_info:\n            logger.warning(\n                f\"Row {patch['row_num']}: Skipping due to resolution failure\"\n            )\n            continue\n\n        genome_uuid = genome_info[\"genome_uuid\"]\n\n        # Initialize genome entry if not exists\n        if genome_uuid not in grouped:\n            grouped[genome_uuid] = {\n                \"genome_uuid\": genome_uuid,\n                \"production_name\": genome_info[\"production_name\"],\n                \"core_db_name\": genome_info[\"core_db_name\"],\n                \"dataset_type\": patch[\"dataset_type\"],\n                \"species_id\": patch[\"species_id\"],\n                \"jira_ticket\": jira_ticket,\n                \"patches\": [],\n                \"row_nums\": [],\n            }\n\n        # Add patch to genome's list (include table_location)\n        grouped[genome_uuid][\"patches\"].append(\n            (patch[\"meta_key\"], patch[\"desired_meta_value\"], patch[\"table_location\"])\n        )\n        grouped[genome_uuid][\"row_nums\"].append(patch[\"row_num\"])\n\n    return grouped\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.main","title":"<code>main()</code>","text":"<p>Main entry point for the beta patcher script.</p> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def main():\n    \"\"\"Main entry point for the beta patcher script.\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Generate standardized SQL patches for Ensembl beta metadata issues from CSV input\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nExamples:\n  # Process patches from CSV file\n  python beta_patcher.py patches.csv --jira-ticket EBD-1111 --output-dir ./patches/\n\n  # Process CSV with custom core suffix\n  python beta_patcher.py patches.csv --jira-ticket EBD-1111 --core-suffix _core_115_1\n\n  # Validation files are automatically generated\n  # Run validate_*.sql files before applying patch_*.sql files\n\nCSV Format:\n  Required columns: meta_key, desired_meta_value\n  Identifier (one required): production_name OR genome_uuid\n  Optional columns: dataset_type, species_id, table_location\n\n  Example:\n    production_name,genome_uuid,meta_key,desired_meta_value,dataset_type,species_id,table_location\n    homo_sapiens,,assembly.name,GRCh38.p14,genebuild,1,dataset_attribute\n    ,a7335667-93e7-11ec-a39d-005056b38ce3,organism.strain,Reference,genebuild,1,genome\n\nSee patches_template.csv for a complete example.\n        \"\"\",\n    )\n\n    # Positional argument\n    parser.add_argument(\n        \"csv_file\",\n        type=Path,\n        help=\"CSV file with patches (see patches_template.csv for format)\",\n    )\n\n    # Jira ticket (required)\n    parser.add_argument(\n        \"--jira-ticket\",\n        type=str,\n        required=True,\n        help=\"Jira ticket reference (e.g., EBD-1111)\",\n    )\n\n    # Core database suffix\n    parser.add_argument(\n        \"--core-suffix\",\n        type=str,\n        default=\"_core_114_1\",\n        help=\"Suffix to append to production_name for core DB name (default: _core_114_1)\",\n    )\n\n    # Database connection (uses environment variables METADATA_URI and TAXONOMY_URI)\n    parser.add_argument(\n        \"--metadata-uri\",\n        type=str,\n        help=\"Metadata database URI (overrides METADATA_URI env var)\",\n    )\n\n    parser.add_argument(\n        \"--taxonomy-uri\",\n        type=str,\n        help=\"Taxonomy database URI (overrides TAXONOMY_URI env var)\",\n    )\n\n    # Output options\n    parser.add_argument(\n        \"-o\",\n        \"--output-dir\",\n        type=Path,\n        default=Path.cwd(),\n        help=\"Output directory for patch files (default: current directory)\",\n    )\n\n    args = parser.parse_args()\n\n    # Validate CSV file exists\n    if not args.csv_file.exists():\n        parser.error(f\"CSV file not found: {args.csv_file}\")\n\n    # Override environment variables if provided\n    if args.metadata_uri:\n        os.environ[\"METADATA_URI\"] = args.metadata_uri\n    if args.taxonomy_uri:\n        os.environ[\"TAXONOMY_URI\"] = args.taxonomy_uri\n\n    # Create output directory\n    args.output_dir.mkdir(parents=True, exist_ok=True)\n\n    # Set up logging\n    log_file = (\n        args.output_dir / f\"patch_csv_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n    )\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n        handlers=[logging.FileHandler(log_file), logging.StreamHandler(sys.stdout)],\n    )\n    logger = logging.getLogger(__name__)\n\n    try:\n        patches = read_csv_patches(args.csv_file, args.core_suffix)\n        logger.info(f\"Processing {len(patches)} patches from {args.csv_file}\")\n    except Exception as e:\n        logger.error(f\"Failed to read CSV: {e}\")\n        return 1\n\n    grouped_patches = group_patches_by_genome(patches, logger, args.jira_ticket)\n    logger.info(f\"Grouped into {len(grouped_patches)} genome(s)\")\n\n    if not grouped_patches:\n        logger.error(\"No valid patches to process after grouping\")\n        return 1\n\n    # Generate consolidated patch files\n    if generate_all_patches(grouped_patches, args.output_dir, args.jira_ticket, logger):\n        logger.info(f\"Success! Log: {log_file}\")\n        return 0\n    else:\n        logger.error(f\"Failed. Log: {log_file}\")\n        return 1\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.read_csv_patches","title":"<code>read_csv_patches(csv_file, core_suffix='_core_114_1')</code>","text":"<p>Read patches from CSV file.</p> <p>CSV columns: - production_name OR genome_uuid (one required) - meta_key (required) - desired_meta_value (required) - dataset_type (optional, default: genebuild) - species_id (optional, default: 1) - table_location (optional, default: dataset_attribute)</p> <p>Parameters:</p> Name Type Description Default <code>csv_file</code> <code>Path</code> <p>Path to CSV file</p> required <code>core_suffix</code> <code>str</code> <p>Suffix to append to production_name for core DB name</p> <code>'_core_114_1'</code> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List of patch dictionaries</p> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def read_csv_patches(csv_file: Path, core_suffix: str = \"_core_114_1\") -&gt; List[Dict]:\n    \"\"\"\n    Read patches from CSV file.\n\n    CSV columns:\n    - production_name OR genome_uuid (one required)\n    - meta_key (required)\n    - desired_meta_value (required)\n    - dataset_type (optional, default: genebuild)\n    - species_id (optional, default: 1)\n    - table_location (optional, default: dataset_attribute)\n\n    Args:\n        csv_file: Path to CSV file\n        core_suffix: Suffix to append to production_name for core DB name\n\n    Returns:\n        List of patch dictionaries\n\n    Raises:\n        ValueError if CSV format is invalid\n    \"\"\"\n    patches = []\n\n    with open(csv_file, \"r\") as f:\n        reader = csv.DictReader(f)\n\n        # Validate required columns\n        required_cols = {\"meta_key\", \"desired_meta_value\"}\n        identifier_cols = {\"production_name\", \"genome_uuid\"}\n\n        if not required_cols.issubset(reader.fieldnames):\n            raise ValueError(f\"CSV must contain columns: {required_cols}\")\n\n        if not identifier_cols.intersection(reader.fieldnames):\n            raise ValueError(f\"CSV must contain at least one of: {identifier_cols}\")\n\n        for row_num, row in enumerate(\n            reader, start=2\n        ):  # Start at 2 for header + 1-indexed\n            # Check we have at least one identifier\n            if not row.get(\"production_name\") and not row.get(\"genome_uuid\"):\n                logging.error(\n                    f\"Row {row_num}: Must provide either production_name or genome_uuid\"\n                )\n                continue\n\n            # Check required fields\n            if not row.get(\"meta_key\") or not row.get(\"desired_meta_value\"):\n                logging.error(\n                    f\"Row {row_num}: Missing required fields meta_key or desired_meta_value\"\n                )\n                continue\n\n            patch = {\n                \"production_name\": row.get(\"production_name\", \"\").strip(),\n                \"genome_uuid\": row.get(\"genome_uuid\", \"\").strip(),\n                \"meta_key\": row[\"meta_key\"].strip(),\n                \"desired_meta_value\": row[\"desired_meta_value\"].strip(),\n                \"dataset_type\": row.get(\"dataset_type\", \"genebuild\").strip(),\n                \"species_id\": int(row.get(\"species_id\", 1)),\n                \"table_location\": row.get(\n                    \"table_location\", \"dataset_attribute\"\n                ).strip(),\n                \"core_suffix\": core_suffix,\n                \"row_num\": row_num,\n            }\n\n            patches.append(patch)\n\n    return patches\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.resolve_genome_info","title":"<code>resolve_genome_info(patch, logger)</code>","text":"<p>Resolve genome UUID and production name from patch data.</p> <p>Parameters:</p> Name Type Description Default <code>patch</code> <code>Dict</code> <p>Patch dictionary from CSV</p> required <code>logger</code> <code>Logger</code> <p>Logger instance</p> required <p>Returns:</p> Type Description <code>Optional[Dict]</code> <p>Dict with genome_uuid, production_name, core_db_name, or None if failed</p> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def resolve_genome_info(patch: Dict, logger: logging.Logger) -&gt; Optional[Dict]:\n    \"\"\"\n    Resolve genome UUID and production name from patch data.\n\n    Args:\n        patch: Patch dictionary from CSV\n        logger: Logger instance\n\n    Returns:\n        Dict with genome_uuid, production_name, core_db_name, or None if failed\n    \"\"\"\n    row_num = patch[\"row_num\"]\n    genome_uuid = patch[\"genome_uuid\"]\n    production_name = patch[\"production_name\"]\n\n    # If production_name provided, resolve to genome_uuid\n    if production_name and not genome_uuid:\n        logger.info(\n            f\"Row {row_num}: Resolving genome_uuid from production_name: {production_name}\"\n        )\n        genomes = suggest_genomes_by_production_name(production_name)\n\n        if not genomes:\n            logger.error(\n                f\"Row {row_num}: No genomes found for production_name: {production_name}\"\n            )\n            return None\n\n        if len(genomes) &gt; 1:\n            logger.error(\n                f\"Row {row_num}: Ambiguous production_name '{production_name}' matches {len(genomes)} genomes. \"\n                f\"Please specify genome_uuid instead. Found UUIDs: {[g['genome_uuid'] for g in genomes]}\"\n            )\n            return None\n\n        genome_uuid = genomes[0][\"genome_uuid\"]\n        logger.info(f\"Row {row_num}: Resolved to genome_uuid: {genome_uuid}\")\n\n    # If genome_uuid provided, get production_name if not already set\n    if genome_uuid and not production_name:\n        logger.info(\n            f\"Row {row_num}: Fetching production_name for genome_uuid: {genome_uuid}\"\n        )\n        genome_info = get_genome_by_uuid(genome_uuid)\n\n        if not genome_info:\n            logger.error(\n                f\"Row {row_num}: Could not fetch genome information for UUID: {genome_uuid}\"\n            )\n            return None\n\n        production_name = genome_info[\"production_name\"]\n        logger.info(f\"Row {row_num}: Found production_name: {production_name}\")\n\n    # Build core database name\n    core_db_name = f\"{production_name}{patch['core_suffix']}\"\n\n    return {\n        \"genome_uuid\": genome_uuid,\n        \"production_name\": production_name,\n        \"core_db_name\": core_db_name,\n    }\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.setup_logging","title":"<code>setup_logging(output_dir, genome_uuid)</code>","text":"<p>Set up logging configuration.</p> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def setup_logging(output_dir: Path, genome_uuid: str) -&gt; logging.Logger:\n    \"\"\"Set up logging configuration.\"\"\"\n    log_file = (\n        output_dir\n        / f\"patch_{genome_uuid}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n    )\n\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n        handlers=[logging.FileHandler(log_file), logging.StreamHandler(sys.stdout)],\n    )\n    return logging.getLogger(__name__)\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.suggest_genomes_by_production_name","title":"<code>suggest_genomes_by_production_name(production_name)</code>","text":"<p>Suggest genome UUIDs based on production name.</p> <p>Parameters:</p> Name Type Description Default <code>production_name</code> <code>str</code> <p>Species production name (e.g., homo_sapiens)</p> required <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List of matching genomes with their UUIDs</p> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def suggest_genomes_by_production_name(production_name: str) -&gt; List[Dict]:\n    \"\"\"\n    Suggest genome UUIDs based on production name.\n\n    Args:\n        production_name: Species production name (e.g., homo_sapiens)\n\n    Returns:\n        List of matching genomes with their UUIDs\n    \"\"\"\n    adaptor = get_genome_adaptor()\n    if not adaptor:\n        return []\n\n    try:\n        results = adaptor.fetch_genomes(production_name=production_name)\n        genomes = []\n        for genome, organism, assembly, release, _site in results:\n            genomes.append(\n                {\n                    \"genome_uuid\": genome.genome_uuid,\n                    \"production_name\": genome.production_name,\n                    \"assembly_accession\": assembly.accession,\n                    \"assembly_name\": assembly.name,\n                    \"genebuild_version\": genome.genebuild_version,\n                    \"release_version\": release.version if release else None,\n                }\n            )\n        return genomes\n    except Exception as e:\n        logging.error(\n            f\"Failed to fetch genomes by production name {production_name}: {e}\"\n        )\n        return []\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.write_core_patch_for_genome","title":"<code>write_core_patch_for_genome(validate_file, patch_file, database, patches, species_id=1)</code>","text":"<p>Write validation and patch SQL for a single core database to open file handles.</p> <p>Parameters:</p> Name Type Description Default <code>validate_file</code> <p>Open file handle for validation SQL</p> required <code>patch_file</code> <p>Open file handle for patch SQL</p> required <code>database</code> <code>str</code> <p>Core database name</p> required <code>patches</code> <code>List[Tuple[str, str, str]]</code> <p>List of (meta_key, new_value, table_location) tuples (table_location ignored for core DB)</p> required <code>species_id</code> <code>int</code> <p>Species ID</p> <code>1</code> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def write_core_patch_for_genome(\n    validate_file,\n    patch_file,\n    database: str,\n    patches: List[Tuple[str, str, str]],\n    species_id: int = 1,\n):\n    \"\"\"\n    Write validation and patch SQL for a single core database to open file handles.\n\n    Args:\n        validate_file: Open file handle for validation SQL\n        patch_file: Open file handle for patch SQL\n        database: Core database name\n        patches: List of (meta_key, new_value, table_location) tuples (table_location ignored for core DB)\n        species_id: Species ID\n    \"\"\"\n    for meta_key, new_value, _table_location in patches:\n        escaped_value = new_value.replace(\"'\", \"''\")\n\n        # Write validation SQL\n        validate_file.write(f\"-- {database} | {meta_key}\\n\")\n        validate_file.write(f\"USE {database};\\n\")\n        validate_file.write(\n            f\"SELECT '{meta_key}' AS meta_key, meta_value AS current_value, \"\n        )\n        validate_file.write(f\"'{escaped_value}' AS proposed_value\\n\")\n        validate_file.write(\"FROM meta\\n\")\n        validate_file.write(_core_db_where(meta_key, species_id))\n        validate_file.write(\";\\n\\n\")\n\n        # Write patch SQL\n        patch_file.write(f\"-- {database} | {meta_key}\\n\")\n        patch_file.write(f\"USE {database};\\n\")\n        patch_file.write(\"UPDATE meta\\n\")\n        patch_file.write(f\"SET meta_value = '{escaped_value}'\\n\")\n        patch_file.write(_core_db_where(meta_key, species_id))\n        patch_file.write(\";\\n\\n\")\n        patch_file.write(\n            f\"INSERT IGNORE INTO meta (species_id, meta_key, meta_value)\\n\"\n        )\n        patch_file.write(f\"VALUES ({species_id}, '{meta_key}', '{escaped_value}');\\n\\n\")\n</code></pre>"},{"location":"ensembl/genes/metadata/beta_patcher/#ensembl.genes.metadata.beta_patcher.write_metadata_patch_for_genome","title":"<code>write_metadata_patch_for_genome(validate_file, patch_file, genome_uuid, patches, dataset_type='genebuild')</code>","text":"<p>Write validation and patch SQL for a single genome to open file handles.</p> <p>Parameters:</p> Name Type Description Default <code>validate_file</code> <p>Open file handle for validation SQL</p> required <code>patch_file</code> <p>Open file handle for patch SQL</p> required <code>genome_uuid</code> <code>str</code> <p>Genome UUID</p> required <code>patches</code> <code>List[Tuple[str, str, str]]</code> <p>List of (attribute_name, new_value, table_location) tuples</p> required <code>dataset_type</code> <code>str</code> <p>Dataset type (genebuild, assembly, etc.)</p> <code>'genebuild'</code> Source code in <code>src/python/ensembl/genes/metadata/beta_patcher.py</code> <pre><code>def write_metadata_patch_for_genome(\n    validate_file,\n    patch_file,\n    genome_uuid: str,\n    patches: List[Tuple[str, str, str]],\n    dataset_type: str = \"genebuild\",\n):\n    \"\"\"\n    Write validation and patch SQL for a single genome to open file handles.\n\n    Args:\n        validate_file: Open file handle for validation SQL\n        patch_file: Open file handle for patch SQL\n        genome_uuid: Genome UUID\n        patches: List of (attribute_name, new_value, table_location) tuples\n        dataset_type: Dataset type (genebuild, assembly, etc.)\n    \"\"\"\n    for attribute_name, new_value, table_location in patches:\n        escaped_value = new_value.replace(\"'\", \"''\")\n\n        # Write validation SQL\n        validate_file.write(\n            f\"-- {genome_uuid} | {attribute_name} (table: {table_location})\\n\"\n        )\n        if table_location == \"dataset_attribute\":\n            validate_file.write(\n                \"SELECT genome.genome_uuid, dataset_attribute.value AS current_value, \"\n            )\n            validate_file.write(f\"'{escaped_value}' AS proposed_value\\n\")\n            validate_file.write(\"FROM dataset_attribute\\n\")\n            validate_file.write(_metadata_db_joins())\n            validate_file.write(\"\\n\")\n            validate_file.write(\n                _metadata_db_where(genome_uuid, dataset_type, attribute_name)\n            )\n            validate_file.write(\";\\n\\n\")\n        elif table_location == \"genome\":\n            column_name = attribute_name.split(\".\")[-1]\n            validate_file.write(\n                f\"SELECT genome.genome_uuid, genome.{column_name} AS current_value, \"\n            )\n            validate_file.write(f\"'{escaped_value}' AS proposed_value\\n\")\n            validate_file.write(\"FROM genome\\n\")\n            validate_file.write(f\"WHERE genome.genome_uuid = '{genome_uuid}';\\n\\n\")\n        else:\n            validate_file.write(\n                f\"-- WARNING: Unknown table_location '{table_location}'\\n\"\n            )\n            validate_file.write(\n                f\"-- Manual validation required for {attribute_name}\\n\\n\"\n            )\n\n        # Write patch SQL\n        patch_file.write(\n            f\"-- {genome_uuid} | {attribute_name} (table: {table_location})\\n\"\n        )\n        if table_location == \"dataset_attribute\":\n            # DELETE existing attribute value (if exists)\n            patch_file.write(\"DELETE dataset_attribute FROM dataset_attribute\\n\")\n            patch_file.write(_metadata_db_joins())\n            patch_file.write(\"\\n\")\n            patch_file.write(\n                _metadata_db_where(genome_uuid, dataset_type, attribute_name)\n            )\n            patch_file.write(\";\\n\\n\")\n\n            # INSERT new attribute value\n            patch_file.write(\n                \"INSERT INTO dataset_attribute (dataset_id, attribute_id, value)\\n\"\n            )\n            patch_file.write(\"SELECT dataset.dataset_id, attribute.attribute_id, \")\n            patch_file.write(f\"'{escaped_value}'\\n\")\n            patch_file.write(\"FROM dataset\\n\")\n            patch_file.write(\n                \"JOIN genome_dataset ON dataset.dataset_id = genome_dataset.dataset_id\\n\"\n            )\n            patch_file.write(\n                \"JOIN genome ON genome_dataset.genome_id = genome.genome_id\\n\"\n            )\n            patch_file.write(\"JOIN attribute ON attribute.name = \")\n            patch_file.write(f\"'{attribute_name}'\\n\")\n            patch_file.write(f\"WHERE genome.genome_uuid = '{genome_uuid}'\\n\")\n            patch_file.write(f\"AND dataset.name = '{dataset_type}'\")\n            patch_file.write(\";\\n\\n\")\n\n        elif table_location == \"genome\":\n            column_name = attribute_name.split(\".\")[-1]\n            patch_file.write(\"UPDATE genome\\n\")\n            patch_file.write(f\"SET {column_name} = '{escaped_value}'\\n\")\n            patch_file.write(f\"WHERE genome_uuid = '{genome_uuid}';\\n\\n\")\n\n        else:\n            patch_file.write(f\"-- ERROR: Unknown table_location '{table_location}'\\n\")\n            patch_file.write(f\"-- Manual SQL required for {attribute_name}\\n\\n\")\n</code></pre>"},{"location":"ensembl/genes/metadata/core_meta_data/","title":"<code>ensembl.genes.metadata.core_meta_data</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data","title":"<code>ensembl.genes.metadata.core_meta_data</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.core_dict","title":"<code>core_dict = {}</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.core_meta","title":"<code>core_meta = mysql_fetch_data(core_query, host=(server_info['staging']['db_host']), user=(server_info['staging']['db_user']), port=(server_info['staging']['db_port']), database=db)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.core_query","title":"<code>core_query = f'SELECT meta_key,meta_value FROM meta WHERE species_id = {species_id} AND (meta_key LIKE 'assembly%' OR meta_key LIKE 'species%' OR meta_key LIKE 'genebuild%' OR meta_key LIKE 'organism%' OR meta_key LIKE 'sample%' OR meta_key LIKE 'annotation%' OR meta_key LIKE 'gencode%');'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.current_id","title":"<code>current_id = str(rank_dict['parent_id'])</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.db","title":"<code>db = args.db_name</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.gca_accession","title":"<code>gca_accession = core_dict['assembly.accession']</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.log_file_path","title":"<code>log_file_path = output_dir / f'{args.production_name}_metadata.log'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.log_ini_path","title":"<code>log_ini_path = metadata_dir / 'logging.conf'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.meta_keys_to_remove","title":"<code>meta_keys_to_remove = ['species.strain', 'strain.type']</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.meta_value","title":"<code>meta_value = truth_dict[meta_key].replace(\"'\", \"''\") if truth_dict[meta_key] else None</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.metadata_dir","title":"<code>metadata_dir = Path(__file__).parent</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.name_info","title":"<code>name_info = mysql_fetch_data(name_query, host=(server_info['meta']['db_host']), user=(server_info['meta']['db_user']), port=(server_info['meta']['db_port']), database='ncbi_taxonomy')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.name_query","title":"<code>name_query = f'SELECT name FROM ncbi_taxa_name WHERE taxon_id={truth_dict['organism.taxonomy_id']} AND name_class='genbank common name';'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.output_dir","title":"<code>output_dir = Path(args.output_dir)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.parent_rank_info","title":"<code>parent_rank_info = mysql_fetch_data(parent_taxonomy_query, host=(server_info['meta']['db_host']), user=(server_info['meta']['db_user']), port=(server_info['meta']['db_port']), database='ncbi_taxonomy')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.parent_taxonomy_query","title":"<code>parent_taxonomy_query = f'SELECT rank, parent_id FROM ncbi_taxa_node WHERE taxon_id={rank_dict['parent_id']};'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.parser","title":"<code>parser = argparse.ArgumentParser(description='Prepare SQL updates for core dbs')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.parts","title":"<code>parts = line.strip().split('\\t')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.provider_dict","title":"<code>provider_dict = {}</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.provider_static_file","title":"<code>provider_static_file = metadata_dir / 'provider_static.txt'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.rank_dict","title":"<code>rank_dict = {}</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.rank_info","title":"<code>rank_info = mysql_fetch_data(taxonomy_query, host=(server_info['meta']['db_host']), user=(server_info['meta']['db_user']), port=(server_info['meta']['db_port']), database='ncbi_taxonomy')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.ref_accession","title":"<code>ref_accession = line.split('\\t')[1].strip()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.ref_list","title":"<code>ref_list = open(ref_static_file).readlines()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.ref_static_file","title":"<code>ref_static_file = metadata_dir / 'ref_static.txt'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.required_meta_keys","title":"<code>required_meta_keys = ['organism.production_name', 'organism.taxonomy_id', 'organism.scientific_name', 'assembly.accession', 'assembly.name', 'genebuild.version', 'genebuild.method', 'genebuild.method_display', 'genebuild.start_date', 'genebuild.annotation_source', 'genebuild.provider_name', 'genebuild.provider_url', 'genebuild.sample_gene', 'genebuild.sample_location', 'genebuild.last_geneset_update', 'organism.biosample_id']</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.s_name_info","title":"<code>s_name_info = mysql_fetch_data(s_name_query, host=(server_info['meta']['db_host']), user=(server_info['meta']['db_user']), port=(server_info['meta']['db_port']), database='ncbi_taxonomy')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.s_name_query","title":"<code>s_name_query = f'SELECT name FROM ncbi_taxa_name WHERE taxon_id={truth_dict['organism.taxonomy_id']} AND name_class='scientific name';'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.server_info","title":"<code>server_info = {'staging': {'db_host': args.host, 'db_port': int(args.port), 'db_user': 'ensro'}, 'meta': {'db_host': 'mysql-ens-meta-prod-1.ebi.ac.uk', 'db_port': 4483, 'db_user': 'ensro', 'db_pass': ''}}</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.snp","title":"<code>snp = line.split('\\t')[1].strip()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.snp_list","title":"<code>snp_list = open(snp_static_file).readlines()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.snp_static_file","title":"<code>snp_static_file = metadata_dir / 'snp_static.txt'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.species_id","title":"<code>species_id = species_meta[0][0]</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.species_meta","title":"<code>species_meta = mysql_fetch_data(species_query, host=(server_info['staging']['db_host']), user=(server_info['staging']['db_user']), port=(server_info['staging']['db_port']), database=db)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.species_query","title":"<code>species_query = f'SELECT species_id FROM meta WHERE meta_key='species.production_name' AND meta_value='{core_dict['species.production_name']}';'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.sql_out","title":"<code>sql_out = open(output_dir / f'{args.production_name}.sql', 'w')</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.taxonomy_query","title":"<code>taxonomy_query = f'SELECT rank, parent_id FROM ncbi_taxa_node WHERE taxon_id={truth_dict['organism.taxonomy_id']};'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.truth_dict","title":"<code>truth_dict = {}</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.url","title":"<code>url = line.split('\\t')[1].strip()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.url_list","title":"<code>url_list = open(url_static_file).readlines()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.url_static_file","title":"<code>url_static_file = metadata_dir / 'url_static.txt'</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.get_biosample_metadata","title":"<code>get_biosample_metadata(biosample_id, assembly_accession, assembly_name, scientific_name)</code>","text":"Source code in <code>src/python/ensembl/genes/metadata/core_meta_data.py</code> <pre><code>def get_biosample_metadata(\n    biosample_id: str, assembly_accession: str, assembly_name: str, scientific_name: str\n) -&gt; Dict[str, str]:\n    biosample_url = f\"https://www.ebi.ac.uk/biosamples/samples/{biosample_id}\"\n    biosample_return = requests.get(biosample_url).text\n    return_dict: Dict[str, str] = {\"organism.strain\": \"\", \"organism.strain_type\": \"\"}\n\n    try:\n        biosample_data = json.loads(biosample_return)\n\n        strain_types = {\"population\", \"race\", \"ecotype\", \"breed\", \"strain\", \"cultivar\"}\n\n        for strain_type in strain_types:\n            try:\n                return_dict[\"organism.strain\"] = biosample_data[\"characteristics\"][\n                    strain_type\n                ][0][\"text\"]\n                return_dict[\"organism.strain_type\"] = strain_type\n                break\n            except KeyError:\n                continue\n\n        if return_dict[\"organism.strain\"] == \"Caucasian\":\n            return_dict[\"organism.strain\"] = \"European\"\n\n        try:\n            return_dict[\"assembly.tol_id\"] = biosample_data[\"characteristics\"][\"tolid\"][\n                0\n            ][\"text\"]\n        except KeyError:\n            return_dict[\"assembly.tol_id\"] = \"\"\n\n    except json.decoder.JSONDecodeError:\n        # fallback to NCBI\n        biosample_dict = get_ncbi_metadata(\n            assembly_accession, assembly_name, scientific_name, \"biosample\"\n        )\n        return_dict[\"organism.strain\"] = biosample_dict.get(\"organism.strain\", \"\")\n        return_dict[\"organism.strain_type\"] = biosample_dict.get(\n            \"organism.strain_type\", \"\"\n        )\n        return_dict[\"assembly.tol_id\"] = \"\"\n\n    return return_dict\n</code></pre>"},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.get_ena_metadata","title":"<code>get_ena_metadata(accession, truth_dict)</code>","text":"Source code in <code>src/python/ensembl/genes/metadata/core_meta_data.py</code> <pre><code>def get_ena_metadata(accession: str, truth_dict: Dict[str, Any]) -&gt; Dict[str, str]:\n    assembly_url = f\"https://www.ebi.ac.uk/ena/browser/api/xml/{accession}\"\n    assembly_xml = requests.get(assembly_url)\n    assembly_dict = xmltodict.parse(assembly_xml.text)\n\n    attribs = (\n        assembly_dict.get(\"ASSEMBLY_SET\", {})\n        .get(\"ASSEMBLY\", {})\n        .get(\"ASSEMBLY_ATTRIBUTES\", {})\n        .get(\"ASSEMBLY_ATTRIBUTE\", [])\n    )\n    # normalize to a list\n    if isinstance(attribs, dict):\n        assembly_attribs = [attribs]\n    else:\n        assembly_attribs = list(attribs)\n\n    return_dict: Dict[str, str] = {}\n\n    # assembly metadata\n    return_dict[\"assembly.name\"] = (\n        (\n            assembly_dict.get(\"ASSEMBLY_SET\", {}).get(\"ASSEMBLY\", {}).get(\"NAME\", \"\")\n        ).replace(\" \", \"_\")\n        if assembly_dict.get(\"ASSEMBLY_SET\", {}).get(\"ASSEMBLY\", {}).get(\"NAME\")\n        else \"\"\n    )\n\n    return_dict[\"assembly.level\"] = (\n        assembly_dict.get(\"ASSEMBLY_SET\", {})\n        .get(\"ASSEMBLY\", {})\n        .get(\"ASSEMBLY_LEVEL\", \"\")\n    )\n\n    for attrib_set in assembly_attribs:\n        # assembly date\n        if attrib_set.get(\"TAG\") == \"ENA-LAST-UPDATED\":\n            return_dict[\"assembly.date\"] = attrib_set.get(\"VALUE\", \"\")\n\n    # organism metadata: sample id\n    if \"organism.biosample_id\" not in truth_dict:\n        biosample_id = (\n            assembly_dict.get(\"ASSEMBLY_SET\", {})\n            .get(\"ASSEMBLY\", {})\n            .get(\"SAMPLE_REF\", {})\n            .get(\"IDENTIFIERS\", {})\n            .get(\"PRIMARY_ID\", \"\")\n        )\n        if biosample_id:\n            return_dict[\"organism.biosample_id\"] = biosample_id\n        else:\n            logger.critical(\n                \" | BIOSAMPLE_ID | organism.biosample_id could not be found in the ENA metadata, this is a required key!\"\n            )\n\n    # taxonomy id (workaround for bad records)\n    if accession in (\"GCA_944452655.1\", \"GCA_944452715.1\"):\n        return_dict[\"organism.taxonomy_id\"] = \"1539398\"\n    else:\n        tax_id = (\n            assembly_dict.get(\"ASSEMBLY_SET\", {})\n            .get(\"ASSEMBLY\", {})\n            .get(\"TAXON\", {})\n            .get(\"TAXON_ID\", \"\")\n        )\n        if tax_id:\n            return_dict[\"organism.taxonomy_id\"] = tax_id\n        else:\n            logger.warning(\n                \" | TAXONOMY_ID | organism.taxonomy_id could not be found in the ENA metadata\"\n            )\n\n    return return_dict\n</code></pre>"},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.get_ncbi_metadata","title":"<code>get_ncbi_metadata(accession, assembly_name, scientific_name, search)</code>","text":"Source code in <code>src/python/ensembl/genes/metadata/core_meta_data.py</code> <pre><code>def get_ncbi_metadata(\n    accession: str, assembly_name: str, scientific_name: str, search: str\n) -&gt; Dict[str, str]:\n    organism = f\"{accession}_{assembly_name}\"\n    ncbi_url = f\"https://ftp.ncbi.nlm.nih.gov/genomes/all/{accession[0:3]}/{accession[4:7]}/{accession[7:10]}/{accession[10:13]}/{organism}/{organism}_assembly_report.txt\"\n    ncbi_return = requests.get(ncbi_url).text.splitlines()\n\n    return_dict: Dict[str, str] = {\n        \"assembly.ucsc_alias\": \"\",\n        \"organism.strain\": \"\",\n        \"organism.strain_type\": \"\",\n    }\n\n    if search == \"ucsc\":\n        for line in ncbi_return:\n            ucsc_match = re.search(r\"# Synonyms:\\s*([A-Za-z0-9]+)\", line)\n            if ucsc_match:\n                return_dict[\"assembly.ucsc_alias\"] = ucsc_match.group(1)\n\n    elif search == \"biosample\":\n        for line in ncbi_return:\n            strain_match = re.search(\n                r\"# Infraspecific name:\\s*([A-Za-z]+)=([A-Za-z0-9 \\-\\./]+)\", line\n            )\n            if strain_match:\n                return_dict[\"organism.strain_type\"] = strain_match.group(1)\n                return_dict[\"organism.strain\"] = strain_match.group(2)\n\n    return return_dict\n</code></pre>"},{"location":"ensembl/genes/metadata/core_meta_data/#ensembl.genes.metadata.core_meta_data.mysql_fetch_data","title":"<code>mysql_fetch_data(query, database, host, port, user)</code>","text":"<p>Run a simple SELECT query and return fetched rows.</p> <p>Returns an empty list on error.</p> Source code in <code>src/python/ensembl/genes/metadata/core_meta_data.py</code> <pre><code>def mysql_fetch_data(\n    query: str, database: str, host: str, port: int, user: str\n) -&gt; List[Tuple[Any, ...]]:\n    \"\"\"Run a simple SELECT query and return fetched rows.\n\n    Returns an empty list on error.\n    \"\"\"\n    conn = None\n    cursor = None\n    info: List[Tuple[Any, ...]] = []\n    try:\n        conn = pymysql.connect(\n            host=host, user=user, port=port, database=database.strip()\n        )\n        cursor = conn.cursor()\n        cursor.execute(query)\n        info = list(cursor.fetchall())\n    except pymysql.Error:\n        logger.exception(\"MySQL error while executing query: %s\", query)\n    finally:\n        if cursor is not None:\n            try:\n                cursor.close()\n            except Exception:\n                logger.exception(\"Error closing cursor\")\n        if conn is not None:\n            try:\n                conn.close()\n            except Exception:\n                logger.exception(\"Error closing connection\")\n    return info\n</code></pre>"},{"location":"ensembl/genes/metrics/busco_lineage_selector/","title":"<code>ensembl.genes.metrics.busco_lineage_selector</code>","text":""},{"location":"ensembl/genes/metrics/busco_lineage_selector/#ensembl.genes.metrics.busco_lineage_selector","title":"<code>ensembl.genes.metrics.busco_lineage_selector</code>","text":""},{"location":"ensembl/genes/metrics/busco_lineage_selector/#ensembl.genes.metrics.busco_lineage_selector.get_dataset_match","title":"<code>get_dataset_match(ncbi_url, dataset)</code>","text":"<p>Get taxonomy tree from ncbi taxonomy datasets and find the closest match with the input list</p> <p>Parameters:</p> Name Type Description Default <code>ncbi_url</code> <code>str</code> <p>Ncbi dataset url</p> required <code>dataset</code> <code>dict</code> <p>list of data to match</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>Optional[Any]</code> <p>closest match in the dataset list</p> <p>Raises:</p> Type Description <code>HTTPError</code> <p>If an HTTP error occurs during the API request.</p> <code>Exception</code> <p>If any other error occurs during the function's operation.</p> Source code in <code>src/python/ensembl/genes/metrics/busco_lineage_selector.py</code> <pre><code>def get_dataset_match(ncbi_url: str, dataset: Dict[str, Any]) -&gt; Optional[Any]:\n    \"\"\"\n    Get taxonomy tree from ncbi taxonomy datasets and find the closest match with the input list\n\n\n    Args:\n        ncbi_url (str): Ncbi dataset url\n        dataset (dict): list of data to match\n\n    Returns:\n        str: closest match in the dataset list\n\n    Raises:\n        requests.HTTPError: If an HTTP error occurs during the API request.\n        Exception: If any other error occurs during the function's operation.\n\n    \"\"\"\n\n    try:\n        # Fetch data from the URL\n        with urllib.request.urlopen(ncbi_url, timeout=10) as response:\n            # Read the response and decode it\n            data = response.read().decode(\"utf-8\")\n            # Parse the JSON data\n            json_data = json.loads(data)\n\n            # Extract classification names\n            parents = json_data[\"reports\"][0][\"taxonomy\"][\"parents\"]\n            # Variable to store the matched result\n            matched_value = None\n\n            # Match parents against the dictionary\n            for parent_id in reversed(parents):\n                parent_id_str = str(parent_id)\n                if parent_id_str in dataset:\n                    matched_value = dataset[parent_id_str]\n                    break\n    except urllib.error.URLError as url_err:\n        print(f\"URL error occurred: {url_err}\")\n    except json.JSONDecodeError as json_err:\n        print(f\"Error decoding JSON: {json_err}\")\n    # print (matched_value)\n    return matched_value\n</code></pre>"},{"location":"ensembl/genes/metrics/busco_lineage_selector/#ensembl.genes.metrics.busco_lineage_selector.main","title":"<code>main()</code>","text":"<p>Entry-point.</p> Source code in <code>src/python/ensembl/genes/metrics/busco_lineage_selector.py</code> <pre><code>def main():\n    \"\"\"Entry-point.\"\"\"\n    args = parse_args()\n\n    ncbi_url = f\"{args.ncbi_url}/{args.taxon_id}/dataset_report\"\n\n    with open(Path(args.datasets), \"r\") as file:  # pylint:disable=unspecified-encoding\n        # datasets = [line[: max(line.find(\" \"), 0) or None] for line in file]\n        datasets = json.load(file)\n    clade_match = get_dataset_match(ncbi_url, datasets)\n\n    if not clade_match:\n        raise ValueError(\"No match found\")\n\n    if args.output == \"stdout\":  # pylint:disable=no-else-return\n        # print(clade_match[0].strip(\"\\n\"))\n        print(clade_match)\n    else:\n        with open(args.output, \"w+\") as output:  # pylint:disable=unspecified-encoding\n            if clade_match[0] == args.species:\n                output.write(clade_match[1])\n            else:\n                output.write(clade_match[0])\n</code></pre>"},{"location":"ensembl/genes/metrics/busco_lineage_selector/#ensembl.genes.metrics.busco_lineage_selector.parse_args","title":"<code>parse_args()</code>","text":"<p>Parse command line arguments.</p> Source code in <code>src/python/ensembl/genes/metrics/busco_lineage_selector.py</code> <pre><code>def parse_args():\n    \"\"\"Parse command line arguments.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Clade selector arguments\")\n    parser.add_argument(\n        \"-d\",\n        \"--datasets\",\n        type=str,\n        help=\"Path to file containing list of datasets (one per line)\",\n        required=True,\n    )\n    parser.add_argument(\"-t\", \"--taxon_id\", type=str, help=\"Taxon id \", required=True)\n    parser.add_argument(\"--output\", type=str, help=\"Output file\", default=\"stdout\")\n    parser.add_argument(\n        \"--ncbi_url\",\n        type=str,\n        help=\"NCBI dataset url\",\n        default=\"https://api.ncbi.nlm.nih.gov/datasets/v2alpha/taxonomy/taxon/\",\n    )\n    return parser.parse_args()\n</code></pre>"},{"location":"ensembl/genes/metrics/busco_metakeys_patch/","title":"<code>ensembl.genes.metrics.busco_metakeys_patch</code>","text":""},{"location":"ensembl/genes/metrics/busco_metakeys_patch/#ensembl.genes.metrics.busco_metakeys_patch","title":"<code>ensembl.genes.metrics.busco_metakeys_patch</code>","text":""},{"location":"ensembl/genes/metrics/busco_metakeys_patch/#ensembl.genes.metrics.busco_metakeys_patch.execute_sql_patches","title":"<code>execute_sql_patches(db_name, sql_statements, host, user, password, port)</code>","text":"<p>Create SQL patch for database and execute it</p> <p>Parameters:</p> Name Type Description Default <code>db_name</code> <code>str</code> <p>Database name</p> required <code>sql_statements</code> <code>Dict[str, Union[str, float]]</code> <p>List of queryes</p> required <code>host</code> <code>str</code> <p>MySQL server host.</p> required <code>user</code> <code>str</code> <p>MySQL user.</p> required <code>password</code> <code>str</code> <p>MySQL password.</p> required <code>port</code> <code>int</code> <p>MySQL port.</p> required Source code in <code>src/python/ensembl/genes/metrics/busco_metakeys_patch.py</code> <pre><code>def execute_sql_patches(  # pylint: disable=too-many-arguments, too-many-locals\n    db_name: str,\n    sql_statements: str,\n    host: str,\n    user: str,\n    password: str,\n    port: int,\n) -&gt; None:  # pylint: disable=line-too-long\n    \"\"\"Create SQL patch for database and execute it\n\n    Args:\n        db_name (str): Database name\n        sql_statements (Dict[str, Union[str, float]]): List of queryes\n        host (str, optional): MySQL server host.\n        user (str, optional): MySQL user.\n        password (str, optional): MySQL password.\n        port (int, optional): MySQL port.\n\n    \"\"\"\n    statements = sql_statements.strip().split(\";\\n\")\n    connection = None  # Initialize connection variable\n    # Connect to the database and execute the SQL statements\n    try:\n        connection = pymysql.connect(\n            host=host, user=user, password=password, database=db_name, port=int(port)\n        )\n        with connection.cursor() as cursor:\n            for statement in statements:\n                print(statement.strip())\n                statement = statement.strip()\n                cursor.execute(statement)  # Execute each SQL statement\n            connection.commit()  # Commit the changes\n    except pymysql.MySQLError as err_msg:\n        print(f\"Error while executing SQL: {err_msg}\")\n    finally:\n        if connection is not None:\n            connection.close()  # Close the database connection\n</code></pre>"},{"location":"ensembl/genes/metrics/busco_metakeys_patch/#ensembl.genes.metrics.busco_metakeys_patch.generate_sql_patches","title":"<code>generate_sql_patches(db_name, json_data, species_id=1, table_name='meta')</code>","text":"<p>Creat Sql patch for database</p> <p>Parameters:</p> Name Type Description Default <code>db_name</code> <code>str</code> <p>db name</p> required <code>json_data</code> <code>Dict[str, Union[str, float]]</code> <p>Dict of metakeys</p> required <code>species_id</code> <code>int</code> <p>species_id Defaults to 1.</p> <code>1</code> <code>table_name</code> <code>str</code> <p>Table name where to store data Defaults to \"meta\".</p> <code>'meta'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>list of Mysql patches</p> Source code in <code>src/python/ensembl/genes/metrics/busco_metakeys_patch.py</code> <pre><code>def generate_sql_patches(\n    db_name: str,\n    json_data: Dict[str, Union[str, int, float]],\n    species_id: int = 1,\n    table_name: str = \"meta\",\n) -&gt; str:  # pylint: disable=line-too-long\n    \"\"\"Creat Sql patch for database\n\n    Args:\n        db_name (str): db name\n        json_data (Dict[str, Union[str, float]]): Dict of metakeys\n        species_id (int, optional): species_id Defaults to 1.\n        table_name (str, optional): Table name where to store data Defaults to \"meta\".\n\n    Returns:\n        str: list of Mysql patches\n    \"\"\"\n    sql_statements = []\n    sql_statements.append(f\"USE {db_name};\\n\")  # Replace with your actual DB name\n\n    # Iterate through the JSON key-value pairs\n    for key, value in json_data.items():\n        if value is None:\n            # Skip if the value is None (or can handle it differently if needed)\n            continue\n        # Convert value to string and escape single quotes if necessary\n        value_str = str(value).replace(\"'\", \"''\")\n        # Create the SQL INSERT statement\n        sql_statements.append(\n            f\"INSERT IGNORE INTO {table_name} (species_id, meta_key, meta_value) VALUES ({species_id}, '{key}', '{value_str}');\"  # pylint: disable=line-too-long\n        )\n\n    return \"\\n\".join(sql_statements)\n</code></pre>"},{"location":"ensembl/genes/metrics/busco_metakeys_patch/#ensembl.genes.metrics.busco_metakeys_patch.main","title":"<code>main()</code>","text":"<p>Main function to parse a BUSCO result file and output the parsed data in JSON format.</p> <p>It expects the file path to the BUSCO result as a command-line argument.</p> Source code in <code>src/python/ensembl/genes/metrics/busco_metakeys_patch.py</code> <pre><code>def main():\n    \"\"\"\n    Main function to parse a BUSCO result file and output the parsed data in JSON format.\n\n    It expects the file path to the BUSCO result as a command-line argument.\n    \"\"\"\n\n    # Set up argument parser\n    parser = argparse.ArgumentParser(\n        description=\"Parse a BUSCO result file and generate JSON output.\"\n    )\n    parser.add_argument(\"-file\", type=str, help=\"Path to the BUSCO result file\")\n    parser.add_argument(\"-db\", required=True, type=str, help=\"Core db\")\n    parser.add_argument(\n        \"-input_dir\",\n        type=str,\n        help=\"Path for directory containing the busco output files\",\n    )\n    parser.add_argument(\n        \"-output_dir\", required=True, type=str, help=\"Path for output directory\"\n    )\n    parser.add_argument(\n        \"-run_query\",\n        type=str,\n        choices=[\"true\", \"false\"],\n        help=\"Add busco metakeys to the db\",\n    )\n    parser.add_argument(\"-host\", required=True, type=str, help=\"Server host\")\n    parser.add_argument(\"-port\", required=True, type=str, help=\"Server port\")\n    parser.add_argument(\n        \"-user\", required=True, type=str, help=\"Db user with writable permission\"\n    )\n    parser.add_argument(\"-password\", required=True, type=str, help=\"Server password\")\n    parser.add_argument(\"-assembly_id\", type=str, help=\"Registry assembly id\")\n    # Parse arguments\n    args = parser.parse_args()\n    if args.file:\n        # Process the single file and write to JSON and SQL\n        sql_patches = process_busco_file(\n            args.file, args.db, args.output_dir, args.assembly_id\n        )\n        with open(\n            Path(args.output_dir) / f\"{args.db}.sql\", \"a\"\n        ) as f_in:  # pylint: disable =unspecified-encoding\n            f_in.write(sql_patches)\n\n    elif args.input_dir:\n        # Process all files that end with 'busco_short_summary'\n        busco_files = list(Path(args.input_dir).rglob(\"*busco_short_summary.txt\"))\n\n        with open(\n            Path(args.output_dir) / f\"{args.db}.sql\", \"a\"\n        ) as f:  # pylint: disable =unspecified-encoding\n            for file in busco_files:\n                print(f\"Processing file: {file}\")\n                sql_patches = process_busco_file(\n                    file, args.db, args.output_dir, args.assembly_id\n                )\n                f.write(sql_patches)\n    if args.run_query == \"true\":\n        execute_sql_patches(\n            args.db, sql_patches, args.host, args.user, args.password, int(args.port)\n        )\n</code></pre>"},{"location":"ensembl/genes/metrics/busco_metakeys_patch/#ensembl.genes.metrics.busco_metakeys_patch.parse_busco_file","title":"<code>parse_busco_file(file_path)</code>","text":"<p>Parses a BUSCO result file and extracts relevant data into a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the BUSCO result file.</p> required <code>db</code> <code>str</code> <p>Core db name.</p> required <p>Returns:</p> Type Description <code>Dict[str, Union[str, int, float]]</code> <p>Dict[str, Union[str, int]]: A dictionary containing parsed BUSCO data,</p> <code>Dict[str, Union[str, int, float]]</code> <p>including the dataset, completeness values, and mode (proteins or genome).</p> Source code in <code>src/python/ensembl/genes/metrics/busco_metakeys_patch.py</code> <pre><code>def parse_busco_file(\n    file_path: str,\n) -&gt; Dict[\n    str, Union[str, int, float]\n]:  # pylint: disable =too-many-locals, too-many-statements\n    \"\"\"\n    Parses a BUSCO result file and extracts relevant data into a dictionary.\n\n    Args:\n        file_path (str): The path to the BUSCO result file.\n        db(str): Core db name.\n\n    Returns:\n        Dict[str, Union[str, int]]: A dictionary containing parsed BUSCO data,\n        including the dataset, completeness values, and mode (proteins or genome).\n    \"\"\"\n\n    # Declare the dictionary to accept str as keys and str or float as values\n    data: Dict[str, Union[str, int, float]] = {}\n    # data[\"core_db\"] = db\n    # Open and read the file\n    with open(file_path, \"r\") as file:  # pylint: disable =unspecified-encoding\n        content = file.read()\n\n    # Define regular expressions to match the relevant numbers\n    version_pattern: Optional[re.Match[str]] = re.search(\n        r\"BUSCO version is: ((\\d+\\.\\d+.\\d+))\", content\n    )\n    dataset_pattern: Optional[re.Match[str]] = re.search(\n        r\"The lineage dataset is: ([\\w_]+)\", content\n    )\n    mode_pattern: Optional[re.Match[str]] = re.search(\n        r\"BUSCO was run in mode: ([\\w_]+)\", content\n    )\n    completeness_pattern: Optional[re.Match[str]] = re.search(\n        r\"(\\d+)\\s+Complete BUSCOs \\(C\\)\", content\n    )\n    single_copy_pattern: Optional[re.Match[str]] = re.search(\n        r\"(\\d+)\\s+Complete and single-copy BUSCOs \\(S\\)\", content\n    )\n    duplicates_pattern: Optional[re.Match[str]] = re.search(\n        r\"(\\d+)\\s+Complete and duplicated BUSCOs \\(D\\)\", content\n    )\n    fragmented_pattern: Optional[re.Match[str]] = re.search(\n        r\"(\\d+)\\s+Fragmented BUSCOs \\(F\\)\", content\n    )\n    missing_pattern: Optional[re.Match[str]] = re.search(\n        r\"(\\d+)\\s+Missing BUSCOs \\(M\\)\", content\n    )\n\n    # Initialize mode_match as None or str\n    mode_match: Optional[str] = None\n\n    # If match is not None, extract the group and assign it to mode_match\n    if mode_pattern is not None:\n        mode_match = mode_pattern.group(1)\n    if mode_match in (\"genome\", \"euk_genome_met\", \"euk_genome_min\"):\n        busco_mode = \"genome\"\n    elif mode_match == \"proteins\":\n        busco_mode = \"protein\"\n    else:\n        mode_match = None\n\n    version = str(version_pattern.group(1)) if version_pattern else None\n    dataset = str(dataset_pattern.group(1)) if dataset_pattern else None\n    completeness = int(completeness_pattern.group(1)) if completeness_pattern else None\n    single_copy = int(single_copy_pattern.group(1)) if single_copy_pattern else None\n    duplicated = int(duplicates_pattern.group(1)) if duplicates_pattern else None\n    fragmented = int(fragmented_pattern.group(1)) if fragmented_pattern else None\n    missing = int(missing_pattern.group(1)) if missing_pattern else None\n\n    # Extract the BUSCO summary line with completeness values\n    if mode_match == \"euk_genome_min\":\n        score_match = re.search(\n            r\"C:(\\d+\\.\\d+)%\\[S:(\\d+\\.\\d+)%.*,D:(\\d+\\.\\d+)%\\],F:(\\d+\\.\\d+)%.*,M:(\\d+\\.\\d+)%,n:(\\d+),E:(\\d+\\.\\d+)%\",  # pylint: disable=line-too-long\n            content,  # pylint: disable=line-too-long\n        )\n    else:\n        score_match = re.search(\n            r\"C:(\\d+\\.\\d+)%\\[S:(\\d+\\.\\d+)%.*,D:(\\d+\\.\\d+)%\\],F:(\\d+\\.\\d+)%.*,M:(\\d+\\.\\d+)%,n:(\\d+)\",\n            content,\n        )\n\n    if score_match:\n        score = score_match.group(0)\n        total_buscos = score_match.group(6)\n        if mode_match == \"euk_genome_min\":\n            erroneus = score_match.group(7)\n\n        if mode_match in (\"genome\", \"euk_genome_met\", \"euk_genome_min\"):\n            # Extract the BUSCO version\n            data[\"assembly.busco_version\"] = str(version)\n            # Extract the BUSCO dataset\n            data[\"assembly.busco_dataset\"] = str(dataset)\n            # Store the BUSCO completeness summary with erroneous\n            data[\"assembly.busco\"] = str(score)\n            data[\"assembly.busco_mode\"] = busco_mode\n            # Store the BUSCO values into individual fields\n            data[\"assembly.busco_completeness\"] = str(completeness)\n            data[\"assembly.busco_single_copy\"] = str(single_copy)\n            data[\"assembly.busco_duplicated\"] = str(duplicated)\n            data[\"assembly.busco_fragmented\"] = str(fragmented)\n            data[\"assembly.busco_missing\"] = str(missing)\n            data[\"assembly.busco_total\"] = int(total_buscos)\n            if mode_match == \"euk_genome_min\":\n                data[\"assembly.busco_erroneus\"] = str(erroneus)\n\n            data[\"assembly.busco\"] = str(score)  # pylint: disable=line-too-long\n\n        else:\n            # Extract the BUSCO version\n            data[\"genebuild.busco_version\"] = str(version)\n            # Extract the BUSCO dataset\n            data[\"genebuild.busco_dataset\"] = str(dataset)\n            # Store the BUSCO completeness summary\n            data[\"genebuild.busco\"] = str(score)\n            data[\"genebuild.busco_mode\"] = busco_mode\n            # Store the BUSCO values into individual fields\n            data[\"genebuild.busco_completeness\"] = str(completeness)\n            data[\"genebuild.busco_single_copy\"] = str(single_copy)\n            data[\"genebuild.busco_duplicated\"] = str(duplicated)\n            data[\"genebuild.busco_fragmented\"] = str(fragmented)\n            data[\"genebuild.busco_missing\"] = str(missing)\n            data[\"genebuild.busco_total\"] = int(total_buscos)\n    return data\n</code></pre>"},{"location":"ensembl/genes/metrics/busco_metakeys_patch/#ensembl.genes.metrics.busco_metakeys_patch.process_busco_file","title":"<code>process_busco_file(busco_file, dbname, output_dir, assembly_id='')</code>","text":"<p>Parses the BUSCO file, generates a JSON, writes it to an output file, and generates SQL patches. Args:     busco_file (str): Busco file to process     dbname (str) : db name     output_dir (str): Output directory path     assembly_id (str, optional): Metadata used in downstream analyses.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>list of Mysql patches</p> Source code in <code>src/python/ensembl/genes/metrics/busco_metakeys_patch.py</code> <pre><code>def process_busco_file(\n    busco_file: str, dbname: str, output_dir: str, assembly_id: str = \"\"\n) -&gt; str:\n    \"\"\"\n    Parses the BUSCO file, generates a JSON, writes it to an output file,\n    and generates SQL patches.\n    Args:\n        busco_file (str): Busco file to process\n        dbname (str) : db name\n        output_dir (str): Output directory path\n        assembly_id (str, optional): Metadata used in downstream analyses.\n\n    Returns:\n        str: list of Mysql patches\n    \"\"\"\n    # Parse the BUSCO file and generate the JSON\n    busco_data = parse_busco_file(busco_file)\n\n    # Determine the file name based on the mode (protein or genome)\n    for key, value in busco_data.items():\n        if key.endswith(\".busco_mode\"):\n            busco_mode = value\n            break  # Exit the loop once we find the first match\n\n    output_file_name = f\"{dbname}_busco_{busco_mode}_metakey.json\"\n    busco_data_json = busco_data.copy()\n    busco_data_json[\"core_db\"] = dbname\n    busco_data_json[\"assembly_id\"] = assembly_id\n    # Convert the dictionary to a JSON object\n    busco_json = json.dumps(busco_data_json, indent=4)\n\n    # Write the JSON output to the dynamically named file\n    output_path = Path(output_dir) / output_file_name\n    with open(output_path, \"w\") as outfile:  # pylint: disable =unspecified-encoding\n        outfile.write(busco_json)\n\n    # Output the JSON\n    print(busco_json)\n\n    # Generate SQL patches from the JSON\n    sql_patches = generate_sql_patches(dbname, busco_data)\n\n    # Return SQL patches to write them to an SQL file later\n    return sql_patches\n</code></pre>"},{"location":"ensembl/genes/metrics/check_busco_score/","title":"<code>ensembl.genes.metrics.check_busco_score</code>","text":""},{"location":"ensembl/genes/metrics/check_busco_score/#ensembl.genes.metrics.check_busco_score","title":"<code>ensembl.genes.metrics.check_busco_score</code>","text":""},{"location":"ensembl/genes/metrics/check_busco_score/#ensembl.genes.metrics.check_busco_score.evaluate_busco","title":"<code>evaluate_busco(genome_json_path, protein_json_path, min_range_protein_score, max_range_protein_score, diff_prot_gen_mode)</code>","text":"<p>Evaluate BUSCO scores from genome and protein JSON files. This function loads the BUSCO JSON files for genome and protein, extracts the completeness scores, and compares them to determine if the protein BUSCO score is significantly higher than the genome BUSCO score. The criteria for significance are: - If the protein BUSCO score is &gt;= 70%, it is considered significant. - If the protein BUSCO score is between 50% and 70%, it is considered significant   if the difference between the protein and genome BUSCO scores is &gt;= 10%. If the genome or protein BUSCO JSON files cannot be loaded, an error message is printed and the function returns False.</p> <p>Parameters:</p> Name Type Description Default <code>genome_json_path</code> <code>str</code> <p>path to the genome BUSCO JSON file</p> required <code>protein_json_path</code> <code>str</code> <p>path to the protein BUSCO JSON file</p> required <code>min_range_protein_score</code> <code>int</code> <p>Lowest threshold to analyse busco score in protein mode</p> required <code>max_range_protein_score</code> <code>int</code> <p>Highest threshold to analyse busco score in protein mode</p> required <code>diff_prot_gen_mode</code> <code>int</code> <p>Max difference between Busco in protein and in genome mode</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If the expected '.busco' key is not found in either JSON file.</p> <p>Returns:</p> Type Description <code>None</code> <p>exit 0 if the protein BUSCO score soddisfy criteria, otherwise exit 42</p> Source code in <code>src/python/ensembl/genes/metrics/check_busco_score.py</code> <pre><code>def evaluate_busco(\n    genome_json_path: str,\n    protein_json_path: str,\n    min_range_protein_score: int,\n    max_range_protein_score: int,\n    diff_prot_gen_mode: int,\n) -&gt; None:\n    \"\"\"Evaluate BUSCO scores from genome and protein JSON files.\n    This function loads the BUSCO JSON files for genome and protein,\n    extracts the completeness scores, and compares them to determine\n    if the protein BUSCO score is significantly higher than the genome BUSCO score.\n    The criteria for significance are:\n    - If the protein BUSCO score is &gt;= 70%, it is considered significant.\n    - If the protein BUSCO score is between 50% and 70%, it is considered significant\n      if the difference between the protein and genome BUSCO scores is &gt;= 10%.\n    If the genome or protein BUSCO JSON files cannot be loaded, an error message is printed\n    and the function returns False.\n\n    Args:\n        genome_json_path (str): _path to the genome BUSCO JSON file_\n        protein_json_path (str): _path to the protein BUSCO JSON file_\n        min_range_protein_score (int): Lowest threshold to analyse busco score in protein mode\n        max_range_protein_score (int): Highest threshold to analyse busco score in protein mode\n        diff_prot_gen_mode (int): Max difference between Busco in protein and in genome mode\n\n    Raises:\n        KeyError: If the expected '.busco' key is not found in either JSON file.\n\n    Returns:\n        exit 0 if the protein BUSCO score soddisfy criteria, otherwise exit 42\n    \"\"\"\n    try:\n        with open(genome_json_path) as g_file:  # pylint:disable=unspecified-encoding\n            genome_data = json.load(g_file)\n    except Exception as err_msg:  # pylint: disable=broad-except\n        print(f\"Failed to load genome BUSCO JSON: {err_msg}\")\n        sys.exit(42)\n\n    try:\n        with open(protein_json_path) as p_file:  # pylint:disable=unspecified-encoding\n            protein_data = json.load(p_file)\n    except Exception as err_msg:  # pylint: disable=broad-except\n        print(f\"Failed to load protein BUSCO JSON: {err_msg}\")\n        sys.exit(42)\n\n    genome_busco_key = next((k for k in genome_data if k.endswith(\".busco\")), None)\n    protein_busco_key = next((k for k in protein_data if k.endswith(\".busco\")), None)\n\n    if not genome_busco_key or not protein_busco_key:\n        raise KeyError(\"Missing '.busco' key in one of the JSON files\")\n\n    genome_busco_score = extract_completeness(genome_data[genome_busco_key])\n    protein_busco_score = extract_completeness(protein_data[protein_busco_key])\n\n    print(f\"Genome BUSCO completeness: {genome_busco_score}%\")\n    print(f\"Protein BUSCO completeness: {protein_busco_score}%\")\n\n    if protein_busco_score &gt;= max_range_protein_score:\n        print(\n            f\"Protein BUSCO completeness {protein_busco_score}% is above threshold (70%)\"\n        )\n        sys.exit(0)\n    if min_range_protein_score &lt; protein_busco_score &lt; max_range_protein_score:\n        difference = protein_busco_score - genome_busco_score\n        print(f\"Difference (protein - genome): {difference:.2f}%\")\n        if difference &lt;= diff_prot_gen_mode:\n            sys.exit(0)\n        else:\n            sys.exit(42)\n    print(f\"Protein BUSCO completeness {protein_busco_score}% is too low\")\n    sys.exit(42)\n</code></pre>"},{"location":"ensembl/genes/metrics/check_busco_score/#ensembl.genes.metrics.check_busco_score.extract_completeness","title":"<code>extract_completeness(busco_str)</code>","text":"<p>Extract the BUSCO completeness value from a string like: \"C:99.2%[S:98.4%,D:0.8%],F:0.6%,M:0.2%,n:3640\" and return it as a float. If the format is invalid, raise a ValueError.</p> <p>Parameters:</p> Name Type Description Default <code>busco_str</code> <code>str</code> <p>The BUSCO string to parse.</p> required <p>Return: The completeness percentage as a float.</p> Source code in <code>src/python/ensembl/genes/metrics/check_busco_score.py</code> <pre><code>def extract_completeness(busco_str) -&gt; float:\n    \"\"\"\n    Extract the BUSCO completeness value from a string like:\n    \"C:99.2%[S:98.4%,D:0.8%],F:0.6%,M:0.2%,n:3640\"\n    and return it as a float.\n    If the format is invalid, raise a ValueError.\n\n    Args:\n        busco_str (str): The BUSCO string to parse.\n    Return: The completeness percentage as a float.\n    \"\"\"\n    match = re.search(r\"C:([\\d.]+)%\", busco_str)\n    if match:\n        return float(match.group(1))\n    raise ValueError(f\"Invalid BUSCO format: {busco_str}\")\n</code></pre>"},{"location":"ensembl/genes/metrics/check_busco_score/#ensembl.genes.metrics.check_busco_score.main","title":"<code>main()</code>","text":"<p>Main function to parse command line arguments and evaluate BUSCO scores.</p> Source code in <code>src/python/ensembl/genes/metrics/check_busco_score.py</code> <pre><code>def main():\n    \"\"\"Main function to parse command line arguments and evaluate BUSCO scores.\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Evaluate BUSCO scores from genome and protein JSON files.\"\n    )\n    parser.add_argument(\n        \"--genome\", required=True, help=\"Path to genome BUSCO JSON file\"\n    )\n    parser.add_argument(\n        \"--protein\", required=True, help=\"Path to protein BUSCO JSON file\"\n    )\n    parser.add_argument(\n        \"--min_range_protein_score\",\n        type=int,\n        required=False,\n        default=50,\n        help=\"Lowest threshold to analyse busco score in protein mode\",\n    )\n    parser.add_argument(\n        \"--max_range_protein_score\",\n        type=int,\n        required=False,\n        default=70,\n        help=\"Highest threshold to analyse busco score in protein mode\",\n    )\n    parser.add_argument(\n        \"--diff_prot_gen_mode\",\n        type=int,\n        required=False,\n        default=10,\n        help=\"Max difference between Busco in protein and in genome mode\",\n    )\n    args = parser.parse_args()\n\n    try:  # pylint: disable=broad-except\n        evaluate_busco(\n            args.genome,\n            args.protein,\n            args.min_range_protein_score,\n            args.max_range_protein_score,\n            args.diff_prot_gen_mode,\n        )\n\n    except Exception as err_msg:  # pylint: disable=broad-except\n        print(f\"ERROR: {err_msg}\")\n        sys.exit(42)\n</code></pre>"},{"location":"ensembl/genes/projects/write_yaml/","title":"<code>ensembl.genes.projects.write_yaml</code>","text":""},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml","title":"<code>ensembl.genes.projects.write_yaml</code>","text":""},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP","title":"<code>EnsemblFTP</code>","text":"<p>Robust FTP client for Ensembl/EBI with reconnect + tolerant shutdown.</p> Source code in <code>src/python/ensembl/genes/projects/write_yaml.py</code> <pre><code>class EnsemblFTP:\n    \"\"\"\n    Robust FTP client for Ensembl/EBI with reconnect + tolerant shutdown.\n    \"\"\"\n\n    def __init__(\n        self, timeout: int = 30, max_retries: int = 2, retry_sleep: float = 3.0\n    ) -&gt; None:\n        self.timeout = timeout\n        self.max_retries = max_retries\n        self.retry_sleep = retry_sleep\n\n        self.ensembl_ftp = None\n        self.ebi_ftp = None\n\n        self._connect_ensembl()\n        self._connect_ebi()\n\n        self.ensembl_ftp_path = \"https://ftp.ensembl.org/\"\n        self.ebi_ftp_path = \"https://ftp.ebi.ac.uk/\"\n\n    # ---- connections ----\n    def _connect_ensembl(self):\n        try:\n            self.ensembl_ftp = FTP(\"ftp.ensembl.org\", timeout=self.timeout)\n            self.ensembl_ftp.set_pasv(True)\n            self.ensembl_ftp.login()\n        except Exception:\n            self.ensembl_ftp = None\n            raise\n\n    def _connect_ebi(self):\n        try:\n            self.ebi_ftp = FTP(\"ftp.ebi.ac.uk\", timeout=self.timeout)\n            self.ebi_ftp.set_pasv(True)\n            self.ebi_ftp.login()\n        except Exception:\n            self.ebi_ftp = None\n            raise\n\n    def _retry(self, fn, which: str, *args, **kwargs):\n        \"\"\"\n        Retry FTP operation; on failure, reconnect that endpoint and try again.\n        \"\"\"\n        last_exc = None\n        for _ in range(self.max_retries):\n            try:\n                return fn(*args, **kwargs)\n            except (\n                ConnectionResetError,\n                EOFError,\n                OSError,\n                error_temp,\n                socket.timeout,\n            ) as e:\n                last_exc = e\n                try:\n                    if which == \"ensembl\":\n                        self._connect_ensembl()\n                    else:\n                        self._connect_ebi()\n                except Exception:\n                    pass\n                time.sleep(self.retry_sleep)\n        raise last_exc\n\n    # ---- utils ----\n    def return_to_root(self, ftp_connection: FTP) -&gt; None:\n        which = \"ensembl\" if ftp_connection is self.ensembl_ftp else \"ebi\"\n        self._retry(ftp_connection.cwd, which, \"/\")\n\n    # ---- lookups ----\n    def check_for_file(\n        self,\n        species_name: str,\n        prod_name: str,\n        accession: str,\n        source: str,\n        file_type: str,\n    ) -&gt; str:\n        if file_type == \"repeatmodeler\":\n            ftp_connection = self.ebi_ftp\n            which = \"ebi\"\n            ftp_path = self.ebi_ftp_path\n            path = (\n                \"pub/databases/ensembl/repeats/unfiltered_repeatmodeler/species/\"\n                + species_name\n                + \"/\"\n            )\n            file_name = accession + \".repeatmodeler.fa\"\n        elif file_type == \"busco\":\n            ftp_connection = self.ensembl_ftp\n            which = \"ensembl\"\n            ftp_path = self.ensembl_ftp_path\n            path = (\n                \"pub/rapid-release/species/\"\n                + species_name\n                + \"/\"\n                + accession\n                + \"/\"\n                + source\n                + \"/statistics/\"\n            )\n            file_name_protein = prod_name + \"_protein_busco_short_summary.txt\"\n            file_name_alternative = prod_name + \"_busco_short_summary.txt\"\n        else:\n            return \"\"\n\n        try:\n            self.return_to_root(ftp_connection)\n            self._retry(ftp_connection.cwd, which, path)\n            files_list = self._retry(ftp_connection.nlst, which)\n\n            if file_type == \"busco\":\n                if file_name_protein in files_list:\n                    return ftp_path + path + file_name_protein\n                if file_name_alternative in files_list:\n                    return ftp_path + path + file_name_alternative\n                return \"\"\n            else:\n                return ftp_path + path + file_name if file_name in files_list else \"\"\n        except error_perm as e:\n            if \"550\" in str(e):\n                return \"\"\n            print(f\"FTP permission error: {e}\", file=sys.stderr)\n            return \"\"\n        except error_temp as e:\n            print(f\"FTP temporary error: {e}\", file=sys.stderr)\n            return \"\"\n        except Exception as e:\n            print(f\"Error while checking FTP file: {e}\", file=sys.stderr)\n            return \"\"\n\n    def check_pre_release_file(\n        self, species_name: str, accession: str, extension: str\n    ) -&gt; str:\n        ftp = self.ebi_ftp\n        which = \"ebi\"\n        base = self.ebi_ftp_path\n        path = f\"pub/databases/ensembl/pre-release/{species_name}/{accession}/\"\n        try:\n            self.return_to_root(ftp)\n            self._retry(ftp.cwd, which, path)\n            for fname in self._retry(ftp.nlst, which):\n                if fname.lower().endswith(extension):\n                    return base + path + fname\n        except error_perm:\n            return \"\"\n        except Exception as e:\n            print(f\"Error while checking pre-release file: {e}\", file=sys.stderr)\n        return \"\"\n\n    def close_connections(self) -&gt; None:\n        \"\"\"\n        Best-effort shutdown: if QUIT fails because the server dropped us,\n        fall back to close() and never raise.\n        \"\"\"\n        for conn in (self.ensembl_ftp, self.ebi_ftp):\n            if not conn:\n                continue\n            try:\n                conn.quit()\n            except Exception:\n                try:\n                    conn.close()\n                except Exception:\n                    pass\n</code></pre>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP.ebi_ftp","title":"<code>ebi_ftp = None</code>  <code>instance-attribute</code>","text":""},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP.ebi_ftp_path","title":"<code>ebi_ftp_path = 'https://ftp.ebi.ac.uk/'</code>  <code>instance-attribute</code>","text":""},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP.ensembl_ftp","title":"<code>ensembl_ftp = None</code>  <code>instance-attribute</code>","text":""},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP.ensembl_ftp_path","title":"<code>ensembl_ftp_path = 'https://ftp.ensembl.org/'</code>  <code>instance-attribute</code>","text":""},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP.max_retries","title":"<code>max_retries = max_retries</code>  <code>instance-attribute</code>","text":""},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP.retry_sleep","title":"<code>retry_sleep = retry_sleep</code>  <code>instance-attribute</code>","text":""},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP.timeout","title":"<code>timeout = timeout</code>  <code>instance-attribute</code>","text":""},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP.check_for_file","title":"<code>check_for_file(species_name, prod_name, accession, source, file_type)</code>","text":"Source code in <code>src/python/ensembl/genes/projects/write_yaml.py</code> <pre><code>def check_for_file(\n    self,\n    species_name: str,\n    prod_name: str,\n    accession: str,\n    source: str,\n    file_type: str,\n) -&gt; str:\n    if file_type == \"repeatmodeler\":\n        ftp_connection = self.ebi_ftp\n        which = \"ebi\"\n        ftp_path = self.ebi_ftp_path\n        path = (\n            \"pub/databases/ensembl/repeats/unfiltered_repeatmodeler/species/\"\n            + species_name\n            + \"/\"\n        )\n        file_name = accession + \".repeatmodeler.fa\"\n    elif file_type == \"busco\":\n        ftp_connection = self.ensembl_ftp\n        which = \"ensembl\"\n        ftp_path = self.ensembl_ftp_path\n        path = (\n            \"pub/rapid-release/species/\"\n            + species_name\n            + \"/\"\n            + accession\n            + \"/\"\n            + source\n            + \"/statistics/\"\n        )\n        file_name_protein = prod_name + \"_protein_busco_short_summary.txt\"\n        file_name_alternative = prod_name + \"_busco_short_summary.txt\"\n    else:\n        return \"\"\n\n    try:\n        self.return_to_root(ftp_connection)\n        self._retry(ftp_connection.cwd, which, path)\n        files_list = self._retry(ftp_connection.nlst, which)\n\n        if file_type == \"busco\":\n            if file_name_protein in files_list:\n                return ftp_path + path + file_name_protein\n            if file_name_alternative in files_list:\n                return ftp_path + path + file_name_alternative\n            return \"\"\n        else:\n            return ftp_path + path + file_name if file_name in files_list else \"\"\n    except error_perm as e:\n        if \"550\" in str(e):\n            return \"\"\n        print(f\"FTP permission error: {e}\", file=sys.stderr)\n        return \"\"\n    except error_temp as e:\n        print(f\"FTP temporary error: {e}\", file=sys.stderr)\n        return \"\"\n    except Exception as e:\n        print(f\"Error while checking FTP file: {e}\", file=sys.stderr)\n        return \"\"\n</code></pre>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP.check_pre_release_file","title":"<code>check_pre_release_file(species_name, accession, extension)</code>","text":"Source code in <code>src/python/ensembl/genes/projects/write_yaml.py</code> <pre><code>def check_pre_release_file(\n    self, species_name: str, accession: str, extension: str\n) -&gt; str:\n    ftp = self.ebi_ftp\n    which = \"ebi\"\n    base = self.ebi_ftp_path\n    path = f\"pub/databases/ensembl/pre-release/{species_name}/{accession}/\"\n    try:\n        self.return_to_root(ftp)\n        self._retry(ftp.cwd, which, path)\n        for fname in self._retry(ftp.nlst, which):\n            if fname.lower().endswith(extension):\n                return base + path + fname\n    except error_perm:\n        return \"\"\n    except Exception as e:\n        print(f\"Error while checking pre-release file: {e}\", file=sys.stderr)\n    return \"\"\n</code></pre>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP.close_connections","title":"<code>close_connections()</code>","text":"<p>Best-effort shutdown: if QUIT fails because the server dropped us, fall back to close() and never raise.</p> Source code in <code>src/python/ensembl/genes/projects/write_yaml.py</code> <pre><code>def close_connections(self) -&gt; None:\n    \"\"\"\n    Best-effort shutdown: if QUIT fails because the server dropped us,\n    fall back to close() and never raise.\n    \"\"\"\n    for conn in (self.ensembl_ftp, self.ebi_ftp):\n        if not conn:\n            continue\n        try:\n            conn.quit()\n        except Exception:\n            try:\n                conn.close()\n            except Exception:\n                pass\n</code></pre>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.EnsemblFTP.return_to_root","title":"<code>return_to_root(ftp_connection)</code>","text":"Source code in <code>src/python/ensembl/genes/projects/write_yaml.py</code> <pre><code>def return_to_root(self, ftp_connection: FTP) -&gt; None:\n    which = \"ensembl\" if ftp_connection is self.ensembl_ftp else \"ebi\"\n    self._retry(ftp_connection.cwd, which, \"/\")\n</code></pre>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.check_database_on_server","title":"<code>check_database_on_server(db, server_key, server_dict)</code>","text":"<p>Checks if a database exists on a given server.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>str</code> <p>The name of the database to check.</p> required <code>server_key</code> <code>str</code> <p>The key of the server in the config.</p> required <code>server_dict</code> <code>dict</code> <p>Dictionary containing server connection details.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the database exists, False otherwise.</p> Source code in <code>src/python/ensembl/genes/projects/write_yaml.py</code> <pre><code>def check_database_on_server(db, server_key, server_dict):\n    \"\"\"\n    Checks if a database exists on a given server.\n\n    Args:\n        db (str): The name of the database to check.\n        server_key (str): The key of the server in the config.\n        server_dict (dict): Dictionary containing server connection details.\n\n    Returns:\n        bool: True if the database exists, False otherwise.\n    \"\"\"\n    try:\n        conn = pymysql.connect(\n            host=server_dict[server_key][\"db_host\"],\n            user=server_dict[server_key][\"db_user\"],\n            passwd=server_dict[server_key][\"db_pass\"],\n            port=server_dict[server_key][\"db_port\"],\n        )\n        with conn.cursor() as cur:\n            # print(f\"Checking for DB '{db}' on server '{server_key}'\", file=sys.stderr)\n            cur.execute(\n                \"SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s\",\n                (db,),\n            )\n            result = cur.fetchone()\n            # print(f\"Query result on {server_key}: {result}\", file=sys.stderr)\n            return result is not None\n\n    except pymysql.MySQLError as e:\n        print(f\"Error connecting to {server_key}: {e}\")\n        return False\n    finally:\n        if \"conn\" in locals() and conn:\n            conn.close()\n</code></pre>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.check_url_status","title":"<code>check_url_status(url)</code>","text":"<p>Checks if a given URL is reachable.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the URL returns a 200 status code, False otherwise.</p> Source code in <code>src/python/ensembl/genes/projects/write_yaml.py</code> <pre><code>def check_url_status(url):\n    \"\"\"\n    Checks if a given URL is reachable.\n\n    Args:\n        url (str): The URL to check.\n\n    Returns:\n        bool: True if the URL returns a 200 status code, False otherwise.\n    \"\"\"\n    try:\n        response = requests.head(\n            url, allow_redirects=True, timeout=5\n        )  # Use HEAD for efficiency\n        return response.status_code == 200\n    except requests.RequestException as e:\n        print(f\"Error checking URL {url}: {e}\")\n        return False\n</code></pre>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.find_database_server","title":"<code>find_database_server(db, server_dict)</code>","text":"<p>Determines which server the given database exists on.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>str</code> <p>The name of the database to check.</p> required <code>server_dict</code> <code>dict</code> <p>Dictionary containing server connection details from the config file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The name of the server where the database is found.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the database is not found on any of the servers.</p> Source code in <code>src/python/ensembl/genes/projects/write_yaml.py</code> <pre><code>def find_database_server(db, server_dict):\n    \"\"\"\n    Determines which server the given database exists on.\n\n    Args:\n        db (str): The name of the database to check.\n        server_dict (dict): Dictionary containing server connection details from the config file.\n\n    Returns:\n        str: The name of the server where the database is found.\n\n    Raises:\n        Exception: If the database is not found on any of the servers.\n    \"\"\"\n    # Check servers in order: st5 -&gt; st6 -&gt; main\n    for server_key in [\"st5\", \"st6\", \"main\"]:\n        if check_database_on_server(db, server_key, server_dict):\n            return server_key\n\n    # If no server found, raise an error\n    raise Exception(f\"Unable to find database {db} on any configured servers!\")\n</code></pre>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.main","title":"<code>main()</code>","text":"<p>Main function that parses arguments, reads server config from JSON, queries MySQL databases, and writes YAML content.</p> Source code in <code>src/python/ensembl/genes/projects/write_yaml.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"\n    Main function that parses arguments, reads server config from JSON,\n    queries MySQL databases, and writes YAML content.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Create a species.yaml file for a given project page.\"\n    )\n    parser.add_argument(\n        \"-f\",\n        \"--db_file\",\n        help=\"Name of the file containing list of databases on Beta or Main servers and their Genome UUIDs\",\n        required=True,\n    )\n    parser.add_argument(\n        \"-p\",\n        \"--project\",\n        choices=[\n            \"aquafaang\",\n            \"asg\",\n            \"bge\",\n            \"bovreg\",\n            \"cbp\",\n            \"dtol\",\n            \"erga\",\n            \"geneswitch\",\n            \"vgp\",\n        ],\n        help=\"Name of the project this set of databases belongs to\",\n        required=True,\n    )\n    parser.add_argument(\n        \"-c\",\n        \"--config_file\",\n        help=\"Path to the JSON configuration file containing server connection details\",\n        required=True,\n    )\n    args = parser.parse_args()\n    project = args.project\n\n    # Load server connection details from JSON\n    with open(args.config_file) as config_f:\n        server_dict = json.load(config_f)\n\n    # Read icons\n    icon_dict = {}\n    with open(\"icons.txt\") as icon_file:\n        for line in icon_file:\n            fields = line.split()\n            if len(fields) &gt;= 2:\n                icon_dict[fields[0]] = fields[1]\n\n    # Read database list\n    with open(args.db_file) as db_file:\n        db_list = db_file.read().strip().split(\"\\n\")\n\n    sorted_db_list = sorted(db_list)\n\n    # Special rearrangements for certain projects\n    if project == \"aquafaang\":\n        # Move danio rerio reference DBs to the end\n        for db in sorted_db_list:\n            if \"danio_rerio_core\" in db:\n                sorted_db_list.append(sorted_db_list.pop(sorted_db_list.index(db)))\n\n    if project == \"bovreg\":\n        # Move bos taurus reference DBs to the top\n        for db in sorted_db_list:\n            if \"bos_taurus_core\" in db:\n                sorted_db_list.insert(0, sorted_db_list.pop(sorted_db_list.index(db)))\n\n    if project == \"geneswitch\":\n        # Move sus scrofa or gallus gallus reference DBs to top\n        for db in sorted_db_list:\n            if \"sus_scrofa_core\" in db or \"gallus_gallus_core\" in db:\n                sorted_db_list.insert(0, sorted_db_list.pop(sorted_db_list.index(db)))\n\n    # Initialize FTP connection\n    ftp_client = EnsemblFTP(timeout=30, max_retries=2, retry_sleep=3.0)\n\n    # Open the output YAML file\n    with open(f\"{project}_species.yaml\", \"w\") as yaml_out:\n        # will replace with guiid eventually\n        for line in sorted_db_list:\n            db = line.split(\"\\t\")[0].strip()\n            guuid = line.split(\"\\t\")[1].strip()\n            if guuid == \"unknown\":\n                use_server = \"gb1\"\n            else:\n                use_server = find_database_server(db, server_dict)\n\n            # Retrieve metadata from the chosen server\n            # update this with query from the metadata db\n            info_query = (\n                \"SELECT meta_key, meta_value FROM meta \"\n                \"WHERE meta_key IN \"\n                \"('species.scientific_name','assembly.accession','assembly.name',\"\n                \"'species.production_name','species.strain','schema_version',\"\n                \"'genebuild.last_geneset_update','species.annotation_source','genebuild.busco','genebuild.busco_dataset') \"\n                \"OR meta_key LIKE 'genebuild.method%'\"\n            )\n            info = mysql_fetch_data(\n                info_query,\n                db,\n                server_dict[use_server][\"db_host\"],\n                server_dict[use_server][\"db_port\"],\n                server_dict[use_server][\"db_user\"],\n                server_dict[use_server][\"db_pass\"],\n            )\n\n            info_dict = {row[0]: row[1] for row in info}\n\n            # Check if assembly has an alternate\n            # update this with query from the metadata db\n            alternate_assembly_name = (\n                info_dict[\"assembly.name\"] + \"_alternate_haplotype\"\n            )\n            alternate_query = (\n                \"SELECT organism.url_name \"\n                \"FROM assembly \"\n                \"JOIN genome USING (assembly_id) \"\n                \"JOIN organism USING (organism_id) \"\n                f\"WHERE assembly.assembly_name='{alternate_assembly_name}' LIMIT 1;\"\n            )\n            alternate_fetch = mysql_fetch_data(\n                alternate_query,\n                \"ensembl_metadata_qrp\",\n                server_dict[\"meta\"][\"db_host\"],\n                server_dict[\"meta\"][\"db_port\"],\n                server_dict[\"meta\"][\"db_user\"],\n                server_dict[\"meta\"][\"db_pass\"],\n            )\n            alternate = alternate_fetch[0][0] if alternate_fetch else \"\"\n\n            # Retrieve classification info\n            # replace this with call to datasets\n            class_query = (\n                \"SELECT meta_value FROM meta WHERE meta_key='species.classification'\"\n            )\n            classifications = mysql_fetch_data(\n                class_query,\n                db,\n                server_dict[use_server][\"db_host\"],\n                server_dict[use_server][\"db_port\"],\n                server_dict[use_server][\"db_user\"],\n                server_dict[use_server][\"db_pass\"],\n            )\n\n            class_list = [c[0] for c in classifications]\n\n            icon = \"Metazoa.png\"\n            chordate = \"Chordata\" in class_list\n            for classification in class_list:\n                if classification in icon_dict:\n                    icon = icon_dict[classification]\n                    break\n\n            if chordate and icon == \"Metazoa.png\":\n                icon = \"Chordates.png\"\n\n            write_yaml(\n                info_dict,\n                icon,\n                yaml_out,\n                project,\n                use_server,\n                alternate,\n                guuid,\n                ftp_client,\n            )\n\n    ftp_client.close_connections()\n</code></pre>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.mysql_fetch_data","title":"<code>mysql_fetch_data(query, database, host, port, user, password)</code>","text":"<p>Fetch data from a MySQL database using a given query.</p>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.mysql_fetch_data--parameters","title":"Parameters","text":"<p>query : str     The SQL query to execute. database : str     The database name. host : str     The database host. port : int     The database port. user : str     The username for the database. password : str     The password for the database.</p>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.mysql_fetch_data--returns","title":"Returns","text":"<p>Tuple     A tuple of results fetched from the database query.</p> Source code in <code>src/python/ensembl/genes/projects/write_yaml.py</code> <pre><code>def mysql_fetch_data(\n    query: str, database: str, host: str, port: int, user: str, password: str\n) -&gt; Tuple:\n    \"\"\"\n    Fetch data from a MySQL database using a given query.\n\n    Parameters\n    ----------\n    query : str\n        The SQL query to execute.\n    database : str\n        The database name.\n    host : str\n        The database host.\n    port : int\n        The database port.\n    user : str\n        The username for the database.\n    password : str\n        The password for the database.\n\n    Returns\n    -------\n    Tuple\n        A tuple of results fetched from the database query.\n    \"\"\"\n    conn = pymysql.connect(\n        host=host, user=user, passwd=password, port=port, database=database.strip()\n    )\n    cursor = conn.cursor()\n    cursor.execute(query)\n    info = cursor.fetchall()\n    cursor.close()\n    conn.close()\n    return info\n</code></pre>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.write_yaml","title":"<code>write_yaml(info_dict, icon, yaml_out, project, use_server, alternate, guuid, ftp_client)</code>","text":"<p>Write YAML content for a species entry based on the provided metadata and project type.</p>"},{"location":"ensembl/genes/projects/write_yaml/#ensembl.genes.projects.write_yaml.write_yaml--parameters","title":"Parameters","text":"<p>info_dict : Dict[str, str]     Dictionary containing species metadata. icon : str     Icon filename for the species. yaml_out : file-like object     The output file handle for writing the YAML. project : str     The project name (e.g., 'aquafaang', 'asg', 'bge', ...). use_server : str     Which server the data was fetched from ('st5', 'st6' or 'main'). alternate : str     Alternate assembly name, if available. ftp_client : EnsemblFTP     An initialized FTP client instance for checking extra files.</p> Source code in <code>src/python/ensembl/genes/projects/write_yaml.py</code> <pre><code>def write_yaml(\n    info_dict: Dict[str, str],\n    icon: str,\n    yaml_out,\n    project: str,\n    use_server: str,\n    alternate: str,\n    guuid: str,\n    ftp_client: EnsemblFTP,\n) -&gt; None:\n    \"\"\"\n    Write YAML content for a species entry based on the provided metadata and project type.\n\n    Parameters\n    ----------\n    info_dict : Dict[str, str]\n        Dictionary containing species metadata.\n    icon : str\n        Icon filename for the species.\n    yaml_out : file-like object\n        The output file handle for writing the YAML.\n    project : str\n        The project name (e.g., 'aquafaang', 'asg', 'bge', ...).\n    use_server : str\n        Which server the data was fetched from ('st5', 'st6' or 'main').\n    alternate : str\n        Alternate assembly name, if available.\n    ftp_client : EnsemblFTP\n        An initialized FTP client instance for checking extra files.\n    \"\"\"\n    prod_url_list = [\"bos_taurus_hybrid\", \"bos_indicus_hybrid\"]\n\n    assembly_name = info_dict[\"assembly.name\"].replace(\" \", \"_\")\n    try:\n        date = info_dict[\"genebuild.last_geneset_update\"].replace(\"-\", \"_\")\n    except KeyError:\n        date = \"\"\n    species_name = info_dict[\"species.scientific_name\"].replace(\" \", \"_\")\n    species_name = species_name.replace(\".\", \"\")\n    lc_species_name = species_name.lower()\n\n    if \"species.strain\" in info_dict and info_dict[\"species.strain\"] != \"reference\":\n        info_dict[\"species.scientific_name\"] += f\" ({info_dict['species.strain']})\"\n\n    uc_prod_name = info_dict[\"species.production_name\"].capitalize()\n\n    # Get submitter from assembly report\n    assembly_report_url = (\n        f\"https://www.ncbi.nlm.nih.gov/assembly/{info_dict['assembly.accession']}\"\n    )\n    assembly_report_response = requests.get(assembly_report_url)\n    submitter_match = re.search(\n        r\"Submitter: &lt;/dt&gt;&lt;dd&gt;([^&lt;]*)&lt;/dd&gt;&lt;dt&gt;\", assembly_report_response.text\n    )\n    submitter = submitter_match.group(1) if submitter_match else \"unknown\"\n    if info_dict[\"assembly.accession\"] == \"GCA_000002315.5\":\n        submitter = \"Genome Reference Consortium\"\n\n    source = info_dict.get(\"species.annotation_source\", \"ensembl\")\n\n    # Start building YAML content\n    yaml = f\"- species: {info_dict['species.scientific_name']}\\n\"\n\n    if use_server == \"st5\" or use_server == \"st6\" or use_server == \"gb1\":\n        ftp_base = \"https://ftp.ebi.ac.uk/pub/ensemblorganisms\"\n\n        if project in (\"vgp\", \"dtol\", \"erga\", \"cbp\", \"bge\", \"asg\"):\n            yaml += f\"  image: {icon}\\n\"\n        else:\n            yaml += f\"  submitted_by: {submitter}\\n\"\n\n        yaml += f\"  accession: {info_dict['assembly.accession']}\\n\"\n\n        if project in (\"dtol\", \"erga\", \"cbp\", \"bge\", \"asg\"):\n            # Add annotation method if available, else default to BRAKER2\n            method = info_dict.get(\"genebuild.method_display\", \"BRAKER2\")\n            yaml += f\"  annotation_method: {method}\\n\"\n\n        # ==== annotation_gtf ====\n        gtf = (\n            f\"{ftp_base}/{species_name}/{info_dict['assembly.accession']}/\"\n            f\"{source}/geneset/{date}/genes.gtf.gz\"\n        )\n        if check_url_status(gtf):\n            yaml += f\"  annotation_gtf: {gtf}\\n\"\n        else:\n            fb = ftp_client.check_pre_release_file(\n                species_name, info_dict[\"assembly.accession\"], \".gtf.gz\"\n            )\n            if fb:\n                yaml += f\"  annotation_gtf: {fb}\\n\"\n        # ==== annotation_gff3: try gzipped, then uncompressed, then pre\u2011release ====\n        gff_gz = (\n            f\"{ftp_base}/{species_name}/{info_dict['assembly.accession']}/\"\n            f\"{source}/geneset/{date}/genes.gff3.gz\"\n        )\n        gff = (\n            f\"{ftp_base}/{species_name}/{info_dict['assembly.accession']}/\"\n            f\"{source}/geneset/{date}/genes.gff3\"\n        )\n        if check_url_status(gff_gz):\n            yaml += f\"  annotation_gff3: {gff_gz}\\n\"\n        elif check_url_status(gff):\n            yaml += f\"  annotation_gff3: {gff}\\n\"\n        else:\n            # fallback: look in pre\u2011release for gzipped first, then uncompressed\n            fb = ftp_client.check_pre_release_file(\n                species_name, info_dict[\"assembly.accession\"], \".gff3.gz\"\n            )\n            if not fb:\n                fb = ftp_client.check_pre_release_file(\n                    species_name, info_dict[\"assembly.accession\"], \".gff3\"\n                )\n            if fb:\n                yaml += f\"  annotation_gff3: {fb}\\n\"\n        # ==== proteins ====\n        pep = (\n            f\"{ftp_base}/{species_name}/{info_dict['assembly.accession']}/\"\n            f\"{source}/geneset/{date}/pep.fa.gz\"\n        )\n        if check_url_status(pep):\n            yaml += f\"  proteins: {pep}\\n\"\n        # ==== transcripts ====\n        cdna = (\n            f\"{ftp_base}/{species_name}/{info_dict['assembly.accession']}/\"\n            f\"{source}/geneset/{date}/cdna.fa.gz\"\n        )\n        if check_url_status(cdna):\n            yaml += f\"  transcripts: {cdna}\\n\"\n        # ==== softmasked genome ====\n        soft = (\n            f\"{ftp_base}/{species_name}/{info_dict['assembly.accession']}/genome/\"\n            f\"softmasked.fa.gz\"\n        )\n        if check_url_status(soft):\n            yaml += f\"  softmasked_genome: {soft}\\n\"\n        else:\n            fb = ftp_client.check_pre_release_file(\n                species_name, info_dict[\"assembly.accession\"], \".dna.softmasked.fa.gz\"\n            )\n            if fb:\n                yaml += f\"  softmasked_genome: {fb}\\n\"\n        rm_file = ftp_client.check_for_file(\n            lc_species_name,\n            info_dict[\"species.production_name\"],\n            info_dict[\"assembly.accession\"],\n            source,\n            \"repeatmodeler\",\n        )\n        if rm_file:\n            yaml += f\"  repeat_library: {rm_file}\\n\"\n        # ==== ftp dumps ====\n        dumps = f\"{ftp_base}/{species_name}/{info_dict['assembly.accession']}\"\n        if check_url_status(dumps):\n            yaml += f\"  ftp_dumps: {ftp_base}/{species_name}/{info_dict['assembly.accession']}/\\n\"\n        else:\n            yaml += f\"  ftp_dumps: https://ftp.ebi.ac.uk/pub/databases/ensembl/pre-release/{species_name}/{info_dict['assembly.accession']}/\\n\"\n\n        main_species_url = \"http://www.ensembl.org/info/about/species.html\"\n        main_species_response = requests.get(main_species_url)\n        if info_dict[\"assembly.accession\"] in main_species_response.text:\n            yaml += (\n                f\"  ensembl_link: https://www.ensembl.org/{species_name}/Info/Index\\n\"\n            )\n        else:\n            beta_link = f\"https://beta.ensembl.org/species/{guuid}\"\n            if check_url_status(beta_link):\n                yaml += f\"  beta_link: https://beta.ensembl.org/species/{guuid}\\n\"\n            else:\n                yaml += f\"  beta_link: Coming soon!\\n\"\n\n        if project in (\"dtol\", \"erga\", \"cbp\", \"bge\", \"asg\"):\n            try:\n                yaml += f\"  busco_score: {info_dict['genebuild.busco']}\\n\"\n            except KeyError:\n                busco_file = ftp_client.check_for_file(\n                    species_name,\n                    info_dict[\"species.production_name\"],\n                    info_dict[\"assembly.accession\"],\n                    source,\n                    \"busco\",\n                )\n                if busco_file:\n                    yaml += f\"  busco_score: {busco_file}\\n\"\n            try:\n                yaml += f\"  busco_lineage: {info_dict['genebuild.busco_dataset']}\\n\"\n            except KeyError:\n                if busco_file:\n                    yaml += f\"  busco_lineage: {busco_file}\\n\"\n            if alternate:\n                alternate_url = f\"https://rapid.ensembl.org/{alternate}/Info/Index\"\n                yaml += f\"  alternate: {alternate_url}\\n\"\n\n    elif use_server == \"main\":\n        # Handle \"geneswitch\" project special case with release 102\n        if project == \"geneswitch\":\n            release = \"release-102\"\n            release_number = \"102\"\n        else:\n            release = \"release-\" + info_dict[\"schema_version\"]\n            release_number = info_dict[\"schema_version\"]\n\n        ftp_base = f\"https://ftp.ensembl.org/pub/{release}\"\n\n        if project in (\"vgp\", \"dtol\", \"erga\", \"cbp\", \"bge\", \"asg\"):\n            yaml += f\"  image: {icon}\\n\"\n        else:\n            yaml += f\"  submitted_by: {submitter}\\n\"\n\n        yaml += f\"  accession: {info_dict['assembly.accession']}\\n\"\n\n        if project in (\"dtol\", \"erga\", \"cbp\", \"bge\", \"asg\"):\n            # Annotation method is always Ensembl genebuild on main\n            yaml += \"  annotation_method: Ensembl genebuild\\n\"\n\n        source = \"ensembl\"  # for consistency with busco retrieval logic\n\n        yaml += (\n            f\"  annotation_gtf: {ftp_base}/gtf/{info_dict['species.production_name']}/\"\n            f\"{uc_prod_name}.{assembly_name}.{release_number}.gtf.gz\\n\"\n        )\n        yaml += (\n            f\"  annotation_gff3: {ftp_base}/gff3/{info_dict['species.production_name']}/\"\n            f\"{uc_prod_name}.{assembly_name}.{release_number}.gff3.gz\\n\"\n        )\n        yaml += (\n            f\"  proteins: {ftp_base}/fasta/{info_dict['species.production_name']}/pep/\"\n            f\"{uc_prod_name}.{assembly_name}.pep.all.fa.gz\\n\"\n        )\n        yaml += (\n            f\"  transcripts: {ftp_base}/fasta/{info_dict['species.production_name']}/cdna/\"\n            f\"{uc_prod_name}.{assembly_name}.cdna.all.fa.gz\\n\"\n        )\n        yaml += (\n            f\"  softmasked_genome: {ftp_base}/fasta/{info_dict['species.production_name']}/dna/\"\n            f\"{uc_prod_name}.{assembly_name}.dna_sm.toplevel.fa.gz\\n\"\n        )\n        rm_file = ftp_client.check_for_file(\n            lc_species_name,\n            info_dict[\"species.production_name\"],\n            info_dict[\"assembly.accession\"],\n            source,\n            \"repeatmodeler\",\n        )\n        if rm_file:\n            yaml += f\"  repeat_library: {rm_file}\\n\"\n\n        yaml += f\"  ftp_dumps: {ftp_base}\\n\"\n        if info_dict[\"species.production_name\"] in prod_url_list:\n            yaml += (\n                f\"  ensembl_link: https://www.ensembl.org/{uc_prod_name}/Info/Index\\n\"\n            )\n        elif project == \"geneswitch\":\n            # geneswitch project frozen at e102\n            yaml += (\n                f\"  ensembl_link: https://e102.ensembl.org/{species_name}/Info/Index\\n\"\n            )\n        else:\n            yaml += (\n                f\"  ensembl_link: https://www.ensembl.org/{species_name}/Info/Index\\n\"\n            )\n\n        if project in (\"dtol\", \"erga\", \"cbp\", \"bge\", \"asg\"):\n            try:\n                yaml += f\"  busco_score: {info_dict['genebuild.busco']}\\n\"\n            except KeyError:\n                busco_file = ftp_client.check_for_file(\n                    lc_species_name,\n                    info_dict[\"species.production_name\"],\n                    info_dict[\"assembly.accession\"],\n                    source,\n                    \"busco\",\n                )\n                if busco_file:\n                    yaml += f\"  busco_score: {busco_file}\\n\"\n            try:\n                yaml += f\"  busco_lineage: {info_dict['genebuild.busco_dataset']}\\n\"\n            except KeyError:\n                if busco_file:\n                    yaml += f\"  busco_lineage: {busco_file}\\n\"\n            if alternate:\n                alternate_url = f\"https://rapid.ensembl.org/{alternate}/Info/Index\"\n                yaml += f\"  alternate: {alternate_url}\\n\"\n\n    print(yaml, file=yaml_out)\n</code></pre>"},{"location":"ensembl/genes/stable_id/pid_overlap/","title":"<code>ensembl.genes.stable_id.pid_overlap</code>","text":""},{"location":"ensembl/genes/stable_id/pid_overlap/#ensembl.genes.stable_id.pid_overlap","title":"<code>ensembl.genes.stable_id.pid_overlap</code>","text":""},{"location":"ensembl/genes/stable_id/pid_overlap/#ensembl.genes.stable_id.pid_overlap.gff3_file_new","title":"<code>gff3_file_new = input('Enter the path to the newer GFF3 file: ').strip()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/stable_id/pid_overlap/#ensembl.genes.stable_id.pid_overlap.gff3_file_old","title":"<code>gff3_file_old = input('Enter the path to the older GFF3 file: ').strip()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/stable_id/pid_overlap/#ensembl.genes.stable_id.pid_overlap.output_report","title":"<code>output_report = input('Enter the path for the output report file: ').strip()</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/stable_id/pid_overlap/#ensembl.genes.stable_id.pid_overlap.compare_protein_sets","title":"<code>compare_protein_sets(gff3_file_old, gff3_file_new, output_report)</code>","text":"Source code in <code>src/python/ensembl/genes/stable_id/pid_overlap.py</code> <pre><code>def compare_protein_sets(gff3_file_old, gff3_file_new, output_report):\n    # Extract protein information from both files\n    proteins_old = extract_proteins_from_gff3(gff3_file_old)\n    proteins_new = extract_proteins_from_gff3(gff3_file_new)\n\n    # Find shared protein IDs\n    shared_proteins = pd.merge(\n        proteins_old, proteins_new, on=\"ProteinID\", suffixes=(\"_old\", \"_new\")\n    )\n\n    # Compute proportions\n    proportion_old = (\n        len(shared_proteins) / len(proteins_old) if len(proteins_old) &gt; 0 else 0\n    )\n    proportion_new = (\n        len(shared_proteins) / len(proteins_new) if len(proteins_new) &gt; 0 else 0\n    )\n\n    print(\n        f\"Proportion of proteins in the old GFF3 that have shared IDs: {proportion_old:.2%}\"\n    )\n    print(\n        f\"Proportion of proteins in the new GFF3 that have shared IDs: {proportion_new:.2%}\"\n    )\n\n    # Add columns for genomic locations in the report\n    shared_proteins = shared_proteins[\n        [\n            \"ProteinID\",\n            \"Chromosome_old\",\n            \"Start_old\",\n            \"End_old\",\n            \"Strand_old\",\n            \"Chromosome_new\",\n            \"Start_new\",\n            \"End_new\",\n            \"Strand_new\",\n        ]\n    ]\n\n    # Save report\n    shared_proteins.to_csv(\n        output_report, index=False, sep=\"\\t\", quoting=csv.QUOTE_MINIMAL\n    )\n    print(f\"Report saved to {output_report}\")\n</code></pre>"},{"location":"ensembl/genes/stable_id/pid_overlap/#ensembl.genes.stable_id.pid_overlap.extract_proteins_from_gff3","title":"<code>extract_proteins_from_gff3(gff3_file)</code>","text":"Source code in <code>src/python/ensembl/genes/stable_id/pid_overlap.py</code> <pre><code>def extract_proteins_from_gff3(gff3_file):\n    protein_data = {}\n    with open(gff3_file, \"r\") as file:\n        for line in file:\n            if line.startswith(\"#\"):\n                continue\n            columns = line.strip().split(\"\\t\")\n            if columns[2] == \"CDS\":\n                attributes = columns[8]\n                match = re.search(r\"ID=CDS:([^;]+)\", attributes)\n                if match:\n                    protein_id = match.group(1)\n                    if protein_id not in protein_data:\n                        protein_data[protein_id] = {\n                            \"ProteinID\": protein_id,\n                            \"Chromosome\": columns[0],\n                            \"Start\": int(columns[3]),\n                            \"End\": int(columns[4]),\n                            \"Strand\": columns[6],\n                            \"Attributes\": [attributes],\n                        }\n                    else:\n                        # Update the start and end to encompass all CDS regions for the protein\n                        protein_data[protein_id][\"Start\"] = min(\n                            protein_data[protein_id][\"Start\"], int(columns[3])\n                        )\n                        protein_data[protein_id][\"End\"] = max(\n                            protein_data[protein_id][\"End\"], int(columns[4])\n                        )\n                        protein_data[protein_id][\"Attributes\"].append(attributes)\n    # Flatten attributes into a single string for each protein\n    for protein in protein_data.values():\n        protein[\"Attributes\"] = \";\".join(protein[\"Attributes\"])\n    return pd.DataFrame(protein_data.values())\n</code></pre>"},{"location":"ensembl/genes/tracking/bioproject_tracking/","title":"<code>ensembl.genes.tracking.bioproject_tracking</code>","text":""},{"location":"ensembl/genes/tracking/bioproject_tracking/#ensembl.genes.tracking.bioproject_tracking","title":"<code>ensembl.genes.tracking.bioproject_tracking</code>","text":""},{"location":"ensembl/genes/tracking/bioproject_tracking/#ensembl.genes.tracking.bioproject_tracking.config","title":"<code>config = json.load(f)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/tracking/bioproject_tracking/#ensembl.genes.tracking.bioproject_tracking.add_ftp","title":"<code>add_ftp(annotations, release_type='live')</code>","text":"Source code in <code>src/python/ensembl/genes/tracking/bioproject_tracking.py</code> <pre><code>def add_ftp(\n    annotations: Dict[str, Dict[str, Any]], release_type: str = \"live\"\n) -&gt; Dict[str, Dict[str, Any]]:\n    for accession, annotation in annotations.items():\n        matches = annotation.get(\"matches\") or []\n\n        if release_type == \"pre\":\n            dbnames = set(m.get(\"dbname\") for m in matches if m.get(\"dbname\"))\n            if annotation.get(\"dbname\"):\n                dbnames.add(annotation[\"dbname\"])\n\n            for dbname in dbnames:\n                query = \"\"\"\n                SELECT meta_value\n                FROM meta\n                WHERE meta_key = 'organism.scientific_name'\n                \"\"\"\n                result = mysql_fetch_data(\n                    query,\n                    (),\n                    server_group=\"pre-release\",\n                    server_name=\"gb1\",\n                    db_name=dbname,\n                )\n\n                if not result:\n                    continue  # skip if no scientific name found\n\n                scientific_name = result[0][0].replace(\" \", \"_\").replace(\".\", \"\")\n                ftp_link = f\"https://ftp.ebi.ac.uk/pub/databases/ensembl/pre-release/{scientific_name}/{accession}\"\n\n                # attach to matching entries\n                for m in matches:\n                    if m.get(\"dbname\") == dbname:\n                        m[\"ftp\"] = ftp_link\n                if annotation.get(\"dbname\") == dbname:\n                    annotation[\"ftp\"] = ftp_link  # top-level\n\n        elif release_type == \"live\":\n            # Build map guuid-&gt;match for easy updates\n            by_guuid = {m.get(\"guuid\"): m for m in matches if m.get(\"guuid\")}\n            guuids = set(by_guuid.keys())\n            if annotation.get(\"guuid\"):\n                guuids.add(annotation[\"guuid\"])\n\n            for guuid in guuids:\n                if not guuid or guuid == \"unknown\":\n                    continue\n                query = \"\"\"\n                SELECT genome.genebuild_date, organism.scientific_name, dataset_attribute.value\n                FROM genome\n                JOIN organism USING(organism_id)\n                JOIN genome_dataset USING(genome_id) \n                JOIN dataset_attribute USING(dataset_id)\n                WHERE genome.genome_uuid = %s\n                AND attribute_id=169\n                \"\"\"\n                data_fetch = mysql_fetch_data(query, (guuid,))\n                if not data_fetch:\n                    continue\n\n                date, scientific_name, source = data_fetch[0]\n                date = str(date).replace(\"-\", \"_\")\n                scientific_name = scientific_name.replace(\" \", \"_\").replace(\".\", \"\")\n                source = source.lower()\n                ftp_link = f\"https://ftp.ebi.ac.uk/pub/ensemblorganisms/{scientific_name}/{accession}/{source}/geneset/{date}/\"\n\n                if guuid in by_guuid:\n                    by_guuid[guuid][\"ftp\"] = ftp_link\n                    by_guuid[guuid][\"date\"] = date\n                if annotation.get(\"guuid\") == guuid:\n                    annotation[\"ftp\"] = ftp_link\n                    annotation[\"date\"] = date\n\n    return annotations\n</code></pre>"},{"location":"ensembl/genes/tracking/bioproject_tracking/#ensembl.genes.tracking.bioproject_tracking.get_assembly_accessions","title":"<code>get_assembly_accessions(query_id, query_type, only_haploid=False)</code>","text":"<p>Prefer NCBI Datasets CLI (all versions), fall back to Datasets API (latest only). Supports query_type in {\"bioproject\", \"taxon\"}. Always returns a dict (possibly empty): {accession: {\"taxon_id\": int}}</p> Source code in <code>src/python/ensembl/genes/tracking/bioproject_tracking.py</code> <pre><code>def get_assembly_accessions(\n    query_id: str, query_type: str, only_haploid: bool = False\n) -&gt; Dict[str, Dict[str, int]]:\n    \"\"\"\n    Prefer NCBI Datasets CLI (all versions), fall back to Datasets API (latest only).\n    Supports query_type in {\"bioproject\", \"taxon\"}.\n    Always returns a dict (possibly empty): {accession: {\"taxon_id\": int}}\n    \"\"\"\n\n    def _parse_reports(lines: List[str]) -&gt; Dict[str, Dict[str, int]]:\n        accs: Dict[str, Dict[str, int]] = {}\n        for line in lines:\n            line = line.strip()\n            if not line:\n                continue\n            try:\n                obj = json.loads(line)\n            except json.JSONDecodeError:\n                continue\n            report = obj.get(\"report\", obj)\n            assembly_info = report.get(\"assembly_info\") or {}\n            if only_haploid and assembly_info.get(\"assembly_type\") != \"haploid\":\n                continue\n            accession = report.get(\"accession\")\n            taxon_id = (report.get(\"organism\") or {}).get(\"tax_id\")\n            if accession:\n                accs[accession] = {\"taxon_id\": taxon_id}\n        return accs\n\n    # --- 1) Try CLI (gets ALL versions) ---\n    datasets_cli = shutil.which(\"datasets\")\n    if datasets_cli:\n        try:\n            if query_type == \"bioproject\":\n                cmd = [\n                    datasets_cli,\n                    \"summary\",\n                    \"genome\",\n                    \"accession\",\n                    str(query_id),\n                    \"--assembly-version\",\n                    \"all\",\n                    \"--as-json-lines\",\n                ]\n            elif query_type == \"taxon\":\n                cmd = [\n                    datasets_cli,\n                    \"summary\",\n                    \"genome\",\n                    \"taxon\",\n                    str(query_id),\n                    \"--assembly-version\",\n                    \"all\",\n                    \"--as-json-lines\",\n                ]\n            else:\n                logging.error(f\"Invalid query_type '{query_type}'\")\n                return {}\n\n            result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n            parsed = _parse_reports(result.stdout.splitlines())\n            if parsed:\n                logging.info(\n                    f\"[Datasets CLI] Retrieved {len(parsed)} assemblies (all versions).\"\n                )\n                return parsed\n            else:\n                logging.warning(\n                    \"[Datasets CLI] Parsed zero rows from stdout; falling back to API.\"\n                )\n        except subprocess.CalledProcessError as e:\n            logging.warning(\n                f\"[Datasets CLI] Exit {e.returncode}. STDERR:\\n{e.stderr}\\nFalling back to API.\"\n            )\n        except Exception as e:\n            logging.warning(\n                f\"[Datasets CLI] Unexpected error: {e}. Falling back to API.\"\n            )\n\n    # --- 2) Fallback: API (latest only) ---\n    try:\n        base_url = config[\"urls\"][\"datasets\"].get(query_type)\n    except Exception:\n        base_url = None\n\n    if not base_url:\n        logging.error(\n            \"[Datasets API] Base URL not found in config; returning empty set.\"\n        )\n        return {}\n\n    assembly_accessions: Dict[str, Dict[str, int]] = {}\n    page_size = 5000\n    next_page_token = None\n\n    while True:\n        url = f\"{base_url}/{query_id}/dataset_report?page_size={page_size}\"\n        if next_page_token:\n            url += f\"&amp;page_token={next_page_token}\"\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n            data = response.json()\n            for assembly in data.get(\"reports\", []):\n                assembly_info = assembly.get(\"assembly_info\", {}) or {}\n                if only_haploid and assembly_info.get(\"assembly_type\") != \"haploid\":\n                    continue\n                accession = assembly.get(\"accession\")\n                taxon_id = (assembly.get(\"organism\") or {}).get(\"tax_id\")\n                if accession:\n                    assembly_accessions[accession] = {\"taxon_id\": taxon_id}\n            next_page_token = data.get(\"next_page_token\")\n            if not next_page_token:\n                break\n        except requests.RequestException as e:\n            logging.error(f\"[Datasets API] Error: {e}\")\n            break\n\n    logging.info(\n        f\"[Datasets API] Retrieved {len(assembly_accessions)} assemblies (latest only).\"\n    )\n    return assembly_accessions\n</code></pre>"},{"location":"ensembl/genes/tracking/bioproject_tracking/#ensembl.genes.tracking.bioproject_tracking.get_ensembl_live","title":"<code>get_ensembl_live(accessions_taxon)</code>","text":"<p>Returns (annotated_dict, missing_list). annotated_dict[accession] contains:   - taxon_id (from input)   - matches: List[{\"guuid\",\"dbname\", optional \"ftp\",\"date\"}]   - guuid, dbname: best match (latest core; prefer non-cm)</p> Source code in <code>src/python/ensembl/genes/tracking/bioproject_tracking.py</code> <pre><code>def get_ensembl_live(accessions_taxon: Dict[str, Dict[str, int]]):\n    \"\"\"\n    Returns (annotated_dict, missing_list).\n    annotated_dict[accession] contains:\n      - taxon_id (from input)\n      - matches: List[{\"guuid\",\"dbname\", optional \"ftp\",\"date\"}]\n      - guuid, dbname: best match (latest core; prefer non-cm)\n    \"\"\"\n    accessions = list(accessions_taxon.keys())\n    if not accessions:\n        return {}, []\n\n    query = \"\"\"\n    SELECT DISTINCT\n        assembly.accession,\n        genome.genome_uuid,\n        dataset_source.name AS database_name\n    FROM genome\n    JOIN assembly ON genome.assembly_id = assembly.assembly_id\n    JOIN genome_dataset ON genome.genome_id = genome_dataset.genome_id\n    JOIN dataset ON genome_dataset.dataset_id = dataset.dataset_id\n    JOIN dataset_source ON dataset.dataset_source_id = dataset_source.dataset_source_id\n    JOIN genome_release ON genome.genome_id = genome_release.genome_id\n    JOIN ensembl_release ON genome_release.release_id = ensembl_release.release_id\n    WHERE dataset.name = 'genebuild'\n      AND assembly.accession IN ({})\n    \"\"\".format(\n        \", \".join([\"%s\"] * len(accessions))\n    )\n\n    rows = mysql_fetch_data(query, tuple(accessions))\n\n    # Seed with taxon info so missing ones can still be tracked\n    live_annotations: Dict[str, Dict[str, Any]] = {}\n\n    for accession, guuid, dbname in rows:\n        entry = live_annotations.setdefault(\n            accession, dict(accessions_taxon.get(accession, {}))\n        )\n        entry.setdefault(\"matches\", [])\n        # Avoid duplicates across joins if any\n        if not any(\n            m[\"guuid\"] == guuid and m[\"dbname\"] == dbname for m in entry[\"matches\"]\n        ):\n            entry[\"matches\"].append({\"guuid\": guuid, \"dbname\": dbname})\n\n    # Choose best match for backward compatibility fields\n    for accession, entry in live_annotations.items():\n        matches = entry.get(\"matches\", [])\n        if matches:\n            best = max(matches, key=lambda m: _score_dbname(m[\"dbname\"]))\n            entry[\"guuid\"] = best[\"guuid\"]\n            entry[\"dbname\"] = best[\"dbname\"]\n\n    # Compute missing (accessions with no rows at all)\n    matched_accessions = set(live_annotations.keys())\n    missing_annotations = [acc for acc in accessions if acc not in matched_accessions]\n\n    return live_annotations, missing_annotations\n</code></pre>"},{"location":"ensembl/genes/tracking/bioproject_tracking/#ensembl.genes.tracking.bioproject_tracking.get_pre_release","title":"<code>get_pre_release(missing_annotations)</code>","text":"<p>Checks for the existence of pre-release Ensembl database schemas for a list of missing accessions. This function takes a list of GenBank/RefSeq assembly accessions that were not found in the Ensembl live database lookup (e.g., from <code>get_ensembl_live</code>). It reformats each accession to match the expected pre-release Ensembl database schema naming convention (e.g., 'GCA_000001405.39' \u2192 'gca000001405v39') and queries the MySQL server's <code>information_schema.schemata</code> table to check if a database with that name exists. If such a schema is found, the function records the corresponding accession and database name in the returned dictionary. Args:     missing_annotations (List[str]): A list of assembly accessions (e.g., 'GCA_000001405.39')         for which no live annotation database was found. Returns:     Dict[str, Dict[str, str]]: A dictionary mapping each accession with a found pre-release     database to a nested dictionary containing:         - \"dbname\": The name of the pre-release schema (e.g., 'gca000001405v39').     Example:         {             \"GCA_000001405.39\": {                 \"dbname\": \"gca000001405v39\"             },             ...         } Notes:     - Only accessions matching the pattern 'GCA/GCF_XXXXXXXXX.XX' are processed.     - If no matching schema is found for an accession, it is omitted from the result.     - The function uses <code>mysql_fetch_data</code> to query the MySQL server's schema metadata.</p> Source code in <code>src/python/ensembl/genes/tracking/bioproject_tracking.py</code> <pre><code>def get_pre_release(missing_annotations: List[str]) -&gt; Dict[str, Dict[str, str]]:\n    \"\"\"\n    Checks for the existence of pre-release Ensembl database schemas for a list of missing accessions.\n    This function takes a list of GenBank/RefSeq assembly accessions that were not found in the\n    Ensembl live database lookup (e.g., from `get_ensembl_live`). It reformats each accession\n    to match the expected pre-release Ensembl database schema naming convention (e.g.,\n    'GCA_000001405.39' \u2192 'gca000001405v39') and queries the MySQL server's\n    `information_schema.schemata` table to check if a database with that name exists.\n    If such a schema is found, the function records the corresponding accession and\n    database name in the returned dictionary.\n    Args:\n        missing_annotations (List[str]): A list of assembly accessions (e.g., 'GCA_000001405.39')\n            for which no live annotation database was found.\n    Returns:\n        Dict[str, Dict[str, str]]: A dictionary mapping each accession with a found pre-release\n        database to a nested dictionary containing:\n            - \"dbname\": The name of the pre-release schema (e.g., 'gca000001405v39').\n        Example:\n            {\n                \"GCA_000001405.39\": {\n                    \"dbname\": \"gca000001405v39\"\n                },\n                ...\n            }\n    Notes:\n        - Only accessions matching the pattern 'GCA/GCF_XXXXXXXXX.XX' are processed.\n        - If no matching schema is found for an accession, it is omitted from the result.\n        - The function uses `mysql_fetch_data` to query the MySQL server's schema metadata.\n    \"\"\"\n    pre_release_annotations: Dict[str, Dict[str, str]] = {}\n\n    for accession in missing_annotations:\n        match = re.match(r\"(GCA|GCF)_(\\d+)\\.(\\d+)\", accession)\n        if not match:\n            continue  # skip malformed accession\n\n        prefix, number, version = match.groups()\n        lookup_string = f\"%{prefix.lower()}{number}v{version}%\"\n\n        query = \"\"\"\n        SELECT SCHEMA_NAME\n        FROM information_schema.schemata\n        WHERE SCHEMA_NAME like %s\n        \"\"\"\n        result = mysql_fetch_data(\n            query, (lookup_string,), server_group=\"pre-release\", server_name=\"gb1\"\n        )\n\n        if result:\n            pre_release_annotations[accession] = {\n                \"guuid\": \"unknown\",  # typo fixed from guiid -&gt; guuid\n                \"dbname\": result[0][0],\n            }\n    return pre_release_annotations\n</code></pre>"},{"location":"ensembl/genes/tracking/bioproject_tracking/#ensembl.genes.tracking.bioproject_tracking.get_taxonomy_info","title":"<code>get_taxonomy_info(live_annotations, accessions_taxon, rank)</code>","text":"<p>Fetches taxonomy information for a given rank from the NCBI Datasets API. For each accession in <code>live_annotations</code>, this function retrieves its <code>taxon_id</code> and queries the NCBI taxonomy endpoint to get the classification at the specified rank. The retrieved rank name is then added to the corresponding annotation data. Args:     live_annotations (Dict[str, Dict[str, str]]): A dictionary where each key is         an assembly accession and its value contains annotation details (including         at least \"taxon_id\").     accessions_taxon (Dict[str, Dict[str, int]]): A dictionary mapping accessions         to basic taxon information, such as {\"GCA_000001405.39\": {\"taxon_id\": 9606}}.     rank (str): The taxonomic rank to retrieve (e.g., \"order\", \"class\", \"phylum\"). Returns:     Dict[str, Dict[str, str]]: The updated <code>live_annotations</code> dictionary with an     additional key for the requested rank. For example:         {             \"GCA_000001405.39\": {                 \"taxon_id\": 9606,                 \"guuid\": \"some-uuid\",                 \"dbname\": \"ensembl_core\",                 \"order\": \"Primates\"             },             ...         }     If the API query fails or the rank is not found, the value for that rank is not added     (or set to None/unknown).</p> Source code in <code>src/python/ensembl/genes/tracking/bioproject_tracking.py</code> <pre><code>def get_taxonomy_info(\n    live_annotations: Dict[str, Dict[str, Any]],\n    accessions_taxon: Dict[str, Dict[str, int]],\n    rank: str,\n) -&gt; Dict[str, Dict[str, Any]]:\n    \"\"\"\n    Fetches taxonomy information for a given rank from the NCBI Datasets API.\n    For each accession in `live_annotations`, this function retrieves its `taxon_id`\n    and queries the NCBI taxonomy endpoint to get the classification at the specified rank.\n    The retrieved rank name is then added to the corresponding annotation data.\n    Args:\n        live_annotations (Dict[str, Dict[str, str]]): A dictionary where each key is\n            an assembly accession and its value contains annotation details (including\n            at least \"taxon_id\").\n        accessions_taxon (Dict[str, Dict[str, int]]): A dictionary mapping accessions\n            to basic taxon information, such as {\"GCA_000001405.39\": {\"taxon_id\": 9606}}.\n        rank (str): The taxonomic rank to retrieve (e.g., \"order\", \"class\", \"phylum\").\n    Returns:\n        Dict[str, Dict[str, str]]: The updated `live_annotations` dictionary with an\n        additional key for the requested rank. For example:\n            {\n                \"GCA_000001405.39\": {\n                    \"taxon_id\": 9606,\n                    \"guuid\": \"some-uuid\",\n                    \"dbname\": \"ensembl_core\",\n                    \"order\": \"Primates\"\n                },\n                ...\n            }\n        If the API query fails or the rank is not found, the value for that rank is not added\n        (or set to None/unknown).\n    \"\"\"\n    for accession in live_annotations:\n        taxon_id = accessions_taxon[accession][\"taxon_id\"]\n        url = f\"https://api.ncbi.nlm.nih.gov/datasets/v2alpha/taxonomy/taxon/{taxon_id}/dataset_report\"\n\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n            data = response.json()\n\n            taxonomies = data.get(\"reports\", [])\n            for taxonomy in taxonomies:\n                rank_name = (\n                    taxonomy.get(\"taxonomy\", {})\n                    .get(\"classification\", {})\n                    .get(rank, {})\n                    .get(\"name\")\n                )\n                taxonomy_info = {rank: rank_name}\n                live_annotations[accession].update(taxonomy_info)\n\n        except requests.HTTPError as http_err:\n            logging.error(f\"HTTP error occurred: {http_err}\")\n        except Exception as err:\n            logging.error(f\"An error occurred: {err}\")\n\n    return live_annotations\n</code></pre>"},{"location":"ensembl/genes/tracking/bioproject_tracking/#ensembl.genes.tracking.bioproject_tracking.main","title":"<code>main()</code>","text":"<p>Main entry point of the script. Parses command-line arguments to determine if a BioProject ID or Taxon ID is provided, whether to filter only haploid assemblies, the desired output file path, the taxonomic rank to retrieve, and whether to include FTP links. It then:   1. Fetches assembly accessions from the NCBI API based on the provided ID.   2. Fetches corresponding Ensembl live database information from the local MySQL database.   3. Retrieves taxonomy information for the specified rank from the NCBI API.   4. Optionally adds FTP links if requested.   5. Writes all collected data into a tab-separated report file. Usage Example:     python script_name.py --bioproject_id PRJNA12345 --haploid --rank order --ftp Returns:     None</p> Source code in <code>src/python/ensembl/genes/tracking/bioproject_tracking.py</code> <pre><code>def main():\n    \"\"\"\n    Main entry point of the script.\n    Parses command-line arguments to determine if a BioProject ID or Taxon ID is provided,\n    whether to filter only haploid assemblies, the desired output file path, the taxonomic\n    rank to retrieve, and whether to include FTP links. It then:\n      1. Fetches assembly accessions from the NCBI API based on the provided ID.\n      2. Fetches corresponding Ensembl live database information from the local MySQL database.\n      3. Retrieves taxonomy information for the specified rank from the NCBI API.\n      4. Optionally adds FTP links if requested.\n      5. Writes all collected data into a tab-separated report file.\n    Usage Example:\n        python script_name.py --bioproject_id PRJNA12345 --haploid --rank order --ftp\n    Returns:\n        None\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Fetch assembly data and report annotations.\"\n    )\n    parser.add_argument(\"--bioproject_id\", type=str, help=\"NCBI BioProject ID\")\n    parser.add_argument(\"--taxon_id\", type=str, help=\"Taxonomy ID\")\n    parser.add_argument(\n        \"--haploid\", action=\"store_true\", help=\"Fetch only haploid assemblies\"\n    )\n    parser.add_argument(\"--report_file\", type=str, default=\"./report_file.tsv\")\n    parser.add_argument(\n        \"--classification\",\n        action=\"store_true\",\n        help=\"Provide breakdown of taxonomic classification\",\n    )\n    parser.add_argument(\"--rank\", type=str, default=\"order\")\n    parser.add_argument(\n        \"--ftp\", action=\"store_true\", help=\"Include FTP links in the report\"\n    )\n    parser.add_argument(\n        \"--pre_release\",\n        action=\"store_true\",\n        help=\"Include list of pre-release databases in the report\",\n    )\n\n    args = parser.parse_args()\n\n    # Determine which ID is provided and which query type is relevant\n    if not args.bioproject_id and not args.taxon_id:\n        parser.error(\"You must provide either --bioproject_id or --taxon_id\")\n\n    accessions_taxon = get_assembly_accessions(\n        args.bioproject_id or args.taxon_id,\n        \"bioproject\" if args.bioproject_id else \"taxon\",\n        args.haploid,\n    )\n\n    # Fetch annotations (live)\n    live_annotations, missing_annotations = get_ensembl_live(accessions_taxon)\n\n    # Taxonomy classification (top-level only; rows inherit from details)\n    if args.classification:\n        get_taxonomy_info(live_annotations, accessions_taxon, args.rank)\n\n    # Optionally add FTP links\n    if args.ftp:\n        live_annotations = add_ftp(live_annotations, \"live\")\n\n    # Unique species count from live annotations\n    unique_taxon_ids = {\n        details[\"taxon_id\"]\n        for details in live_annotations.values()\n        if \"taxon_id\" in details\n    }\n\n    # Optionally add Pre-release data\n    if args.pre_release and missing_annotations:\n        pre_release_annotations = get_pre_release(missing_annotations)\n\n        for accession in pre_release_annotations:\n            if accession in accessions_taxon:\n                pre_release_annotations[accession][\"taxon_id\"] = accessions_taxon[\n                    accession\n                ][\"taxon_id\"]\n\n        if args.classification and pre_release_annotations:\n            get_taxonomy_info(pre_release_annotations, accessions_taxon, args.rank)\n\n        if args.ftp and pre_release_annotations:\n            pre_release_annotations = add_ftp(pre_release_annotations, \"pre\")\n\n        all_annotations: Dict[str, Dict[str, Any]] = {\n            **live_annotations,\n            **pre_release_annotations,\n        }\n    else:\n        all_annotations = live_annotations\n\n    # Console summary\n    if args.bioproject_id:\n        print(\n            f\"Found {len(accessions_taxon)} assemblies under BioProject ID {args.bioproject_id}\"\n        )\n    elif args.taxon_id:\n        print(f\"Found {len(accessions_taxon)} assemblies for taxon ID {args.taxon_id}\")\n\n    print(\n        f\"Found {len(live_annotations)} annotations in beta.ensembl.org for {len(unique_taxon_ids)} unique species\"\n    )\n\n    if args.classification:\n        rank_values = [\n            details.get(args.rank, \"unknown\") for details in live_annotations.values()\n        ]\n        rank_counts = Counter(rank_values)\n        print(\"\\nBreakdown:\")\n        print(rank_counts)\n\n    # Write final report\n    write_report(\n        all_annotations,\n        args.report_file,\n        args.rank,\n        include_class=args.classification,\n        include_ftp=args.ftp,\n    )\n</code></pre>"},{"location":"ensembl/genes/tracking/bioproject_tracking/#ensembl.genes.tracking.bioproject_tracking.mysql_fetch_data","title":"<code>mysql_fetch_data(query, params=(), server_group='meta', server_name='beta', db_name=None)</code>","text":"<p>Executes a SQL query with optional parameters to fetch results from a specified MySQL server.</p> <p>Returns empty list on error or no data.</p> Source code in <code>src/python/ensembl/genes/tracking/bioproject_tracking.py</code> <pre><code>def mysql_fetch_data(\n    query: str,\n    params: Tuple = (),\n    server_group: str = \"meta\",\n    server_name: str = \"beta\",\n    db_name: Optional[str] = None,\n) -&gt; List[Tuple[Any, ...]]:\n    \"\"\"\n    Executes a SQL query with optional parameters to fetch results from a specified MySQL server.\n\n    Returns empty list on error or no data.\n    \"\"\"\n    try:\n        server_config = config[\"server_details\"][server_group][server_name]\n        connection = pymysql.connect(\n            host=server_config[\"db_host\"],\n            user=server_config[\"db_user\"],\n            port=server_config[\"db_port\"],\n            database=db_name or server_config.get(\"db_name\", \"\"),\n        )\n        with connection.cursor() as cursor:\n            cursor.execute(query, params)\n            result = cursor.fetchall()\n        connection.close()\n        return result\n\n    except KeyError as key_err:\n        logging.error(f\"Invalid server group or name in config: {key_err}\")\n    except pymysql.Error as sql_err:\n        logging.error(f\"MySQL Error: {sql_err}\")\n\n    return []\n</code></pre>"},{"location":"ensembl/genes/tracking/bioproject_tracking/#ensembl.genes.tracking.bioproject_tracking.write_report","title":"<code>write_report(live_annotations, report_file, rank, include_class=False, include_ftp=False)</code>","text":"<p>Writes a tab-separated report. If an accession has multiple matches, produces one line per match; otherwise one line.</p> Source code in <code>src/python/ensembl/genes/tracking/bioproject_tracking.py</code> <pre><code>def write_report(\n    live_annotations: Dict[str, Dict[str, Any]],\n    report_file: str,\n    rank: str,\n    include_class: bool = False,\n    include_ftp: bool = False,\n):\n    \"\"\"\n    Writes a tab-separated report. If an accession has multiple matches,\n    produces one line per match; otherwise one line.\n    \"\"\"\n    report_path = Path(report_file)\n    lines_written = 0\n\n    with open(report_path, \"w\", encoding=\"utf-8\") as file:\n        for accession, details in live_annotations.items():\n            matches = details.get(\"matches\")\n\n            # If we have multiple, write one row per match\n            rows = (\n                matches\n                if matches\n                else [\n                    {\n                        \"guuid\": details.get(\"guuid\"),\n                        \"dbname\": details.get(\"dbname\"),\n                        \"ftp\": details.get(\"ftp\"),\n                        \"date\": details.get(\"date\"),\n                    }\n                ]\n            )\n\n            for m in rows:\n                row = [\n                    str(accession),\n                    str(m.get(\"guuid\") or \"unknown\"),\n                    str(m.get(\"dbname\") or \"unknown\"),\n                ]\n                if include_class:\n                    row.append(str(details.get(rank) or \"unknown\"))\n                if include_ftp:\n                    row.append(str(m.get(\"date\") or details.get(\"date\") or \"\"))\n                    row.append(str(m.get(\"ftp\") or details.get(\"ftp\") or \"N/A\"))\n\n                file.write(\"\\t\".join(row) + \"\\n\")\n                lines_written += 1\n\n    logging.info(\n        f\"Report written to {report_path.resolve()} with {lines_written} lines.\"\n    )\n</code></pre>"},{"location":"ensembl/genes/tracking/live_tracking/","title":"<code>ensembl.genes.tracking.live_tracking</code>","text":""},{"location":"ensembl/genes/tracking/live_tracking/#ensembl.genes.tracking.live_tracking","title":"<code>ensembl.genes.tracking.live_tracking</code>","text":""},{"location":"ensembl/genes/tracking/live_tracking/#ensembl.genes.tracking.live_tracking.config","title":"<code>config = json.load(f)</code>  <code>module-attribute</code>","text":""},{"location":"ensembl/genes/tracking/live_tracking/#ensembl.genes.tracking.live_tracking.check_database_on_server","title":"<code>check_database_on_server(db, server_key, config)</code>","text":"<p>Checks if a database exists on a given server. Args:     db (str): The name of the database to check.     server_key (str): The key of the server in the config.     server_dict (dict): Dictionary containing server connection details. Returns:     bool: True if the database exists, False otherwise.</p> Source code in <code>src/python/ensembl/genes/tracking/live_tracking.py</code> <pre><code>def check_database_on_server(db, server_key, config):\n    \"\"\"\n    Checks if a database exists on a given server.\n    Args:\n        db (str): The name of the database to check.\n        server_key (str): The key of the server in the config.\n        server_dict (dict): Dictionary containing server connection details.\n    Returns:\n        bool: True if the database exists, False otherwise.\n    \"\"\"\n    try:\n        conn = pymysql.connect(\n            host=config[\"server_details\"][\"staging\"][server_key][\"db_host\"],\n            user=config[\"server_details\"][\"staging\"][server_key][\"db_user\"],\n            passwd=config[\"server_details\"][\"staging\"][server_key][\"db_pass\"],\n            port=config[\"server_details\"][\"staging\"][server_key][\"db_port\"],\n        )\n        with conn.cursor() as cur:\n            cur.execute(\n                \"SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s\",\n                (db,),\n            )\n            result = cur.fetchone()\n            return result is not None\n\n    except pymysql.MySQLError as e:\n        print(f\"Error connecting to {server_key}: {e}\")\n        return False\n    finally:\n        if \"conn\" in locals() and conn:\n            conn.close()\n</code></pre>"},{"location":"ensembl/genes/tracking/live_tracking/#ensembl.genes.tracking.live_tracking.clean_server","title":"<code>clean_server(config, mode)</code>","text":"<p>Fetches a list of core databases that are both current in the rapid database and present on the MySQL server.</p> <p>This function performs the following steps: 1. Executes a query on the rapid database to fetch all current core databases. 2. Executes a query on the MySQL server to fetch all core databases. 3. Compares the results from both queries and compiles a list of core databases that are present in both.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>A list of core databases that are current in the rapid database and present on the MySQL server.</p> Source code in <code>src/python/ensembl/genes/tracking/live_tracking.py</code> <pre><code>def clean_server(config, mode: str):\n    \"\"\"\n    Fetches a list of core databases that are both current in the rapid database and present on the MySQL server.\n\n    This function performs the following steps:\n    1. Executes a query on the rapid database to fetch all current core databases.\n    2. Executes a query on the MySQL server to fetch all core databases.\n    3. Compares the results from both queries and compiles a list of core databases that are present in both.\n\n    Returns:\n        list: A list of core databases that are current in the rapid database and present on the MySQL server.\n    \"\"\"\n    rapid_live_databases = []\n    beta_live_databases = []\n\n    cores_query = \"SHOW DATABASES like '%core%';\"\n    cores_fetch = mysql_fetch_data(\n        cores_query,\n        \"\",\n        config[\"server_details\"][\"genebuild\"][\"prod_1\"][\"db_host\"],\n        config[\"server_details\"][\"genebuild\"][\"prod_1\"][\"db_port\"],\n        config[\"server_details\"][\"genebuild\"][\"prod_1\"][\"db_user\"],\n    )\n    core_dbs = [db[0] for db in cores_fetch]\n\n    if mode == \"rapid\":\n        rapid_query = (\n            \"SELECT dbname FROM genome_database JOIN genome USING(genome_id) \"\n            \"JOIN data_release USING(data_release_id) WHERE is_current = 1 and dbname like '%core%';\"\n        )\n        rapid_fetch = mysql_fetch_data(\n            rapid_query,\n            config[\"server_details\"][\"meta\"][\"rapid\"][\"db_name\"],\n            config[\"server_details\"][\"meta\"][\"rapid\"][\"db_host\"],\n            config[\"server_details\"][\"meta\"][\"rapid\"][\"db_port\"],\n            config[\"server_details\"][\"meta\"][\"rapid\"][\"db_user\"],\n        )\n        rapid_databases = [rrdb[0] for rrdb in rapid_fetch]\n\n        for core_db in core_dbs:\n            if core_db in rapid_databases:\n                for server_key in [\"st5\", \"st6\"]:\n                    if check_database_on_server(core_db, server_key, config):\n                        rapid_live_databases.append(core_db)\n                        break\n        return rapid_live_databases\n\n    elif mode == \"beta\":\n        beta_query = (\n            \"SELECT DISTINCT(dataset_source.name) AS dbname FROM genome \"\n            \"JOIN assembly ON genome.assembly_id = assembly.assembly_id \"\n            \"JOIN genome_dataset ON genome.genome_id = genome_dataset.genome_id \"\n            \"JOIN dataset ON genome_dataset.dataset_id = dataset.dataset_id \"\n            \"JOIN dataset_source ON dataset.dataset_source_id = dataset_source.dataset_source_id \"\n            \"JOIN genome_release ON genome.genome_id = genome_release.genome_id \"\n            \"JOIN ensembl_release ON genome_release.release_id = ensembl_release.release_id \"\n            \"WHERE dataset.name='assembly' AND dataset.status='Released';\"\n        )\n        beta_fetch = mysql_fetch_data(\n            beta_query,\n            config[\"server_details\"][\"meta\"][\"beta\"][\"db_name\"],\n            config[\"server_details\"][\"meta\"][\"beta\"][\"db_host\"],\n            config[\"server_details\"][\"meta\"][\"beta\"][\"db_port\"],\n            config[\"server_details\"][\"meta\"][\"beta\"][\"db_user\"],\n        )\n        beta_databases = [rrdb[0] for rrdb in beta_fetch]\n\n        for core_db in core_dbs:\n            if core_db in beta_databases:\n                for server_key in [\"st5\", \"st6\"]:\n                    if check_database_on_server(core_db, server_key, config):\n                        beta_live_databases.append(core_db)\n                        break\n        return beta_live_databases\n\n    else:\n        raise ValueError(\"Mode must be either 'rapid' or 'beta'\")\n</code></pre>"},{"location":"ensembl/genes/tracking/live_tracking/#ensembl.genes.tracking.live_tracking.main","title":"<code>main()</code>","text":"Source code in <code>src/python/ensembl/genes/tracking/live_tracking.py</code> <pre><code>def main():\n    parser = argparse.ArgumentParser(\n        description=\"Check rapid or beta metadata databases.\"\n    )\n    parser.add_argument(\n        \"--mode\",\n        choices=[\"rapid\", \"beta\"],\n        required=True,\n        help=\"Choose either 'rapid' or 'beta'\",\n    )\n    args = parser.parse_args()\n\n    live_databases = clean_server(config, args.mode)\n\n    print(\n        f\"Here is a list of databases on genebuild-prod-1 that can also be found in the {args.mode} metadata:\"\n    )\n    for db in live_databases:\n        print(f\"{db}\")\n</code></pre>"},{"location":"ensembl/genes/tracking/live_tracking/#ensembl.genes.tracking.live_tracking.mysql_fetch_data","title":"<code>mysql_fetch_data(query, database, host, port, user)</code>","text":"<p>Executes a given SQL query on a MySQL database and fetches the result.</p> <p>This function establishes a connection to the MySQL database using provided connection details. It then executes the given query using a cursor obtained from the connection. After executing the query, it fetches all the rows of the query result and returns them. The function handles any errors that might occur during the process and ensures that the database connection is closed before returning the result.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>database</code> <code>str</code> <p>The name of the database to connect to.</p> required <code>host</code> <code>str</code> <p>The host name or IP address of the MySQL server.</p> required <code>port</code> <code>int</code> <p>The port number to use for the connection.</p> required <code>user</code> <code>str</code> <p>The username to use for the database connection.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>List[Tuple[Any, ...]]</code> <p>A tuple of tuples containing the rows returned by the query execution.</p> Note <p>This function does not handle database password authentication. Ensure that the provided user has the necessary permissions and that the database is configured to allow password-less connections from the given host.</p> Source code in <code>src/python/ensembl/genes/tracking/live_tracking.py</code> <pre><code>def mysql_fetch_data(\n    query: str, database: str, host: str, port: int, user: str\n) -&gt; List[Tuple[Any, ...]]:\n    \"\"\"\n    Executes a given SQL query on a MySQL database and fetches the result.\n\n    This function establishes a connection to the MySQL database using provided connection details.\n    It then executes the given query using a cursor obtained from the connection. After executing the query,\n    it fetches all the rows of the query result and returns them. The function handles any errors that might\n    occur during the process and ensures that the database connection is closed before returning the result.\n\n    Args:\n        query (str): The SQL query to be executed.\n        database (str): The name of the database to connect to.\n        host (str): The host name or IP address of the MySQL server.\n        port (int): The port number to use for the connection.\n        user (str): The username to use for the database connection.\n\n    Returns:\n        tuple: A tuple of tuples containing the rows returned by the query execution.\n\n    Note:\n        This function does not handle database password authentication. Ensure that the provided user\n        has the necessary permissions and that the database is configured to allow password-less connections\n        from the given host.\n    \"\"\"\n    try:\n        conn = pymysql.connect(\n            host=host, user=user, port=port, database=database.strip()\n        )\n\n        cursor = conn.cursor()\n        cursor.execute(query)\n        result = cursor.fetchall()\n\n        cursor.close()\n        conn.close()\n\n        return result\n\n    except pymysql.Error as err:\n        print(f\"Error: {err}\")\n\n        try:\n            cursor.close()\n            conn.close()\n        except:\n            pass\n        return []\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/check_for_transcriptomic/","title":"<code>ensembl.genes.transcriptomic_data.check_for_transcriptomic</code>","text":""},{"location":"ensembl/genes/transcriptomic_data/check_for_transcriptomic/#ensembl.genes.transcriptomic_data.check_for_transcriptomic","title":"<code>ensembl.genes.transcriptomic_data.check_for_transcriptomic</code>","text":"<p>Check the availability for short and long read data from ENA website given a taxon id</p>"},{"location":"ensembl/genes/transcriptomic_data/check_for_transcriptomic/#ensembl.genes.transcriptomic_data.check_for_transcriptomic.InputSchema","title":"<code>InputSchema</code>","text":"<p>               Bases: <code>ArgumentParser</code></p> <p>Input arguments</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/check_for_transcriptomic.py</code> <pre><code>class InputSchema(argparse.ArgumentParser):\n    \"\"\"Input arguments\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n        self.add_argument(\"-t\", \"--taxon_id\", type=str, required=False, help=\"Taxon id\")\n\n        self.add_argument(\n            \"--tree\",\n            action=\"store_true\",\n            required=False,\n            help=\"Turn on the 'Include subordinate taxa' option in your query to ENA\",\n        )\n        self.add_argument(\n            \"--file\",\n            type=str,\n            required=False,\n            help=\"Path to the file containing a list of taxon ids\",\n        )\n        self.add_argument(\"--output_dir\", required=True, help=\"Output directory path\")\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/check_for_transcriptomic/#ensembl.genes.transcriptomic_data.check_for_transcriptomic.check_data_from_ena","title":"<code>check_data_from_ena(taxon_id, tree)</code>","text":"<p>Query ENA API to get short or long read data</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/check_for_transcriptomic.py</code> <pre><code>def check_data_from_ena(  # pylint: disable=too-many-locals\n    taxon_id: int,\n    tree: bool,\n) -&gt; dict:\n    \"\"\"Query ENA API to get short or long read data\"\"\"\n\n    TEXT_FORMAT = {\"BOLD\": \"\\033[1m\", \"UNDERLINE\": \"\\033[4m\", \"END\": \"\\033[0m\"}\n    if tree:\n        query = f\"tax_tree({taxon_id})\"\n    else:\n        query = f\"tax_eq({taxon_id})\"\n\n    query_short_paired = (\n        query\n        + \" AND instrument_platform=ILLUMINA AND library_layout=PAIRED\"\n        + \" AND library_source=TRANSCRIPTOMIC\"\n    )\n    query_short_single = (\n        query\n        + \" AND instrument_platform=ILLUMINA AND library_layout=SINGLE\"\n        + \" AND library_source=TRANSCRIPTOMIC\"\n    )\n    query_pacbio = (\n        query + \" AND instrument_platform=PACBIO_SMRT AND library_source=TRANSCRIPTOMIC\"\n    )\n    query_onp = (\n        query\n        + \" AND instrument_platform=OXFORD_NANOPORE AND library_source=TRANSCRIPTOMIC\"\n    )\n\n    short_paired_runs = ena_rest_api(query_short_paired)\n    short_single_runs = ena_rest_api(query_short_single)\n    pacbio_read_runs = ena_rest_api(query_pacbio)\n    onp_read_runs = ena_rest_api(query_onp)\n\n    print(\n        TEXT_FORMAT[\"BOLD\"]\n        + \"Short-read paired-end illumina data available! \"\n        + TEXT_FORMAT[\"END\"]\n        + f\"Found {short_paired_runs} runs.\"\n    )\n    print(\n        TEXT_FORMAT[\"BOLD\"]\n        + \"Short-read single-end illumina data available! \"\n        + TEXT_FORMAT[\"END\"]\n        + f\"Found {short_single_runs} runs.\"\n    )\n    print(\n        TEXT_FORMAT[\"BOLD\"]\n        + \"Long-read PacBio data available! \"\n        + TEXT_FORMAT[\"END\"]\n        + f\"Found {pacbio_read_runs} runs.\"\n    )\n    print(\n        TEXT_FORMAT[\"BOLD\"]\n        + \"Long_read ONP data available! \"\n        + TEXT_FORMAT[\"END\"]\n        + f\"Found {onp_read_runs} runs.\"\n    )\n\n    return {\n        \"Short-read paired-end illumina\": short_paired_runs,\n        \"Short-read single-end illumina\": short_single_runs,\n        \"Long-read PacBio\": pacbio_read_runs,\n        \"Long-read ONP\": onp_read_runs,\n    }\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/check_for_transcriptomic/#ensembl.genes.transcriptomic_data.check_for_transcriptomic.ena_rest_api","title":"<code>ena_rest_api(query)</code>","text":"<p>Call to ENA API</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/check_for_transcriptomic.py</code> <pre><code>def ena_rest_api(query: str) -&gt; int:\n    \"\"\"Call to ENA API\"\"\"\n    search_url = f\"https://www.ebi.ac.uk/ena/portal/api/search?display=report&amp;query={query}&amp;domain=read&amp;result=read_run&amp;fields=sample_accession,run_accession,fastq_ftp,read_count,instrument_platform\"  # pylint: disable=line-too-long\n    search_result = requests.get(search_url)\n    results = search_result.text.strip().split(\"\\n\")[1:]\n    return len(results)\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/check_for_transcriptomic/#ensembl.genes.transcriptomic_data.check_for_transcriptomic.main","title":"<code>main()</code>","text":"<p>Entrypoint</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/check_for_transcriptomic.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Entrypoint\"\"\"\n    parser = InputSchema()\n    args = parser.parse_args()\n    output_dir = Path(args.output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    taxon_ids = [args.taxon_id]  # Start with the single taxon_id\n\n    if args.file:\n        with open(args.file, \"r\") as input_file:\n            taxon_ids = input_file.read().splitlines()\n\n    # Prepare CSV file\n    csv_file = output_dir / \"taxon_summary.csv\"\n    with open(csv_file, mode=\"w\", newline=\"\") as file:\n        writer = csv.writer(file)\n\n        # Write the header row\n        writer.writerow(\n            [\n                \"Taxon ID\",\n                \"Short-read paired-end illumina\",\n                \"Short-read single-end illumina\",\n                \"Long-read PacBio\",\n                \"Long-read ONP\",\n            ]\n        )\n\n        for taxon_id in taxon_ids:\n            results = check_data_from_ena(int(taxon_id), args.tree)\n            writer.writerow(\n                [\n                    taxon_id,\n                    results[\"Short-read paired-end illumina\"],\n                    results[\"Short-read single-end illumina\"],\n                    results[\"Long-read PacBio\"],\n                    results[\"Long-read ONP\"],\n                ]\n            )\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/get_transcriptomic_data/","title":"<code>ensembl.genes.transcriptomic_data.get_transcriptomic_data</code>","text":""},{"location":"ensembl/genes/transcriptomic_data/get_transcriptomic_data/#ensembl.genes.transcriptomic_data.get_transcriptomic_data","title":"<code>ensembl.genes.transcriptomic_data.get_transcriptomic_data</code>","text":"<p>Download short and long read data from ENA website</p>"},{"location":"ensembl/genes/transcriptomic_data/get_transcriptomic_data/#ensembl.genes.transcriptomic_data.get_transcriptomic_data.InputSchema","title":"<code>InputSchema</code>","text":"<p>               Bases: <code>ArgumentParser</code></p> <p>Input arguments</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/get_transcriptomic_data.py</code> <pre><code>class InputSchema(argparse.ArgumentParser):\n    \"\"\"Input arguments\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n        self.add_argument(\"-t\", \"--taxon_id\", type=int, required=True, help=\"Taxon id\")\n        self.add_argument(\n            \"--tree\",\n            action=\"store_true\",\n            required=False,\n            help=\"Turn on the 'Include subordinate taxa' option in your query to ENA\",\n        )\n        self.add_argument(\n            \"-f\",\n            \"--csv_file\",\n            type=str,\n            required=True,\n            help=\"Output file path (csv format)\",\n        )\n        self.add_argument(\n            \"-r\",\n            \"--read_type\",\n            choices=[\"short\", \"long\"],\n            required=True,\n            help=\"Specify the type of transcriptomic data to download ['short', 'long']\",\n        )\n        self.add_argument(\n            \"-l\",\n            \"--limit\",\n            type=int,\n            required=False,\n            help=\"The number of runs to be included in your csv file - consider that 1 run = 2 files, so setting '-l 50' will result in 100 lines in your csv (WARNING: this limit does not consider quality of data, it is a simple subsampling)\",\n        )\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/get_transcriptomic_data/#ensembl.genes.transcriptomic_data.get_transcriptomic_data.get_data_from_ena","title":"<code>get_data_from_ena(taxon_id, read_type, tree)</code>","text":"<p>Query ENA API to get short or long read data</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/get_transcriptomic_data.py</code> <pre><code>def get_data_from_ena(taxon_id: int, read_type: str, tree: bool) -&gt; List[str]:\n    \"\"\"Query ENA API to get short or long read data\"\"\"\n    csv_data = []\n\n    if tree:\n        query = f\"tax_tree({taxon_id})\"\n    else:\n        query = f\"tax_eq({taxon_id})\"\n\n    if read_type == \"short\":\n        query += \" AND instrument_platform=ILLUMINA AND library_layout=PAIRED\"\n    else:\n        query += \" AND (instrument_platform=OXFORD_NANOPORE OR instrument_platform=PACBIO_SMRT)\"\n\n    query += \" AND library_source=TRANSCRIPTOMIC\"\n\n    search_url = f\"https://www.ebi.ac.uk/ena/portal/api/search?display=report&amp;query={query}&amp;domain=read&amp;result=read_run&amp;fields=sample_accession,run_accession,fastq_ftp,read_count,instrument_platform,fastq_md5\"\n    search_result = requests.get(search_url)\n    results = search_result.text.strip().split(\"\\n\")[1:]\n    is_paired = \"1\"\n    is_mate_1 = \"-1\"\n    read_length = \"1\"\n    is_plus_13 = \"0\"\n    centre = \"ENA\"\n\n    for row in results:\n        if len(row.split(\"\\t\")) == 6:\n            row_data = row.split(\"\\t\")\n            sample_accession = row_data[1]\n            run_accession = row_data[0]\n\n            multi_samples = sample_accession.split(\";\")\n            if len(multi_samples) &gt; 1:\n                sample, description = \"multiple\", \"multiple\"\n            else:\n                sample, description = get_sample_info(sample_accession)\n\n            try:\n                read_count = int(row_data[3])\n                instrument_platform = row_data[4]\n            except ValueError:\n                read_count = \"0\"\n                instrument_platform = row_data[3]\n\n            file_entries = row_data[2].split(\";\")\n            md5_entries = row_data[5].split(\";\")\n\n            if len(file_entries) == 2 and instrument_platform == \"ILLUMINA\":\n                pass  # Nothing special to do, continue as normal\n            elif len(file_entries) == 1 and instrument_platform == \"PACBIO_SMRT\":\n                pass\n            elif len(file_entries) == 3 and instrument_platform == \"ILLUMINA\":\n                # Identify the unwanted entry and remove it\n                file_entries = [\n                    f for f in file_entries if \"_1.fastq.gz\" in f or \"_2.fastq.gz\" in f\n                ]\n                # Assuming the order of md5 corresponds to files and the unwanted file is in the middle\n                md5_entries = [\n                    md5_entries[i]\n                    for i, f in enumerate(row_data[2].split(\";\"))\n                    if \"_1.fastq.gz\" in f or \"_2.fastq.gz\" in f\n                ]\n            else:\n                print(\n                    \"Warning: Unexpected number of file entries, skipping \"\n                    + run_accession\n                )\n                next  # Skip further processing for this row\n\n            # Only proceed if we have exactly 2 entries after any necessary filtering\n            if (len(file_entries) == 1 and instrument_platform == \"PACBIO_SMRT\") or (\n                len(file_entries) == 2 and instrument_platform == \"ILLUMINA\"\n            ):\n                # if \"ftp\" in row_data[2] and \";\" in row_data[5]:\n                for file, md5_file in zip(file_entries, md5_entries):\n                    file_path = os.path.basename(file)\n                    md5_file_value = md5_file\n                    csv_data.append(\n                        (\n                            sample,\n                            run_accession,\n                            is_paired,\n                            file_path,\n                            is_mate_1,\n                            read_length,\n                            is_plus_13,\n                            centre,\n                            instrument_platform,\n                            description,\n                            file,\n                            md5_file_value,\n                        )\n                    )\n\n    return csv_data\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/get_transcriptomic_data/#ensembl.genes.transcriptomic_data.get_transcriptomic_data.get_sample_info","title":"<code>get_sample_info(accession)</code>","text":"<p>Get info about sample name and description for the run accession</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/get_transcriptomic_data.py</code> <pre><code>def get_sample_info(accession: str) -&gt; List:\n    \"\"\"Get info about sample name and description for the run accession\"\"\"\n    biosample_url = f\"https://www.ebi.ac.uk/biosamples/samples/{accession}\"\n\n    try:\n        response = requests.get(biosample_url)\n        response.raise_for_status()  # Raise an HTTPError if the request was not successful\n\n        biosample_data = response.json()\n\n        if (\n            \"characteristics\" in biosample_data\n            and \"tissue\" in biosample_data[\"characteristics\"]\n        ):\n            sample = biosample_data[\"characteristics\"][\"tissue\"][0][\"text\"].lower()\n        elif (\n            \"characteristics\" in biosample_data\n            and \"organism_part\" in biosample_data[\"characteristics\"]\n        ):\n            sample = biosample_data[\"characteristics\"][\"organism_part\"][0][\n                \"text\"\n            ].lower()\n        else:\n            sample = accession\n\n        if (\n            \"characteristics\" in biosample_data\n            and \"description\" in biosample_data[\"characteristics\"]\n        ):\n            description = biosample_data[\"characteristics\"][\"description\"][0][\"text\"]\n            if len(description) &gt; 250:\n                description = accession\n        else:\n            description = accession\n\n        sample = re.sub(r\"[ ;\\(\\)\\/\\\\]\", \"_\", sample)\n        # remove punctuation\n        sample = re.sub(r\"[!\\\"#$%&amp;()*\\+,\\-\\'.\\/:;&lt;=&gt;?@\\[\\]^`{|}~]\", \"\", sample)\n        multi_tissuesREGEX = \"([a-zA-Z]+\\,)+\"\n        if re.search(multi_tissuesREGEX, sample):\n            sample = \"mixed_tissues\"\n\n        return (sample, description)\n\n    except (RequestException, HTTPError, ConnectionError, Timeout) as e:\n        print(f\"An error occurred while fetching data from {biosample_url}: {str(e)}\")\n        # Handle the error here, you can log it or take other appropriate actions.\n        return (\"unknown\", \"unknown\")\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/get_transcriptomic_data/#ensembl.genes.transcriptomic_data.get_transcriptomic_data.main","title":"<code>main()</code>","text":"<p>Entrypoint</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/get_transcriptomic_data.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Entrypoint\"\"\"\n    parser = InputSchema()\n    args = parser.parse_args()\n\n    if os.path.isfile(args.csv_file) and os.stat(args.csv_file).st_size &gt; 0:\n        print(\n            \"File \" + args.csv_file + \" exists, and is not empty, will not overwrite!\"\n        )\n        exit\n    else:\n        try:\n            csv_data = get_data_from_ena(args.taxon_id, args.read_type, args.tree)\n\n            if args.limit:\n                csv_data = csv_data[: (args.limit * 2)]\n\n            with open(Path(args.csv_file), \"w\", encoding=\"utf8\") as csv_file:\n                for row in csv_data:\n                    csv_file.write(\"\\t\".join(row) + \"\\n\")\n        except (RequestException, HTTPError, ConnectionError, Timeout) as e:\n            print(f\"An error occurred during the data retrieval process: {str(e)}\")\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/select_transcriptomic_data/","title":"<code>ensembl.genes.transcriptomic_data.select_transcriptomic_data</code>","text":""},{"location":"ensembl/genes/transcriptomic_data/select_transcriptomic_data/#ensembl.genes.transcriptomic_data.select_transcriptomic_data","title":"<code>ensembl.genes.transcriptomic_data.select_transcriptomic_data</code>","text":"<p>Select assessed data from the database and create a report. This script connects to a MySQL database, retrieves data related to sequencing runs, applies quality checks using FastQC and STAR, and generates a report summarizing the results.</p>"},{"location":"ensembl/genes/transcriptomic_data/select_transcriptomic_data/#ensembl.genes.transcriptomic_data.select_transcriptomic_data.check_fastqc_star_quality","title":"<code>check_fastqc_star_quality(df)</code>","text":"<p>Apply FastQC and STAR quality to each row Args:     df (pd.DataFrame): DataFrame containing the data to be processed. Returns:     pd.DataFrame: DataFrame with additional columns for FastQC and STAR quality.</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/select_transcriptomic_data.py</code> <pre><code>def check_fastqc_star_quality(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Apply FastQC and STAR quality to each row\n    Args:\n        df (pd.DataFrame): DataFrame containing the data to be processed.\n    Returns:\n        pd.DataFrame: DataFrame with additional columns for FastQC and STAR quality.\n    \"\"\"\n    # Apply FastQC and STAR quality to each row\n    df[\"fastqc_pass\"] = df.apply(fastqc_quality, axis=1)\n    df[\"star_quality\"] = df.apply(star_quality, axis=1)\n\n    # Assign final quality labels\n\n    df[\"final_fastqc_status\"] = df.groupby(\"run_accession\")[\"fastqc_pass\"].transform(\n        lambda x: \"Failed\" if not all(x) else \"Passed\"\n    )\n    df[\"final_star_status\"] = df.groupby(\"run_accession\")[\"star_quality\"].transform(\n        lambda x: \"Failed\" if not all(x) else \"Passed\"\n    )\n    df[\"passed_both\"] = (df[\"final_fastqc_status\"] == \"Passed\") &amp; (\n        df[\"final_star_status\"] == \"Passed\"\n    )\n    # print(df.head(10))\n    return df\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/select_transcriptomic_data/#ensembl.genes.transcriptomic_data.select_transcriptomic_data.clean_repeated_words","title":"<code>clean_repeated_words(text)</code>","text":"<p>Remove consecutive duplicate words from a string.\"</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The input string from which to remove</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string with consecutive duplicate words removed,</p> <code>str</code> <p>preserving the first occurrence of each word.</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/select_transcriptomic_data.py</code> <pre><code>def clean_repeated_words(text: str) -&gt; str:\n    \"\"\"Remove consecutive duplicate words from a string.\"\n\n    Args:\n        text (str): The input string from which to remove\n        consecutive duplicate words.\n\n    Returns:\n        str: A string with consecutive duplicate words removed,\n        preserving the first occurrence of each word.\n    \"\"\"\n    words = text.split()\n    if not words:\n        return \"\"\n    # Keep only the first occurrence, skip consecutive duplicates\n    cleaned_words = [words[0]]\n    for w in words[1:]:\n        if w != cleaned_words[-1]:\n            cleaned_words.append(w)\n    return \" \".join(cleaned_words)\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/select_transcriptomic_data/#ensembl.genes.transcriptomic_data.select_transcriptomic_data.connect_to_db","title":"<code>connect_to_db(host, user, password, database, port=3306)</code>","text":"<p>Establishes a connection to the MySQL database.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>The hostname or IP address of the MySQL server.</p> required <code>user</code> <code>str</code> <p>The username to connect to the database.</p> required <code>password</code> <code>str</code> <p>The password for the user.</p> required <code>db</code> <p>The name of the database to connect to.</p> required <code>port</code> <p>The port of the MySQL server (default is 3306).</p> <code>3306</code> <p>Returns:     A pymysql connection object.</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/select_transcriptomic_data.py</code> <pre><code>def connect_to_db(\n    host: str, user: str, password: str, database: str, port=3306\n) -&gt; pymysql.connections.Connection:\n    \"\"\"\n    Establishes a connection to the MySQL database.\n\n    Args:\n        host: The hostname or IP address of the MySQL server.\n        user: The username to connect to the database.\n        password: The password for the user.\n        db: The name of the database to connect to.\n        port: The port of the MySQL server (default is 3306).\n    Returns:\n        A pymysql connection object.\n    \"\"\"\n    try:\n        connection = pymysql.connect(\n            host=host, user=user, password=password, database=database, port=port\n        )\n        return connection\n    except pymysql.MySQLError as e:\n        print(f\"Error connecting to MySQL: {e}\")\n        return None\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/select_transcriptomic_data/#ensembl.genes.transcriptomic_data.select_transcriptomic_data.create_report","title":"<code>create_report(df, tissue_report_file)</code>","text":"<p>Create a report based on the DataFrame. This function summarizes the FastQC and STAR quality results for each taxon_id and run_accession. It calculates the number of runs that passed both quality checks and the percentage of runs that passed. The report is printed to the console. 1. Group the DataFrame by taxon_id and run_accession. 2. Aggregate the final_fastqc_status and final_star_status columns. 3. Create a new column passed_both to indicate if both quality checks passed. 4. Group the DataFrame by taxon_id and aggregate the results. 5. Calculate the percentage of runs that passed both quality checks. 6. Print the report to the console. 7. Return the summarized DataFrame. 8. The report includes the following columns:     - taxon_id: The taxon ID.     - passed_fastqc: The number of runs that passed FastQC.     - passed_star: The number of runs that passed STAR.     - passed_both: The number of runs that passed both quality checks.     - total_runs: The total number of runs for the taxon_id.     - percentage_passed_both: The percentage of runs that passed both quality checks. Args:     df (pd.DataFrame): DataFrame containing the data to be processed. Returns:     pd.DataFrame: DataFrame with the summarized report.</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/select_transcriptomic_data.py</code> <pre><code>def create_report(df: pd.DataFrame, tissue_report_file: str) -&gt; pd.DataFrame:\n    \"\"\"Create a report based on the DataFrame.\n    This function summarizes the FastQC and STAR quality results for each taxon_id and run_accession.\n    It calculates the number of runs that passed both quality checks and the percentage of runs that passed.\n    The report is printed to the console.\n    1. Group the DataFrame by taxon_id and run_accession.\n    2. Aggregate the final_fastqc_status and final_star_status columns.\n    3. Create a new column passed_both to indicate if both quality checks passed.\n    4. Group the DataFrame by taxon_id and aggregate the results.\n    5. Calculate the percentage of runs that passed both quality checks.\n    6. Print the report to the console.\n    7. Return the summarized DataFrame.\n    8. The report includes the following columns:\n        - taxon_id: The taxon ID.\n        - passed_fastqc: The number of runs that passed FastQC.\n        - passed_star: The number of runs that passed STAR.\n        - passed_both: The number of runs that passed both quality checks.\n        - total_runs: The total number of runs for the taxon_id.\n        - percentage_passed_both: The percentage of runs that passed both quality checks.\n    Args:\n        df (pd.DataFrame): DataFrame containing the data to be processed.\n    Returns:\n        pd.DataFrame: DataFrame with the summarized report.\n    \"\"\"\n    # Collapse to one row per run_accession\n    run_summary = (\n        df.groupby([\"taxon_id\", \"run_accession\"])\n        .agg(\n            final_fastqc_status=(\"final_fastqc_status\", \"first\"),\n            final_star_status=(\"final_star_status\", \"first\"),\n        )\n        .reset_index()\n    )\n    run_summary[\"passed_both\"] = (run_summary[\"final_fastqc_status\"] == \"Passed\") &amp; (\n        run_summary[\"final_star_status\"] == \"Passed\"\n    )\n    # REPORT\n    taxon_pass_summary = (\n        run_summary.groupby(\"taxon_id\")\n        .agg(\n            passed_fastqc=(\"final_fastqc_status\", lambda x: (x == \"Passed\").sum()),\n            passed_star=(\"final_star_status\", lambda x: (x == \"Passed\").sum()),\n            passed_both=(\"passed_both\", \"sum\"),\n            total_runs=(\"run_accession\", \"nunique\"),\n        )\n        .reset_index()\n    )\n\n    # Compute percentage outside of .agg()\n    taxon_pass_summary[\"percentage_passed_both\"] = (\n        taxon_pass_summary[\"passed_both\"] / taxon_pass_summary[\"total_runs\"] * 100\n    ).round(2)\n    taxon_pass_summary[\"passed_fastqc_only\"] = (\n        taxon_pass_summary[\"passed_fastqc\"] - taxon_pass_summary[\"passed_both\"]\n    )\n    taxon_pass_summary[\"passed_star_only\"] = (\n        taxon_pass_summary[\"passed_star\"] - taxon_pass_summary[\"passed_both\"]\n    )\n\n    # print(taxon_pass_summary.head())\n    # print(\"\\n=== Run Quality Summary by Taxon ===\")\n    for _, row in taxon_pass_summary.iterrows():\n        print(\n            f\"Taxon ID: {int(row['taxon_id'])} | \"\n            f\"Total Runs: {row['total_runs']} | \"\n            f\"Passed BOTH: {row['passed_both']} | \"\n            # f\"FastQC Passed: {row['passed_fastqc']} | \"\n            # f\"STAR Passed: {row['passed_star']} | \"\n            f\"\ud83e\uddea FastQC Only: {row['passed_fastqc_only']} | \"\n            f\"\ud83d\ude80 STAR Only: {row['passed_star_only']} | \"\n            f\"\u2714\ufe0f Both %: {row['percentage_passed_both']}%\"\n        )\n        # Prepare tissue-level summary\n    if \"tissue_prediction\" in df.columns:\n        run_tissue_summary = (\n            df.groupby([\"taxon_id\", \"tissue_prediction\", \"run_accession\"])\n            .agg(\n                final_fastqc_status=(\"final_fastqc_status\", \"first\"),\n                final_star_status=(\"final_star_status\", \"first\"),\n            )\n            .reset_index()\n        )\n\n        run_tissue_summary[\"passed_both\"] = (\n            run_tissue_summary[\"final_fastqc_status\"] == \"Passed\"\n        ) &amp; (run_tissue_summary[\"final_star_status\"] == \"Passed\")\n\n        tissue_pass_summary = (\n            run_tissue_summary.groupby([\"taxon_id\", \"tissue_prediction\"])\n            .agg(\n                passed_fastqc=(\"final_fastqc_status\", lambda x: (x == \"Passed\").sum()),\n                passed_star=(\"final_star_status\", lambda x: (x == \"Passed\").sum()),\n                passed_both=(\"passed_both\", \"sum\"),\n                total_runs=(\"run_accession\", \"nunique\"),\n            )\n            .reset_index()\n        )\n\n        tissue_pass_summary[\"percentage_passed_both\"] = (\n            tissue_pass_summary[\"passed_both\"] / tissue_pass_summary[\"total_runs\"] * 100\n        ).round(2)\n\n        tissue_pass_summary[\"passed_fastqc_only\"] = (\n            tissue_pass_summary[\"passed_fastqc\"] - tissue_pass_summary[\"passed_both\"]\n        )\n        tissue_pass_summary[\"passed_star_only\"] = (\n            tissue_pass_summary[\"passed_star\"] - tissue_pass_summary[\"passed_both\"]\n        )\n\n        # Save to text file\n        with open(tissue_report_file, \"w\") as f:\n            for _, row in tissue_pass_summary.iterrows():\n                f.write(\n                    f\"Taxon ID: {int(row['taxon_id'])} | \"\n                    f\"Tissue: {row['tissue_prediction']} | \"\n                    f\"Total Runs: {row['total_runs']} | \"\n                    f\"Passed BOTH: {row['passed_both']} | \"\n                    # f\"FastQC Passed: {row['passed_fastqc']} | \"\n                    # f\"STAR Passed: {row['passed_star']} | \"\n                    f\"FastQC Only: {row['passed_fastqc_only']} | \"\n                    f\"STAR Only: {row['passed_star_only']} | \"\n                    f\"BOTH %: {row['percentage_passed_both']}%\\n\"\n                )\n\n    return df\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/select_transcriptomic_data/#ensembl.genes.transcriptomic_data.select_transcriptomic_data.fastqc_quality","title":"<code>fastqc_quality(row)</code>","text":"<p>Calculate FastQC quality based on the criteria. The function checks the FastQC quality criteria for each row and returns True if the criteria are met.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>_type_</code> <p>dataframe row</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the criteria are met, False otherwise.</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/select_transcriptomic_data.py</code> <pre><code>def fastqc_quality(row: pd.Series) -&gt; bool:\n    \"\"\"Calculate FastQC quality based on the criteria.\n    The function checks the FastQC quality criteria for each row and returns True if the criteria are met.\n\n\n    Args:\n        row (_type_): dataframe row\n\n    Returns:\n        bool: True if the criteria are met, False otherwise.\n    \"\"\"\n    fastqc_criteria = [\n        row[\"per_base_sequence_quality\"] in [\"PASS\", \"WARN\"],\n        row[\"overrepresented_sequences\"] in [\"PASS\", \"WARN\"],\n        row[\"per_base_n_content\"] in [\"PASS\", \"WARN\"],\n        row[\"per_sequence_quality_scores\"] in [\"PASS\", \"WARN\"],\n    ]\n    return sum(fastqc_criteria) == 4\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/select_transcriptomic_data/#ensembl.genes.transcriptomic_data.select_transcriptomic_data.filter_data","title":"<code>filter_data(df)</code>","text":"<p>Filter the DataFrame to select tissue-annotated samples based on quality criteria.</p> <p>Steps: 1. Remove duplicate run_accessions. 2. Filter out rows with null tissue predictions. 3. Exclude rows with tumor/cancer-related tissue labels. 4. Prioritize specific tissue types (e.g., brain, heart, lung). 5. Group by tissue and select samples up to 250M total reads. 6. If fewer than 500 samples selected, add more high-quality unannotated samples.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame with tissue predictions and QC info.</p> required <code>debug</code> <code>bool</code> <p>If True, write intermediate CSVs for debugging.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List[str]: List of selected run_accessions.</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/select_transcriptomic_data.py</code> <pre><code>def filter_data(df: pd.DataFrame) -&gt; list:\n    \"\"\"\n    Filter the DataFrame to select tissue-annotated samples based on quality criteria.\n\n    Steps:\n    1. Remove duplicate run_accessions.\n    2. Filter out rows with null tissue predictions.\n    3. Exclude rows with tumor/cancer-related tissue labels.\n    4. Prioritize specific tissue types (e.g., brain, heart, lung).\n    5. Group by tissue and select samples up to 250M total reads.\n    6. If fewer than 500 samples selected, add more high-quality unannotated samples.\n\n    Args:\n        df (pd.DataFrame): Input DataFrame with tissue predictions and QC info.\n        debug (bool): If True, write intermediate CSVs for debugging.\n\n    Returns:\n        List[str]: List of selected run_accessions.\n    \"\"\"\n    df = df.drop_duplicates(subset=\"run_accession\", keep=\"first\")\n    df_tissue = df[df[\"tissue_prediction\"].notnull()].reset_index(drop=True)\n    df_tissue = df_tissue[\n        ~df_tissue[\"tissue_prediction\"].str.contains(\n            r\"tumor|cancer|melanoma|cancer/disease\", flags=re.IGNORECASE, regex=True\n        )\n    ].reset_index(drop=True)\n    # Prioritise tissue types\n    priority_tissues = [\n        \"heart\",\n        \"lung\",\n        \"brain\",\n        \"ovary\",\n        \"ovaries\",\n        \"testes\",\n        \"testis\",\n        \"gonad\",\n        \"gonads\",\n    ]\n    df_tissue = prioritise_tissues(df_tissue, priority_tissues)\n    df_tissue.to_csv(\"tissueall.csv\", index=False)\n    df_tissue = df_tissue[\n        ~(\n            (~df_tissue[\"passed_both\"])\n            &amp; (df_tissue[\"final_fastqc_status\"] == \"Failed\")\n            &amp; (df_tissue[\"final_star_status\"] == \"Failed\")\n        )\n    ]\n    df_tissue.to_csv(\"tissueless.csv\", index=False)\n    df_no_tissue = df[df[\"tissue_prediction\"].isna()].reset_index(drop=True)\n    run_accessions = []\n    # Filter tissue-annotated samples\n    for _, group in df_tissue.groupby(\"tissue_prediction\"):\n        group = group.sort_values(\n            by=[\"priority\", \"passed_both\", \"final_fastqc_status\", \"final_star_status\"],\n            ascending=False,\n        )\n        group.to_csv(\"group.csv\", index=False)\n        total_length = 0\n        for _, row in group.iterrows():\n            if total_length + row[\"total_sequences\"] &lt;= 250 * 10**6:\n                run_accessions.append(row[\"run_accession\"])\n                total_length += row[\"total_sequences\"]\n\n    df_tissue[df_tissue[\"run_accession\"].isin(run_accessions)].to_csv(\n        \"tissuedanio.csv\", index=False\n    )\n\n    if len(run_accessions) &lt; 500:\n        for _, group in df_no_tissue.groupby(\"run_accession\"):\n            total_length = 0\n            if group[\"passed_both\"].any():\n                for _, row in group[group[\"passed_both\"]].iterrows():\n                    run_accessions.append(row[\"run_accession\"])\n\n    return run_accessions\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/select_transcriptomic_data/#ensembl.genes.transcriptomic_data.select_transcriptomic_data.main","title":"<code>main()</code>","text":"<p>Module's entry-point.</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/select_transcriptomic_data.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Module's entry-point.\"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"llm_prediction.py\", description=\"Predict tissue using LLMs\"\n    )\n\n    parser.add_argument(\n        \"--taxon_id\", default=\"10116\", type=str, required=True, help=\"Taxonomy ID\"\n    )\n    parser.add_argument(\n        \"--host\",\n        type=str,\n        default=\"mysql-ens-genebuild-prod-1\",\n        required=False,\n        help=\"Host\",\n    )\n    parser.add_argument(\n        \"--user\", type=str, default=\"ensadmin\", required=False, help=\"User\"\n    )\n    parser.add_argument(\n        \"--password\", type=str, default=\"ensembl\", required=False, help=\"Password\"\n    )\n    parser.add_argument(\n        \"--database\",\n        default=\"gb_transcriptomic_registry\",\n        type=str,\n        required=False,\n        help=\"Database\",\n    )\n    parser.add_argument(\"--port\", default=4527, type=int, required=False, help=\"Port\")\n    parser.add_argument(\n        \"--file_name\", type=str, required=False, help=\"Output file name\"\n    )\n    parser.add_argument(\n        \"--read_type\",\n        type=str,\n        choices=[\"short\", \"long\"],\n        default=\"short\",\n        required=False,\n        help=\"Read type short/long\",\n    )\n    parser.add_argument(\n        \"--csv_for_main\",\n        action=\"store_true\",\n        required=False,\n        help=\"if true will produce the csv we need for main pipeline otherwise \\\n            the one for the full alignment pipeline\",\n    )\n    args = parser.parse_args()\n    engine = create_engine(\n        f\"mysql+pymysql://{args.user}:{args.password}@{args.host}:{args.port}/{args.database}\"\n    )\n\n    # Load the rows to fix (e.g., 150k rows)\n    query = \"\"\n    if args.read_type == \"short\":\n        query = (\n            \"SELECT r.taxon_id, r.run_accession, r.sample_accession, r.platform, r.paired, \\\n            r.tissue_prediction, d.file_name, d.file_url,d.md5,d.per_base_sequence_quality, \\\n            d.per_sequence_quality_scores, d.per_base_n_content, d.overrepresented_sequences,\\\n            d.total_sequences, a.uniquely_mapped_reads_percentage, \\\n            a.percentage_reads_mapped_to_multiple_loci,a.percentage_reads_unmapped_too_short, \\\n            a.assembly_accession \\\n            FROM run r INNER JOIN data_files d ON r.run_id=d.run_id INNER JOIN align a ON r.run_id=a.run_id \\\n            WHERE  r.qc_status='ALIGNED' AND r.paired=1 AND r.platform='ILLUMINA' AND r.taxon_id = \"\n            + args.taxon_id\n        )\n    elif args.read_type == \"long\":\n        query = (\n            \"SELECT r.taxon_id, r.run_accession, r.sample_accession, r.platform, r.paired, \\\n            r.tissue_prediction, d.file_name, d.file_url,d.md5,d.per_base_sequence_quality, \\\n            d.per_sequence_quality_scores, d.per_base_n_content, d.overrepresented_sequences, \\\n            d.total_sequences, a.uniquely_mapped_reads_percentage, \\\n            a.percentage_reads_mapped_to_multiple_loci,a.percentage_reads_unmapped_too_short \\\n            FROM run r INNER JOIN data_files d ON r.run_id=d.run_id INNER JOIN align a ON r.run_id=a.run_id \\\n            WHERE  r.qc_status='ALIGNED' AND r.paired=0 AND r.platform='PACBIO_SMRT' AND r.taxon_id = \"\n            + args.taxon_id\n        )\n    # Connect to the database\n    # db_connection = connect_to_db(**db_config)\n    # Clean the input text\n    try:\n        # if db_connection:\n        # df = pd.read_sql(query, db_connection)\n        df = pd.read_sql(query, engine)\n        # print(f\"Loaded {len(df)} rows.\")\n    except pymysql.MySQLError as e:\n        print(f\"Error connecting to MySQL: {e}\")\n\n    if not df.empty:\n        df = check_fastqc_star_quality(df)\n\n        # df[\"tissue_prediction\"] = df[\"tissue_prediction\"].apply(\n        #    lambda x: re.search(r\"^(.*)\", str(x)).group(1) if re.search(r\"^(.*)\", str(x)) else x\n        # )\n        df[\"tissue_prediction\"] = df[\"tissue_prediction\"].apply(\n            lambda x: str(x) if pd.notnull(x) else x\n        )\n        # df[\"tissue_prediction\"] = df[\"tissue_prediction\"].apply(\n        #    lambda x: (m.group(1) if (m := re.search(r\"^(.*)\", str(x))) else x)\n        # )\n        df[\"tissue_prediction\"] = (\n            df[\"tissue_prediction\"]\n            .astype(str)\n            .str.replace('\"', \"\", regex=True)\n            .replace(\"Answer: \", \"\", regex=True)\n            .replace(\"\\n\", \"\", regex=True)\n            .replace(\"Output: \", \"\", regex=True)\n        )\n        df[\"tissue_prediction\"] = df[\"tissue_prediction\"].apply(\n            lambda x: re.sub(\n                r\"[, ]+\",\n                \"_\",  # replace space/comma with underscore\n                re.sub(\n                    r\"\\b\\d+\\b|\\bday\\b|\\b[a-zA-Z]\\b\",\n                    \"\",  # remove numbers, \"day\", and single letters\n                    clean_repeated_words(str(x)),\n                ),\n            ).strip(\n                \"_\"\n            )  # remove leading/trailing underscores\n        )\n        df[\"tissue_prediction\"] = df[\"tissue_prediction\"].astype(str).str.lower()\n\n        df.loc[\n            df[\"tissue_prediction\"]\n            .astype(str)\n            .str.contains(\"NONE\", case=False, na=False),\n            \"tissue_prediction\",\n        ] = None\n        df.loc[\n            df[\"tissue_prediction\"]\n            .astype(str)\n            .str.contains(\"nan\", case=False, na=False),\n            \"tissue_prediction\",\n        ] = None\n\n        create_report(\n            df, f\"{Path(args.file_name).parent}/{args.taxon_id}_tissue_summary.txt\"\n        )\n        # print(df.head())\n        # Remove duplicates based on 'run_accession' while keeping the first row for each\n        df_original = df.copy()\n        run_accessions = filter_data(df)\n\n        # Build a regex pattern from run_accession list\n        selected_accessions = run_accessions[0:25000]\n        # df_final = df_original[df_original[\"run_accession\"].isin(run_accessions[0:250])].copy()\n        df_final = df_original[\n            df_original[\"run_accession\"].isin(selected_accessions)\n        ].copy()\n        df_final[\"run_accession\"] = pd.Categorical(\n            df_final[\"run_accession\"], categories=selected_accessions, ordered=True\n        )\n        df_final = df_final.sort_values(\n            by=[\"run_accession\", \"file_name\"]\n        )  # \"run_accession\")\n\n        df_final.drop_duplicates(inplace=True)\n        df_final[\"predicted_tissue\"] = df_final.apply(\n            lambda row: (\n                row[\"sample_accession\"]\n                if pd.isnull(row[\"tissue_prediction\"])\n                else row[\"tissue_prediction\"]\n            ),\n            axis=1,\n        )\n        # print(df_final.head())\n        if not df_final.empty:\n            if args.csv_for_main:\n                print(df_final.head())\n                df_final.loc[:, \"file_name\"] = (\n                    df_final[\"file_name\"].astype(str) + \".fastq.gz\"\n                )\n                df_final.loc[:, \"col1\"] = 1\n                df_final.loc[:, \"col_1\"] = -1\n                df_final.loc[:, \"col0\"] = 0\n                df_final.loc[:, \"ENA\"] = \"ENA\"\n\n                with open(args.file_name, \"w\") as f:\n                    df_final.to_csv(\n                        f,\n                        sep=\"\\t\",\n                        index=False,\n                        columns=[\n                            \"predicted_tissue\",\n                            \"run_accession\",\n                            \"col1\",\n                            \"file_name\",\n                            \"col_1\",\n                            \"col1\",\n                            \"col0\",\n                            \"ENA\",\n                            \"platform\",\n                            \"sample_accession\",\n                            \"file_url\",\n                            \"md5\",\n                        ],\n                        header=False,\n                    )\n            else:\n                # taxon_id,gca,platform,paired,tissue,run_accession,pair1,md5_1,pair2,md5_2\n                output_df = (\n                    df_final.groupby(\"run_accession\")\n                    .apply(\n                        lambda g: pd.Series(\n                            {\n                                \"taxon_id\": g[\"taxon_id\"].iloc[0],\n                                \"assembly_accession\": g.get(\n                                    \"assembly_accession\", pd.Series([\"NA\"])\n                                ).iloc[\n                                    0\n                                ],  # optional if gca exists\n                                \"platform\": g[\"platform\"].iloc[0],\n                                \"paired\": bool(int(g[\"paired\"].iloc[0])),\n                                # \"paired\": g[\"paired\"].iloc[0],\n                                \"predicted_tissue\": g[\"predicted_tissue\"].iloc[0],\n                                \"pair1\": g[g[\"file_name\"].str.contains(\"_1\")][\n                                    \"file_url\"\n                                ].values[0],\n                                \"md5_1\": g[g[\"file_name\"].str.contains(\"_1\")][\n                                    \"md5\"\n                                ].values[0],\n                                \"pair2\": g[g[\"file_name\"].str.contains(\"_2\")][\n                                    \"file_url\"\n                                ].values[0],\n                                \"md5_2\": g[g[\"file_name\"].str.contains(\"_2\")][\n                                    \"md5\"\n                                ].values[0],\n                            }\n                        )\n                    )\n                    .reset_index()\n                )\n                output_df = output_df.drop(columns=[\"tissue\"], errors=\"ignore\").rename(\n                    columns={\"predicted_tissue\": \"tissue\"}\n                )\n\n                with open(args.file_name, \"w\") as f:\n                    output_df.to_csv(\n                        f,\n                        sep=\",\",\n                        index=False,\n                        columns=[\n                            \"taxon_id\",\n                            \"assembly_accession\",\n                            \"platform\",\n                            \"paired\",\n                            \"tissue\",\n                            \"run_accession\",\n                            \"pair1\",\n                            \"md5_1\",\n                            \"pair2\",\n                            \"md5_2\",\n                        ],\n                        header=True,\n                    )\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/select_transcriptomic_data/#ensembl.genes.transcriptomic_data.select_transcriptomic_data.prioritise_tissues","title":"<code>prioritise_tissues(df, priority_tissues)</code>","text":"<p>Assign a numeric priority to tissue predictions based on a predefined list.</p> <p>This function adds a 'priority' column to the input DataFrame: - Rows where the 'tissue_prediction' matches any of the <code>priority_tissues</code> (case-insensitive, partial match) are assigned a priority of 1. - All other rows receive a priority of 2.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing a 'tissue_prediction' column.</p> required <code>priority_tissues</code> <code>List[str]</code> <p>List of tissue names to prioritize (e.g., ['brain', 'liver']).</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Modified DataFrame with an added 'priority' column.</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/select_transcriptomic_data.py</code> <pre><code>def prioritise_tissues(\n    df: pd.DataFrame, priority_tissues: typing.List[str]\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Assign a numeric priority to tissue predictions based on a predefined list.\n\n    This function adds a 'priority' column to the input DataFrame:\n    - Rows where the 'tissue_prediction' matches any of the `priority_tissues`\n    (case-insensitive, partial match) are assigned a priority of 1.\n    - All other rows receive a priority of 2.\n\n    Args:\n        df (pd.DataFrame): DataFrame containing a 'tissue_prediction' column.\n        priority_tissues (List[str]): List of tissue names to prioritize (e.g., ['brain', 'liver']).\n\n    Returns:\n        pd.DataFrame: Modified DataFrame with an added 'priority' column.\n    \"\"\"\n    priority_regex = re.compile(\n        r\"|\".join(map(re.escape, priority_tissues)), re.IGNORECASE\n    )\n    df[\"priority\"] = df[\"tissue_prediction\"].apply(\n        lambda x: 1 if isinstance(x, str) and priority_regex.search(x) else 2\n    )\n    return df\n</code></pre>"},{"location":"ensembl/genes/transcriptomic_data/select_transcriptomic_data/#ensembl.genes.transcriptomic_data.select_transcriptomic_data.star_quality","title":"<code>star_quality(row)</code>","text":"<p>Calculate STAR quality based on the criteria. The function checks the STAR quality criteria for each row and returns True if the criteria are met. Args:     row (type): dataframe row Returns:     bool: True if the criteria are met, False otherwise.</p> Source code in <code>src/python/ensembl/genes/transcriptomic_data/select_transcriptomic_data.py</code> <pre><code>def star_quality(row: pd.Series) -&gt; bool:\n    \"\"\"Calculate STAR quality based on the criteria.\n    The function checks the STAR quality criteria for each row and returns True if the criteria are met.\n    Args:\n        row (_type_): dataframe row\n    Returns:\n        bool: True if the criteria are met, False otherwise.\n    \"\"\"\n    return (\n        row[\"uniquely_mapped_reads_percentage\"] &gt;= 50\n        and row[\"percentage_reads_mapped_to_multiple_loci\"] &lt;= 30\n        and row[\"percentage_reads_unmapped_too_short\"] &lt;= 20\n    )\n</code></pre>"},{"location":"reference/summary/","title":"Summary","text":"<ul> <li>Home<ul> <li>Overview</li> <li>Install</li> <li>Usage</li> </ul> </li> <li>Development<ul> <li>Code of Conduct</li> <li>Coverage report</li> </ul> </li> <li>Code reference<ul> <li>ensembl<ul> <li>genes<ul> <li>automation<ul> <li>pre_release_ftp</li> </ul> </li> <li>content<ul> <li>main_static_content</li> <li>main_static_murine_content</li> </ul> </li> <li>info_from_registry<ul> <li>assign_species_prefix</li> <li>assign_stable_space</li> <li>build_anno_commands</li> <li>check_if_annotated</li> <li>check_stable_space_old_registry</li> <li>create_config</li> <li>create_pipe_reg</li> <li>genebuild_start_pipeline</li> <li>mysql_helper</li> <li>registry_helper</li> <li>seed_nonvert</li> <li>start_pipeline_from_registry</li> <li>taxonomy_helper</li> <li>update_assembly_registry</li> <li>write_metrics_to_registry</li> </ul> </li> <li>metadata<ul> <li>beta_patcher</li> <li>core_meta_data</li> </ul> </li> <li>metrics<ul> <li>busco_lineage_selector</li> <li>busco_metakeys_patch</li> <li>check_busco_score</li> </ul> </li> <li>projects<ul> <li>write_yaml</li> </ul> </li> <li>stable_id<ul> <li>pid_overlap</li> </ul> </li> <li>tracking<ul> <li>bioproject_tracking</li> <li>live_tracking</li> </ul> </li> <li>transcriptomic_data<ul> <li>check_for_transcriptomic</li> <li>get_transcriptomic_data</li> <li>select_transcriptomic_data</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"}]}